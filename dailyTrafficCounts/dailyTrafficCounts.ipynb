{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily Traffic Counts\n",
    "Questions:\n",
    "- Can we get time stamp of the image?\n",
    "- How can we get live speed data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import segmentation_models_pytorch as smp\n",
    "import albumentations as album\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import plotly.express as px\n",
    "import torchmetrics\n",
    "from torchmetrics import MeanAbsolutePercentageError\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 1024\n",
    "VEHICLE_DETECTION_COUNT_PATH = '/home/ah2719/FYP/Spatial_Finance_Transport/data/vehicle_counts_detection.csv'\n",
    "DAILY_COUNT_PATH = '/home/ah2719/FYP/Spatial_Finance_Transport/data/ground_truth_data/df_aadt_week.csv'\n",
    "SPEED_DATA_PATH = \"/home/ah2719/FYP/Spatial_Finance_Transport/data/ground_truth_data/avg_mph.csv\"\n",
    "ROAD_WIDTH_PATH = \"\"\n",
    "TIMESTAMP_PATH = \"/home/ah2719/FYP/Spatial_Finance_Transport/data/ground_truth_data/timestamp.csv\"\n",
    "AVG_MPH_PATH = \"/home/ah2719/FYP/Spatial_Finance_Transport/data/ground_truth_data/avg_mph.csv\"\n",
    "\n",
    "NN_MODEL_PATH = \"/home/ah2719/FYP/Spatial_Finance_Transport/models/nn_model.pth\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True Count Data\n",
    "- Traffic monitoring stations for long-term traffic count data\n",
    "    - Extract at same time as Satellite Image!\n",
    "- How to use permanent and temporary traffic count stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Ground Truth Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vehicle detection number\n",
    "From vehicle detection model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Road characteristics\n",
    "From road characterstics pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Includes:\n",
    "- Road width\n",
    "- Live speed data\n",
    "- Directionality"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.labels = torch.tensor(pd.read_csv(DAILY_COUNT_PATH)['aadt'].values.astype('float32'))\n",
    "        self.vehicle_count = torch.tensor(pd.read_csv(DAILY_COUNT_PATH)['total_volume_normalised'].values.astype('float32')).unsqueeze(1) # Training\n",
    "        #self.speed_data = pd.read_csv(SPEED_DATA_PATH) \n",
    "        #self.road_width = pd.read_csv(ROAD_WIDTH_PATH)\n",
    "        self.hour = torch.tensor(pd.read_csv(DAILY_COUNT_PATH)['hour'].values.astype('float32')).unsqueeze(1)\n",
    "        self.avg_mph = torch.tensor(pd.read_csv(DAILY_COUNT_PATH)['avg_mph'].values.astype('float32')).unsqueeze(1)\n",
    "        self.day = torch.tensor(pd.read_csv(DAILY_COUNT_PATH)['day'].values.astype('float32')).unsqueeze(1)\n",
    "        self.month = torch.tensor(pd.read_csv(DAILY_COUNT_PATH)['month'].values.astype('float32')).unsqueeze(1)\n",
    "\n",
    "        self.x = torch.concat((self.vehicle_count, self.avg_mph, self.day, self.month, self.hour), dim=-1)\n",
    "        self.y = self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "custom_data = CustomDataset()\n",
    "train_split = 0.8\n",
    "train_data, test_data = random_split(custom_data, [train_split, 1-train_split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(5, 5),\n",
    "            nn.Linear(5,20),\n",
    "            nn.Linear(20,1)\n",
    "            #nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=5, bias=True)\n",
       "    (1): Linear(in_features=5, out_features=20, bias=True)\n",
       "    (2): Linear(in_features=20, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model = NeuralNetwork()\n",
    "nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=5, bias=True)\n",
       "    (1): Linear(in_features=5, out_features=20, bias=True)\n",
       "    (2): Linear(in_features=20, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "nn_model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-1\n",
    "batch_size = 1\n",
    "epochs = 1\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(nn_model.parameters(), lr=learning_rate)\n",
    "\n",
    "MAPE = MeanAbsolutePercentageError()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=False, sampler=None,\n",
    "                    batch_sampler=None, num_workers=0, collate_fn=None,\n",
    "                    pin_memory=False, drop_last=False, timeout=0,\n",
    "                    worker_init_fn=None, prefetch_factor=2,\n",
    "                    persistent_workers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False, sampler=None,\n",
    "                    batch_sampler=None, num_workers=0, collate_fn=None,\n",
    "                    pin_memory=False, drop_last=False, timeout=0,\n",
    "                    worker_init_fn=None, prefetch_factor=2,\n",
    "                    persistent_workers=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(ep_id, action, loader, model, optimizer, criterion):\n",
    "    losses = [] # Keep list of accuracies to track progress\n",
    "    is_training = action == \"train\" # True when action == \"train\", else False \n",
    "\n",
    "    # Looping over all batches\n",
    "    for batch_idx, batch in enumerate(loader): \n",
    "            x, y = batch\n",
    "            #print(\"x: {}\".format(x))\n",
    "            #print(\"y: {}\".format(y))\n",
    "\n",
    "            # Resetting the optimizer gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Setting model to train or test\n",
    "            with torch.set_grad_enabled(is_training):\n",
    "                \n",
    "                # Feed batch to model\n",
    "                logits = nn_model(x).squeeze(1)\n",
    "                print(\"logits: {}\".format(logits))\n",
    "\n",
    "                # Calculate the loss based on predictions and real labels\n",
    "                loss = criterion(logits, y)\n",
    "                print(\"loss: {}\".format(loss))\n",
    "                mape_loss = MAPE(logits, y)\n",
    "\n",
    "                # If training, perform backprop and update weights\n",
    "                if is_training:\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # Append current batch accuracy\n",
    "                losses.append(mape_loss.detach().numpy())\n",
    "\n",
    "                # Print some stats every 50th batch \n",
    "                if batch_idx % 50 == 0:\n",
    "                    print(f\"{action.capitalize()}ing, Epoch: {ep_id+1}, Batch {batch_idx}: Loss = {loss.item()}\")\n",
    "    # Return accuracies to main loop                 \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(epochs, train_dl, test_dl, model, optimizer, criterion):\n",
    "\n",
    "    # Keep lists of accuracies to track performance on train and test sets\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    # Looping over epochs\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Looping over train set and training\n",
    "        train_loss = run_epoch(epoch, \"train\", train_dl, model, optimizer, criterion)\n",
    "\n",
    "        # Looping over test set\n",
    "        test_loss = run_epoch(epoch, \"test\", test_dl, model, optimizer, criterion) \n",
    "\n",
    "        # Collecting stats\n",
    "        train_losses += train_loss\n",
    "        test_losses += test_loss         \n",
    "            \n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits: tensor([38.6336], grad_fn=<SqueezeBackward1>)\n",
      "loss: 332482752.0\n",
      "Training, Epoch: 1, Batch 0: Loss = 332482752.0\n",
      "logits: tensor([183.8640], grad_fn=<SqueezeBackward1>)\n",
      "loss: 327207552.0\n",
      "logits: tensor([346.5258], grad_fn=<SqueezeBackward1>)\n",
      "loss: 321349248.0\n",
      "logits: tensor([675.1091], grad_fn=<SqueezeBackward1>)\n",
      "loss: 309676672.0\n",
      "logits: tensor([1154.5023], grad_fn=<SqueezeBackward1>)\n",
      "loss: 293034144.0\n",
      "logits: tensor([1673.0631], grad_fn=<SqueezeBackward1>)\n",
      "loss: 275549376.0\n",
      "logits: tensor([2698.9248], grad_fn=<SqueezeBackward1>)\n",
      "loss: 242543792.0\n",
      "logits: tensor([3635.2786], grad_fn=<SqueezeBackward1>)\n",
      "loss: 214255344.0\n",
      "logits: tensor([5129.1216], grad_fn=<SqueezeBackward1>)\n",
      "loss: 172754768.0\n",
      "logits: tensor([7048.3823], grad_fn=<SqueezeBackward1>)\n",
      "loss: 125986240.0\n",
      "logits: tensor([10443.5078], grad_fn=<SqueezeBackward1>)\n",
      "loss: 61296912.0\n",
      "logits: tensor([12811.5146], grad_fn=<SqueezeBackward1>)\n",
      "loss: 29825006.0\n",
      "logits: tensor([14610.2773], grad_fn=<SqueezeBackward1>)\n",
      "loss: 13413649.0\n",
      "logits: tensor([18937.9766], grad_fn=<SqueezeBackward1>)\n",
      "loss: 442536.78125\n",
      "logits: tensor([24200.8398], grad_fn=<SqueezeBackward1>)\n",
      "loss: 35142340.0\n",
      "logits: tensor([24461.4062], grad_fn=<SqueezeBackward1>)\n",
      "loss: 38299564.0\n",
      "logits: tensor([25675.6367], grad_fn=<SqueezeBackward1>)\n",
      "loss: 54802848.0\n",
      "logits: tensor([24443.6152], grad_fn=<SqueezeBackward1>)\n",
      "loss: 38079676.0\n",
      "logits: tensor([22073.7617], grad_fn=<SqueezeBackward1>)\n",
      "loss: 14447749.0\n",
      "logits: tensor([23856.3984], grad_fn=<SqueezeBackward1>)\n",
      "loss: 31177218.0\n",
      "logits: tensor([21971.4570], grad_fn=<SqueezeBackward1>)\n",
      "loss: 13680491.0\n",
      "logits: tensor([17285.3730], grad_fn=<SqueezeBackward1>)\n",
      "loss: 974897.8125\n",
      "logits: tensor([18326.0273], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2839.307861328125\n",
      "logits: tensor([16430.3535], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3394396.0\n",
      "logits: tensor([15390.8613], grad_fn=<SqueezeBackward1>)\n",
      "loss: 8305237.5\n",
      "logits: tensor([14528.9727], grad_fn=<SqueezeBackward1>)\n",
      "loss: 14015810.0\n",
      "logits: tensor([14212.8633], grad_fn=<SqueezeBackward1>)\n",
      "loss: 16482617.0\n",
      "logits: tensor([12847.8135], grad_fn=<SqueezeBackward1>)\n",
      "loss: 29429852.0\n",
      "logits: tensor([14944.0762], grad_fn=<SqueezeBackward1>)\n",
      "loss: 11080017.0\n",
      "logits: tensor([13697.0342], grad_fn=<SqueezeBackward1>)\n",
      "loss: 20937104.0\n",
      "logits: tensor([13131.3447], grad_fn=<SqueezeBackward1>)\n",
      "loss: 26433968.0\n",
      "logits: tensor([17346.4297], grad_fn=<SqueezeBackward1>)\n",
      "loss: 858054.875\n",
      "logits: tensor([14749.0322], grad_fn=<SqueezeBackward1>)\n",
      "loss: 12416532.0\n",
      "logits: tensor([19109.7363], grad_fn=<SqueezeBackward1>)\n",
      "loss: 700559.1875\n",
      "logits: tensor([17107.5762], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1357611.875\n",
      "logits: tensor([18686.5352], grad_fn=<SqueezeBackward1>)\n",
      "loss: 171224.625\n",
      "logits: tensor([23352.0918], grad_fn=<SqueezeBackward1>)\n",
      "loss: 25799792.0\n",
      "logits: tensor([21675.7383], grad_fn=<SqueezeBackward1>)\n",
      "loss: 11580382.0\n",
      "logits: tensor([21996.4902], grad_fn=<SqueezeBackward1>)\n",
      "loss: 13866300.0\n",
      "logits: tensor([18254.8457], grad_fn=<SqueezeBackward1>)\n",
      "loss: 320.2841491699219\n",
      "logits: tensor([22018.0332], grad_fn=<SqueezeBackward1>)\n",
      "loss: 14027205.0\n",
      "logits: tensor([20727.6270], grad_fn=<SqueezeBackward1>)\n",
      "loss: 6026459.0\n",
      "logits: tensor([17374.0312], grad_fn=<SqueezeBackward1>)\n",
      "loss: 807681.375\n",
      "logits: tensor([18778.9902], grad_fn=<SqueezeBackward1>)\n",
      "loss: 256287.078125\n",
      "logits: tensor([17246.0879], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1054019.0\n",
      "logits: tensor([17576.6133], grad_fn=<SqueezeBackward1>)\n",
      "loss: 484595.46875\n",
      "logits: tensor([14678.8896], grad_fn=<SqueezeBackward1>)\n",
      "loss: 12915776.0\n",
      "logits: tensor([13169.2930], grad_fn=<SqueezeBackward1>)\n",
      "loss: 26045194.0\n",
      "logits: tensor([15677.5020], grad_fn=<SqueezeBackward1>)\n",
      "loss: 6735272.0\n",
      "logits: tensor([15437.1738], grad_fn=<SqueezeBackward1>)\n",
      "loss: 8040448.0\n",
      "logits: tensor([16626.7383], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2709328.75\n",
      "Training, Epoch: 1, Batch 50: Loss = 2709328.75\n",
      "logits: tensor([17746.4062], grad_fn=<SqueezeBackward1>)\n",
      "loss: 277029.53125\n",
      "logits: tensor([17506.8535], grad_fn=<SqueezeBackward1>)\n",
      "loss: 586585.4375\n",
      "logits: tensor([20580.3945], grad_fn=<SqueezeBackward1>)\n",
      "loss: 5325259.5\n",
      "logits: tensor([19915.9336], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2700078.0\n",
      "logits: tensor([19604.6836], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1774067.875\n",
      "logits: tensor([20062.6055], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3203610.5\n",
      "logits: tensor([17293.3926], grad_fn=<SqueezeBackward1>)\n",
      "loss: 959125.6875\n",
      "logits: tensor([19602.5781], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1768463.625\n",
      "logits: tensor([18464.2266], grad_fn=<SqueezeBackward1>)\n",
      "loss: 36666.265625\n",
      "logits: tensor([20889.7793], grad_fn=<SqueezeBackward1>)\n",
      "loss: 6848883.0\n",
      "logits: tensor([16273.7686], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3995895.5\n",
      "logits: tensor([18720.7637], grad_fn=<SqueezeBackward1>)\n",
      "loss: 200723.25\n",
      "logits: tensor([17448.0801], grad_fn=<SqueezeBackward1>)\n",
      "loss: 680067.625\n",
      "logits: tensor([17929.7617], grad_fn=<SqueezeBackward1>)\n",
      "loss: 117635.6015625\n",
      "logits: tensor([18608.2129], grad_fn=<SqueezeBackward1>)\n",
      "loss: 112540.59375\n",
      "logits: tensor([14647.9922], grad_fn=<SqueezeBackward1>)\n",
      "loss: 13138813.0\n",
      "logits: tensor([16866.7676], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1976764.625\n",
      "logits: tensor([16793.2109], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2189012.75\n",
      "logits: tensor([16504.1660], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3127861.75\n",
      "logits: tensor([18693.7344], grad_fn=<SqueezeBackward1>)\n",
      "loss: 177234.421875\n",
      "logits: tensor([20054.2695], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3173839.75\n",
      "logits: tensor([18535.2285], grad_fn=<SqueezeBackward1>)\n",
      "loss: 68899.0703125\n",
      "logits: tensor([19670.6855], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1954245.625\n",
      "logits: tensor([19910.3477], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2681751.75\n",
      "logits: tensor([19040.2129], grad_fn=<SqueezeBackward1>)\n",
      "loss: 589011.25\n",
      "logits: tensor([19913.0801], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2690708.5\n",
      "logits: tensor([18015.1621], grad_fn=<SqueezeBackward1>)\n",
      "loss: 66347.5\n",
      "logits: tensor([20021.4746], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3058065.0\n",
      "logits: tensor([19203.7852], grad_fn=<SqueezeBackward1>)\n",
      "loss: 866841.0\n",
      "logits: tensor([16638.8047], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2669751.75\n",
      "logits: tensor([16025.2432], grad_fn=<SqueezeBackward1>)\n",
      "loss: 5051252.0\n",
      "logits: tensor([14125.2158], grad_fn=<SqueezeBackward1>)\n",
      "loss: 17201974.0\n",
      "logits: tensor([15031.4326], grad_fn=<SqueezeBackward1>)\n",
      "loss: 10506088.0\n",
      "logits: tensor([17374.1445], grad_fn=<SqueezeBackward1>)\n",
      "loss: 807477.75\n",
      "logits: tensor([18421.8613], grad_fn=<SqueezeBackward1>)\n",
      "loss: 22236.517578125\n",
      "logits: tensor([18696.7461], grad_fn=<SqueezeBackward1>)\n",
      "loss: 179779.3125\n",
      "logits: tensor([17043.3398], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1511430.125\n",
      "logits: tensor([19795.5000], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2318791.25\n",
      "logits: tensor([18626.8418], grad_fn=<SqueezeBackward1>)\n",
      "loss: 125386.53125\n",
      "logits: tensor([18344.9531], grad_fn=<SqueezeBackward1>)\n",
      "loss: 5214.41943359375\n",
      "logits: tensor([20261.3555], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3954582.75\n",
      "logits: tensor([19351.2480], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1163174.875\n",
      "logits: tensor([19871.2969], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2555377.0\n",
      "logits: tensor([20288.9238], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4064988.5\n",
      "logits: tensor([17504.3438], grad_fn=<SqueezeBackward1>)\n",
      "loss: 590436.1875\n",
      "logits: tensor([17829.9922], grad_fn=<SqueezeBackward1>)\n",
      "loss: 196027.5625\n",
      "logits: tensor([18481.3242], grad_fn=<SqueezeBackward1>)\n",
      "loss: 43506.46484375\n",
      "logits: tensor([16993.7754], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1635756.125\n",
      "logits: tensor([17675.5156], grad_fn=<SqueezeBackward1>)\n",
      "loss: 356679.5625\n",
      "logits: tensor([18440.3691], grad_fn=<SqueezeBackward1>)\n",
      "loss: 28098.794921875\n",
      "Training, Epoch: 1, Batch 100: Loss = 28098.794921875\n",
      "logits: tensor([17658.4727], grad_fn=<SqueezeBackward1>)\n",
      "loss: 377327.0625\n",
      "logits: tensor([17444.2793], grad_fn=<SqueezeBackward1>)\n",
      "loss: 686350.75\n",
      "logits: tensor([16257.4912], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4061236.5\n",
      "logits: tensor([17072.1875], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1441331.5\n",
      "logits: tensor([18240.7188], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1025.50048828125\n",
      "logits: tensor([15707.6465], grad_fn=<SqueezeBackward1>)\n",
      "loss: 6579716.0\n",
      "logits: tensor([20081.7344], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3272452.75\n",
      "logits: tensor([17980.8066], grad_fn=<SqueezeBackward1>)\n",
      "loss: 85226.3671875\n",
      "logits: tensor([20056.5312], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3181903.5\n",
      "logits: tensor([19089.7070], grad_fn=<SqueezeBackward1>)\n",
      "loss: 667431.5625\n",
      "logits: tensor([19048.5352], grad_fn=<SqueezeBackward1>)\n",
      "loss: 601854.75\n",
      "logits: tensor([18628.6191], grad_fn=<SqueezeBackward1>)\n",
      "loss: 126648.40625\n",
      "logits: tensor([19317.1191], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1090723.25\n",
      "logits: tensor([18509.3086], grad_fn=<SqueezeBackward1>)\n",
      "loss: 55963.6640625\n",
      "logits: tensor([18734.4785], grad_fn=<SqueezeBackward1>)\n",
      "loss: 213200.4375\n",
      "logits: tensor([18390.9727], grad_fn=<SqueezeBackward1>)\n",
      "loss: 13978.443359375\n",
      "logits: tensor([18012.8320], grad_fn=<SqueezeBackward1>)\n",
      "loss: 67553.2890625\n",
      "logits: tensor([17649.3418], grad_fn=<SqueezeBackward1>)\n",
      "loss: 388628.0625\n",
      "logits: tensor([15981.0186], grad_fn=<SqueezeBackward1>)\n",
      "loss: 5251997.0\n",
      "logits: tensor([17193.1504], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1165518.5\n",
      "logits: tensor([18259.6270], grad_fn=<SqueezeBackward1>)\n",
      "loss: 172.00936889648438\n",
      "logits: tensor([16228.7256], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4178003.75\n",
      "logits: tensor([18346.1816], grad_fn=<SqueezeBackward1>)\n",
      "loss: 5393.353515625\n",
      "logits: tensor([18272.6738], grad_fn=<SqueezeBackward1>)\n",
      "loss: 0.004673004150390625\n",
      "logits: tensor([19547.0742], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1623922.125\n",
      "logits: tensor([20045.4766], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3142587.25\n",
      "logits: tensor([19153.3086], grad_fn=<SqueezeBackward1>)\n",
      "loss: 775397.1875\n",
      "logits: tensor([18296.9766], grad_fn=<SqueezeBackward1>)\n",
      "loss: 587.304931640625\n",
      "logits: tensor([19308.3613], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1072507.0\n",
      "logits: tensor([18123.0410], grad_fn=<SqueezeBackward1>)\n",
      "loss: 22410.44140625\n",
      "logits: tensor([16982.3438], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1665128.125\n",
      "logits: tensor([17037.9082], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1524815.0\n",
      "logits: tensor([18740.3652], grad_fn=<SqueezeBackward1>)\n",
      "loss: 218671.3125\n",
      "logits: tensor([18295.3945], grad_fn=<SqueezeBackward1>)\n",
      "loss: 513.128662109375\n",
      "logits: tensor([15410.5234], grad_fn=<SqueezeBackward1>)\n",
      "loss: 8192296.0\n",
      "logits: tensor([18010.0059], grad_fn=<SqueezeBackward1>)\n",
      "loss: 69030.375\n",
      "logits: tensor([18432.0273], grad_fn=<SqueezeBackward1>)\n",
      "loss: 25371.76171875\n",
      "logits: tensor([19549.6621], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1630524.5\n",
      "logits: tensor([18178.9219], grad_fn=<SqueezeBackward1>)\n",
      "loss: 8802.2509765625\n",
      "logits: tensor([18506.5391], grad_fn=<SqueezeBackward1>)\n",
      "loss: 54660.98046875\n",
      "logits: tensor([19368.8672], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1201490.0\n",
      "logits: tensor([17355.4062], grad_fn=<SqueezeBackward1>)\n",
      "loss: 841505.25\n",
      "logits: tensor([19515.0840], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1543413.125\n",
      "logits: tensor([20003.3984], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2995171.0\n",
      "logits: tensor([18179.0059], grad_fn=<SqueezeBackward1>)\n",
      "loss: 8786.4990234375\n",
      "logits: tensor([17083.9824], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1413149.75\n",
      "logits: tensor([18346.1211], grad_fn=<SqueezeBackward1>)\n",
      "loss: 5384.4638671875\n",
      "logits: tensor([17678.6094], grad_fn=<SqueezeBackward1>)\n",
      "loss: 352993.8125\n",
      "logits: tensor([16204.5674], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4277347.0\n",
      "logits: tensor([17042.2051], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1514221.625\n",
      "Training, Epoch: 1, Batch 150: Loss = 1514221.625\n",
      "logits: tensor([17341.6973], grad_fn=<SqueezeBackward1>)\n",
      "loss: 866844.625\n",
      "logits: tensor([16031.8037], grad_fn=<SqueezeBackward1>)\n",
      "loss: 5021805.5\n",
      "logits: tensor([17496.5215], grad_fn=<SqueezeBackward1>)\n",
      "loss: 602518.5625\n",
      "logits: tensor([18404.1445], grad_fn=<SqueezeBackward1>)\n",
      "loss: 17266.576171875\n",
      "logits: tensor([20456.8730], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4770427.5\n",
      "logits: tensor([20462.8809], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4796707.5\n",
      "logits: tensor([21604.9902], grad_fn=<SqueezeBackward1>)\n",
      "loss: 11103877.0\n",
      "logits: tensor([20540.2070], grad_fn=<SqueezeBackward1>)\n",
      "loss: 5141397.0\n",
      "logits: tensor([18520.9863], grad_fn=<SqueezeBackward1>)\n",
      "loss: 61625.15234375\n",
      "logits: tensor([18685.8066], grad_fn=<SqueezeBackward1>)\n",
      "loss: 170622.25\n",
      "logits: tensor([17591.9473], grad_fn=<SqueezeBackward1>)\n",
      "loss: 463481.71875\n",
      "logits: tensor([15915.0723], grad_fn=<SqueezeBackward1>)\n",
      "loss: 5558607.5\n",
      "logits: tensor([14825.3350], grad_fn=<SqueezeBackward1>)\n",
      "loss: 11884617.0\n",
      "logits: tensor([15147.3535], grad_fn=<SqueezeBackward1>)\n",
      "loss: 9768054.0\n",
      "logits: tensor([15467.7920], grad_fn=<SqueezeBackward1>)\n",
      "loss: 7867745.5\n",
      "logits: tensor([17536.8164], grad_fn=<SqueezeBackward1>)\n",
      "loss: 541586.75\n",
      "logits: tensor([16742.2754], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2342328.5\n",
      "logits: tensor([18894.7402], grad_fn=<SqueezeBackward1>)\n",
      "loss: 386881.5625\n",
      "logits: tensor([21326.7754], grad_fn=<SqueezeBackward1>)\n",
      "loss: 9327119.0\n",
      "logits: tensor([18866.5957], grad_fn=<SqueezeBackward1>)\n",
      "loss: 352662.0\n",
      "logits: tensor([18756.6973], grad_fn=<SqueezeBackward1>)\n",
      "loss: 234212.515625\n",
      "logits: tensor([18876.0410], grad_fn=<SqueezeBackward1>)\n",
      "loss: 363969.46875\n",
      "logits: tensor([19726.8320], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2114377.25\n",
      "logits: tensor([18082.9102], grad_fn=<SqueezeBackward1>)\n",
      "loss: 36036.19921875\n",
      "logits: tensor([18548.3535], grad_fn=<SqueezeBackward1>)\n",
      "loss: 75961.6015625\n",
      "logits: tensor([17957.4922], grad_fn=<SqueezeBackward1>)\n",
      "loss: 99382.5625\n",
      "logits: tensor([18666.6582], grad_fn=<SqueezeBackward1>)\n",
      "loss: 155169.828125\n",
      "logits: tensor([18187.2598], grad_fn=<SqueezeBackward1>)\n",
      "loss: 7307.24462890625\n",
      "logits: tensor([18257.8398], grad_fn=<SqueezeBackward1>)\n",
      "loss: 222.07984924316406\n",
      "logits: tensor([17904.7598], grad_fn=<SqueezeBackward1>)\n",
      "loss: 135411.0625\n",
      "logits: tensor([16438.7305], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3363599.0\n",
      "logits: tensor([17866.9355], grad_fn=<SqueezeBackward1>)\n",
      "loss: 164679.03125\n",
      "logits: tensor([17852.3438], grad_fn=<SqueezeBackward1>)\n",
      "loss: 176734.84375\n",
      "logits: tensor([17669.4199], grad_fn=<SqueezeBackward1>)\n",
      "loss: 363997.75\n",
      "logits: tensor([19370.7363], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1205591.125\n",
      "logits: tensor([18899.1152], grad_fn=<SqueezeBackward1>)\n",
      "loss: 392343.1875\n",
      "logits: tensor([18927.1289], grad_fn=<SqueezeBackward1>)\n",
      "loss: 428221.96875\n",
      "logits: tensor([20002.7383], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2992886.5\n",
      "logits: tensor([18551.9727], grad_fn=<SqueezeBackward1>)\n",
      "loss: 77969.65625\n",
      "logits: tensor([18093.8984], grad_fn=<SqueezeBackward1>)\n",
      "loss: 31985.0859375\n",
      "logits: tensor([17648.4707], grad_fn=<SqueezeBackward1>)\n",
      "loss: 389714.875\n",
      "logits: tensor([16868.2930], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1972477.625\n",
      "logits: tensor([16808.0078], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2145446.75\n",
      "logits: tensor([18927.3281], grad_fn=<SqueezeBackward1>)\n",
      "loss: 428482.75\n",
      "logits: tensor([17949.9062], grad_fn=<SqueezeBackward1>)\n",
      "loss: 104223.0390625\n",
      "logits: tensor([19012.2793], grad_fn=<SqueezeBackward1>)\n",
      "loss: 546915.125\n",
      "logits: tensor([18555.5762], grad_fn=<SqueezeBackward1>)\n",
      "loss: 79995.0625\n",
      "logits: tensor([18641.9297], grad_fn=<SqueezeBackward1>)\n",
      "loss: 136299.40625\n",
      "logits: tensor([16581.6191], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2859897.25\n",
      "logits: tensor([16326.9473], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3786118.0\n",
      "Training, Epoch: 1, Batch 200: Loss = 3786118.0\n",
      "logits: tensor([19789.6367], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2300969.0\n",
      "logits: tensor([18212.9824], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3571.2294921875\n",
      "logits: tensor([18605.8672], grad_fn=<SqueezeBackward1>)\n",
      "loss: 110972.265625\n",
      "logits: tensor([18751.6270], grad_fn=<SqueezeBackward1>)\n",
      "loss: 229330.625\n",
      "logits: tensor([18953.2129], grad_fn=<SqueezeBackward1>)\n",
      "loss: 463040.375\n",
      "logits: tensor([17407.3652], grad_fn=<SqueezeBackward1>)\n",
      "loss: 748877.25\n",
      "logits: tensor([18615.5801], grad_fn=<SqueezeBackward1>)\n",
      "loss: 117537.8203125\n",
      "logits: tensor([17812.0723], grad_fn=<SqueezeBackward1>)\n",
      "loss: 212216.78125\n",
      "logits: tensor([18369.4160], grad_fn=<SqueezeBackward1>)\n",
      "loss: 9345.8291015625\n",
      "logits: tensor([19011.8203], grad_fn=<SqueezeBackward1>)\n",
      "loss: 546236.5\n",
      "logits: tensor([18750.8652], grad_fn=<SqueezeBackward1>)\n",
      "loss: 228601.640625\n",
      "logits: tensor([17076.6016], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1430752.375\n",
      "logits: tensor([18251.7910], grad_fn=<SqueezeBackward1>)\n",
      "loss: 438.95159912109375\n",
      "logits: tensor([18410.3359], grad_fn=<SqueezeBackward1>)\n",
      "loss: 18932.0390625\n",
      "logits: tensor([17764.8281], grad_fn=<SqueezeBackward1>)\n",
      "loss: 257976.6875\n",
      "logits: tensor([17504.4590], grad_fn=<SqueezeBackward1>)\n",
      "loss: 590259.0625\n",
      "logits: tensor([18298.2051], grad_fn=<SqueezeBackward1>)\n",
      "loss: 648.3588256835938\n",
      "logits: tensor([18206.9434], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4329.48583984375\n",
      "logits: tensor([18480.5488], grad_fn=<SqueezeBackward1>)\n",
      "loss: 43183.6015625\n",
      "logits: tensor([18959.4414], grad_fn=<SqueezeBackward1>)\n",
      "loss: 471555.8125\n",
      "logits: tensor([18447.6016], grad_fn=<SqueezeBackward1>)\n",
      "loss: 30575.80078125\n",
      "logits: tensor([19103.], grad_fn=<SqueezeBackward1>)\n",
      "loss: 689328.0625\n",
      "logits: tensor([18765.4199], grad_fn=<SqueezeBackward1>)\n",
      "loss: 242731.34375\n",
      "logits: tensor([18028.4766], grad_fn=<SqueezeBackward1>)\n",
      "loss: 59665.6953125\n",
      "logits: tensor([19002.6992], grad_fn=<SqueezeBackward1>)\n",
      "loss: 532837.25\n",
      "logits: tensor([17779.0488], grad_fn=<SqueezeBackward1>)\n",
      "loss: 243733.140625\n",
      "logits: tensor([16528.0312], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3044016.25\n",
      "logits: tensor([17561.5098], grad_fn=<SqueezeBackward1>)\n",
      "loss: 505851.5625\n",
      "logits: tensor([17874.3105], grad_fn=<SqueezeBackward1>)\n",
      "loss: 158747.765625\n",
      "logits: tensor([18646.2578], grad_fn=<SqueezeBackward1>)\n",
      "loss: 139513.921875\n",
      "logits: tensor([18168.1758], grad_fn=<SqueezeBackward1>)\n",
      "loss: 10934.1337890625\n",
      "logits: tensor([20161.5332], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3567531.5\n",
      "logits: tensor([19377.6680], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1220861.0\n",
      "logits: tensor([18035.2422], grad_fn=<SqueezeBackward1>)\n",
      "loss: 56406.25\n",
      "logits: tensor([19010.8242], grad_fn=<SqueezeBackward1>)\n",
      "loss: 544765.0625\n",
      "logits: tensor([18281.1953], grad_fn=<SqueezeBackward1>)\n",
      "loss: 71.455322265625\n",
      "logits: tensor([16291.8838], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3923800.0\n",
      "logits: tensor([16894.1680], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1900466.875\n",
      "logits: tensor([18805.0254], grad_fn=<SqueezeBackward1>)\n",
      "loss: 283325.40625\n",
      "logits: tensor([16794.5371], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2185090.25\n",
      "logits: tensor([19028.5781], grad_fn=<SqueezeBackward1>)\n",
      "loss: 571287.9375\n",
      "logits: tensor([17438.7793], grad_fn=<SqueezeBackward1>)\n",
      "loss: 695494.125\n",
      "logits: tensor([17502.6465], grad_fn=<SqueezeBackward1>)\n",
      "loss: 593047.375\n",
      "logits: tensor([18743.9980], grad_fn=<SqueezeBackward1>)\n",
      "loss: 222082.078125\n",
      "logits: tensor([21227.3613], grad_fn=<SqueezeBackward1>)\n",
      "loss: 8729774.0\n",
      "logits: tensor([18372.4805], grad_fn=<SqueezeBackward1>)\n",
      "loss: 9947.724609375\n",
      "logits: tensor([18342.3105], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4839.7568359375\n",
      "logits: tensor([16205.7764], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4272347.5\n",
      "logits: tensor([18166.4453], grad_fn=<SqueezeBackward1>)\n",
      "loss: 11299.025390625\n",
      "logits: tensor([19061.8457], grad_fn=<SqueezeBackward1>)\n",
      "loss: 622684.375\n",
      "Training, Epoch: 1, Batch 250: Loss = 622684.375\n",
      "logits: tensor([18040.4141], grad_fn=<SqueezeBackward1>)\n",
      "loss: 53976.359375\n",
      "logits: tensor([17868.5156], grad_fn=<SqueezeBackward1>)\n",
      "loss: 163399.109375\n",
      "logits: tensor([18408.7168], grad_fn=<SqueezeBackward1>)\n",
      "loss: 18489.09375\n",
      "logits: tensor([18080.4590], grad_fn=<SqueezeBackward1>)\n",
      "loss: 36972.83203125\n",
      "logits: tensor([18064.6641], grad_fn=<SqueezeBackward1>)\n",
      "loss: 43296.5078125\n",
      "logits: tensor([18307.4453], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1204.306884765625\n",
      "logits: tensor([18741.0918], grad_fn=<SqueezeBackward1>)\n",
      "loss: 219351.359375\n",
      "logits: tensor([18432.2598], grad_fn=<SqueezeBackward1>)\n",
      "loss: 25445.857421875\n",
      "logits: tensor([19709.3574], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2063863.375\n",
      "logits: tensor([17489.0977], grad_fn=<SqueezeBackward1>)\n",
      "loss: 614098.75\n",
      "logits: tensor([16900.9102], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1881923.125\n",
      "logits: tensor([17277.1680], grad_fn=<SqueezeBackward1>)\n",
      "loss: 991168.0\n",
      "logits: tensor([17007.8379], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1599982.875\n",
      "logits: tensor([17791.2246], grad_fn=<SqueezeBackward1>)\n",
      "loss: 231859.171875\n",
      "logits: tensor([18676.2324], grad_fn=<SqueezeBackward1>)\n",
      "loss: 162804.375\n",
      "logits: tensor([18374.7812], grad_fn=<SqueezeBackward1>)\n",
      "loss: 10411.970703125\n",
      "logits: tensor([19541.3203], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1609290.5\n",
      "logits: tensor([19768.4492], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2237139.5\n",
      "logits: tensor([19247.6348], grad_fn=<SqueezeBackward1>)\n",
      "loss: 950415.5625\n",
      "logits: tensor([19192.0781], grad_fn=<SqueezeBackward1>)\n",
      "loss: 845178.5625\n",
      "logits: tensor([18045.2910], grad_fn=<SqueezeBackward1>)\n",
      "loss: 51734.03515625\n",
      "logits: tensor([19387.2441], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1242114.625\n",
      "logits: tensor([16113.0703], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4664182.5\n",
      "logits: tensor([16637.2676], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2674777.25\n",
      "logits: tensor([15232.5781], grad_fn=<SqueezeBackward1>)\n",
      "loss: 9242598.0\n",
      "logits: tensor([19286.9219], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1028560.4375\n",
      "logits: tensor([17300.8145], grad_fn=<SqueezeBackward1>)\n",
      "loss: 944643.5\n",
      "logits: tensor([19630.0859], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1842382.0\n",
      "logits: tensor([18783.1445], grad_fn=<SqueezeBackward1>)\n",
      "loss: 260510.546875\n",
      "logits: tensor([19407.3418], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1287316.25\n",
      "logits: tensor([18375.9922], grad_fn=<SqueezeBackward1>)\n",
      "loss: 10660.5625\n",
      "logits: tensor([18115.9629], grad_fn=<SqueezeBackward1>)\n",
      "loss: 24579.748046875\n",
      "logits: tensor([16220.4766], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4211794.0\n",
      "logits: tensor([17342.3262], grad_fn=<SqueezeBackward1>)\n",
      "loss: 865673.9375\n",
      "logits: tensor([17980.2656], grad_fn=<SqueezeBackward1>)\n",
      "loss: 85542.5390625\n",
      "logits: tensor([19331.2852], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1120513.25\n",
      "logits: tensor([18746.4297], grad_fn=<SqueezeBackward1>)\n",
      "loss: 224379.84375\n",
      "logits: tensor([18367.2949], grad_fn=<SqueezeBackward1>)\n",
      "loss: 8940.2197265625\n",
      "logits: tensor([19750.0781], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2182521.5\n",
      "logits: tensor([19118.9863], grad_fn=<SqueezeBackward1>)\n",
      "loss: 716129.125\n",
      "logits: tensor([19235.7930], grad_fn=<SqueezeBackward1>)\n",
      "loss: 927466.8125\n",
      "logits: tensor([17701.8770], grad_fn=<SqueezeBackward1>)\n",
      "loss: 325887.125\n",
      "logits: tensor([16889.4219], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1913575.125\n",
      "logits: tensor([17320.5625], grad_fn=<SqueezeBackward1>)\n",
      "loss: 906646.1875\n",
      "logits: tensor([17939.9746], grad_fn=<SqueezeBackward1>)\n",
      "loss: 110734.2578125\n",
      "logits: tensor([18029.4629], grad_fn=<SqueezeBackward1>)\n",
      "loss: 59184.81640625\n",
      "logits: tensor([16598.3301], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2803656.0\n",
      "logits: tensor([18728.4512], grad_fn=<SqueezeBackward1>)\n",
      "loss: 207670.671875\n",
      "logits: tensor([18019.3438], grad_fn=<SqueezeBackward1>)\n",
      "loss: 64210.76953125\n",
      "logits: tensor([19667.4961], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1945338.5\n",
      "Training, Epoch: 1, Batch 300: Loss = 1945338.5\n",
      "logits: tensor([18484.1621], grad_fn=<SqueezeBackward1>)\n",
      "loss: 44698.3828125\n",
      "logits: tensor([19144.8594], grad_fn=<SqueezeBackward1>)\n",
      "loss: 760588.375\n",
      "logits: tensor([17659.6230], grad_fn=<SqueezeBackward1>)\n",
      "loss: 375915.09375\n",
      "logits: tensor([17885.2559], grad_fn=<SqueezeBackward1>)\n",
      "loss: 150145.65625\n",
      "logits: tensor([18698.2402], grad_fn=<SqueezeBackward1>)\n",
      "loss: 181048.59375\n",
      "logits: tensor([18523.1875], grad_fn=<SqueezeBackward1>)\n",
      "loss: 62722.85546875\n",
      "logits: tensor([17384.6309], grad_fn=<SqueezeBackward1>)\n",
      "loss: 788741.75\n",
      "logits: tensor([17216.9336], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1114731.75\n",
      "logits: tensor([18236.2246], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1333.5335693359375\n",
      "logits: tensor([19560.7363], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1658928.875\n",
      "logits: tensor([19262.2832], grad_fn=<SqueezeBackward1>)\n",
      "loss: 979191.4375\n",
      "logits: tensor([18235.4688], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1389.30908203125\n",
      "logits: tensor([16733.4785], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2369332.75\n",
      "logits: tensor([17740.8555], grad_fn=<SqueezeBackward1>)\n",
      "loss: 282903.46875\n",
      "logits: tensor([18270.6934], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4.197696685791016\n",
      "logits: tensor([18875.4180], grad_fn=<SqueezeBackward1>)\n",
      "loss: 363218.09375\n",
      "logits: tensor([19379.6797], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1225310.625\n",
      "logits: tensor([18663.4512], grad_fn=<SqueezeBackward1>)\n",
      "loss: 152653.515625\n",
      "logits: tensor([16973.6133], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1687735.875\n",
      "logits: tensor([18246.2852], grad_fn=<SqueezeBackward1>)\n",
      "loss: 699.9744873046875\n",
      "logits: tensor([17492.7129], grad_fn=<SqueezeBackward1>)\n",
      "loss: 608445.6875\n",
      "logits: tensor([16594.5664], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2816274.0\n",
      "logits: tensor([18077.7598], grad_fn=<SqueezeBackward1>)\n",
      "loss: 38018.14453125\n",
      "logits: tensor([17291.9824], grad_fn=<SqueezeBackward1>)\n",
      "loss: 961889.6875\n",
      "logits: tensor([19943.9922], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2793076.5\n",
      "logits: tensor([19142.3184], grad_fn=<SqueezeBackward1>)\n",
      "loss: 756162.6875\n",
      "logits: tensor([20077.6016], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3257517.25\n",
      "logits: tensor([20446.0215], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4723143.0\n",
      "logits: tensor([17723.6367], grad_fn=<SqueezeBackward1>)\n",
      "loss: 301516.8125\n",
      "logits: tensor([17037.9355], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1524747.5\n",
      "logits: tensor([18701.9941], grad_fn=<SqueezeBackward1>)\n",
      "loss: 184257.234375\n",
      "logits: tensor([17388.4492], grad_fn=<SqueezeBackward1>)\n",
      "loss: 781974.0625\n",
      "logits: tensor([16479.3477], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3216264.0\n",
      "logits: tensor([16790.5781], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2196810.25\n",
      "logits: tensor([16536.8984], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3013153.5\n",
      "logits: tensor([17772.2324], grad_fn=<SqueezeBackward1>)\n",
      "loss: 250510.03125\n",
      "logits: tensor([18483.0762], grad_fn=<SqueezeBackward1>)\n",
      "loss: 44240.38671875\n",
      "logits: tensor([19356.9199], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1175441.375\n",
      "logits: tensor([19756.7266], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2202209.75\n",
      "logits: tensor([20689.6602], grad_fn=<SqueezeBackward1>)\n",
      "loss: 5841492.5\n",
      "logits: tensor([20461.1953], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4789327.0\n",
      "logits: tensor([18332.9414], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3623.946044921875\n",
      "logits: tensor([17148.7402], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1263380.375\n",
      "logits: tensor([17109.5273], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1353068.75\n",
      "logits: tensor([15855.6826], grad_fn=<SqueezeBackward1>)\n",
      "loss: 5842177.0\n",
      "logits: tensor([17338.2363], grad_fn=<SqueezeBackward1>)\n",
      "loss: 873301.1875\n",
      "logits: tensor([16558.6855], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2937990.25\n",
      "logits: tensor([16904.6172], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1871766.0\n",
      "logits: tensor([17683.7734], grad_fn=<SqueezeBackward1>)\n",
      "loss: 346884.1875\n",
      "logits: tensor([18552.3418], grad_fn=<SqueezeBackward1>)\n",
      "loss: 78175.9453125\n",
      "Training, Epoch: 1, Batch 350: Loss = 78175.9453125\n",
      "logits: tensor([19634.6328], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1854746.125\n",
      "logits: tensor([20432.1094], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4662866.5\n",
      "logits: tensor([20057.2773], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3184565.75\n",
      "logits: tensor([20867.0137], grad_fn=<SqueezeBackward1>)\n",
      "loss: 6730244.5\n",
      "logits: tensor([18520.8320], grad_fn=<SqueezeBackward1>)\n",
      "loss: 61548.5703125\n",
      "logits: tensor([17727.1133], grad_fn=<SqueezeBackward1>)\n",
      "loss: 297710.90625\n",
      "logits: tensor([16265.6934], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4028245.0\n",
      "logits: tensor([15786.5498], grad_fn=<SqueezeBackward1>)\n",
      "loss: 6181152.5\n",
      "logits: tensor([16690.9844], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2501957.75\n",
      "logits: tensor([16534.5508], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3021309.25\n",
      "logits: tensor([17475.2070], grad_fn=<SqueezeBackward1>)\n",
      "loss: 636062.3125\n",
      "logits: tensor([18309.3242], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1338.2449951171875\n",
      "logits: tensor([17719.2461], grad_fn=<SqueezeBackward1>)\n",
      "loss: 306357.9375\n",
      "logits: tensor([18797.9492], grad_fn=<SqueezeBackward1>)\n",
      "loss: 275842.4375\n",
      "logits: tensor([19701.3320], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2040869.0\n",
      "logits: tensor([19135.7598], grad_fn=<SqueezeBackward1>)\n",
      "loss: 744799.3125\n",
      "logits: tensor([20528.2109], grad_fn=<SqueezeBackward1>)\n",
      "loss: 5087139.5\n",
      "logits: tensor([20502.1543], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4970278.5\n",
      "logits: tensor([19013.8691], grad_fn=<SqueezeBackward1>)\n",
      "loss: 549269.1875\n",
      "logits: tensor([16771.9297], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2252438.25\n",
      "logits: tensor([17308.2695], grad_fn=<SqueezeBackward1>)\n",
      "loss: 930207.5\n",
      "logits: tensor([16252.6455], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4080790.5\n",
      "logits: tensor([17096.3496], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1383899.5\n",
      "logits: tensor([15839.7578], grad_fn=<SqueezeBackward1>)\n",
      "loss: 5919413.0\n",
      "logits: tensor([18612.2070], grad_fn=<SqueezeBackward1>)\n",
      "loss: 115236.3828125\n",
      "logits: tensor([19635.4551], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1856986.375\n",
      "logits: tensor([18390.5195], grad_fn=<SqueezeBackward1>)\n",
      "loss: 13871.5029296875\n",
      "logits: tensor([18292.1816], grad_fn=<SqueezeBackward1>)\n",
      "loss: 377.892333984375\n",
      "logits: tensor([19422.1641], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1321170.625\n",
      "logits: tensor([19534.8867], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1593008.875\n",
      "logits: tensor([19455.3398], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1398537.25\n",
      "logits: tensor([17975.9531], grad_fn=<SqueezeBackward1>)\n",
      "loss: 88083.75\n",
      "logits: tensor([16069.5654], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4853988.0\n",
      "logits: tensor([15896.2373], grad_fn=<SqueezeBackward1>)\n",
      "loss: 5647775.5\n",
      "logits: tensor([18919.7188], grad_fn=<SqueezeBackward1>)\n",
      "loss: 418578.6875\n",
      "logits: tensor([18416.0469], grad_fn=<SqueezeBackward1>)\n",
      "loss: 20536.234375\n",
      "logits: tensor([18475.0898], grad_fn=<SqueezeBackward1>)\n",
      "loss: 40944.57421875\n",
      "logits: tensor([17772.0879], grad_fn=<SqueezeBackward1>)\n",
      "loss: 250654.71875\n",
      "logits: tensor([19185.2207], grad_fn=<SqueezeBackward1>)\n",
      "loss: 832617.0625\n",
      "logits: tensor([18078.8926], grad_fn=<SqueezeBackward1>)\n",
      "loss: 37577.671875\n",
      "logits: tensor([20356.7422], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4343056.0\n",
      "logits: tensor([17649.9121], grad_fn=<SqueezeBackward1>)\n",
      "loss: 387917.3125\n",
      "logits: tensor([18563.7109], grad_fn=<SqueezeBackward1>)\n",
      "loss: 84662.8125\n",
      "logits: tensor([17319.3672], grad_fn=<SqueezeBackward1>)\n",
      "loss: 908923.875\n",
      "logits: tensor([18401.9160], grad_fn=<SqueezeBackward1>)\n",
      "loss: 16685.876953125\n",
      "logits: tensor([17679.9355], grad_fn=<SqueezeBackward1>)\n",
      "loss: 351419.71875\n",
      "logits: tensor([17965.9629], grad_fn=<SqueezeBackward1>)\n",
      "loss: 94113.5390625\n",
      "logits: tensor([17434.3828], grad_fn=<SqueezeBackward1>)\n",
      "loss: 702846.4375\n",
      "logits: tensor([17627.7754], grad_fn=<SqueezeBackward1>)\n",
      "loss: 415982.15625\n",
      "logits: tensor([16363.8193], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3643986.5\n",
      "Training, Epoch: 1, Batch 400: Loss = 3643986.5\n",
      "logits: tensor([18700.5723], grad_fn=<SqueezeBackward1>)\n",
      "loss: 183038.578125\n",
      "logits: tensor([19768.6934], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2237870.0\n",
      "logits: tensor([18842.8301], grad_fn=<SqueezeBackward1>)\n",
      "loss: 325000.1875\n",
      "logits: tensor([20784.0703], grad_fn=<SqueezeBackward1>)\n",
      "loss: 6306769.0\n",
      "logits: tensor([19445.4395], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1375218.875\n",
      "logits: tensor([18685.3496], grad_fn=<SqueezeBackward1>)\n",
      "loss: 170244.890625\n",
      "logits: tensor([16345.4248], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3714552.25\n",
      "logits: tensor([14947.3516], grad_fn=<SqueezeBackward1>)\n",
      "loss: 11058223.0\n",
      "logits: tensor([16998.9336], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1622588.375\n",
      "logits: tensor([17595.7461], grad_fn=<SqueezeBackward1>)\n",
      "loss: 458323.71875\n",
      "logits: tensor([18313.1074], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1629.3521728515625\n",
      "logits: tensor([19745.1211], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2167899.75\n",
      "logits: tensor([19710.0254], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2065783.0\n",
      "logits: tensor([19036.3066], grad_fn=<SqueezeBackward1>)\n",
      "loss: 583030.6875\n",
      "logits: tensor([18780.8887], grad_fn=<SqueezeBackward1>)\n",
      "loss: 258212.84375\n",
      "logits: tensor([18081.0879], grad_fn=<SqueezeBackward1>)\n",
      "loss: 36731.37109375\n",
      "logits: tensor([18419.8027], grad_fn=<SqueezeBackward1>)\n",
      "loss: 21626.8046875\n",
      "logits: tensor([18215.4531], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3282.03662109375\n",
      "logits: tensor([16527.9023], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3044466.0\n",
      "logits: tensor([17757.7227], grad_fn=<SqueezeBackward1>)\n",
      "loss: 265245.125\n",
      "logits: tensor([15816.9746], grad_fn=<SqueezeBackward1>)\n",
      "loss: 6030794.5\n",
      "logits: tensor([18440.5586], grad_fn=<SqueezeBackward1>)\n",
      "loss: 28162.345703125\n",
      "logits: tensor([17870.5352], grad_fn=<SqueezeBackward1>)\n",
      "loss: 161770.5\n",
      "logits: tensor([17680.2891], grad_fn=<SqueezeBackward1>)\n",
      "loss: 351000.71875\n",
      "logits: tensor([20952.6367], grad_fn=<SqueezeBackward1>)\n",
      "loss: 7181834.5\n",
      "logits: tensor([17813.8574], grad_fn=<SqueezeBackward1>)\n",
      "loss: 210575.234375\n",
      "logits: tensor([19071.0898], grad_fn=<SqueezeBackward1>)\n",
      "loss: 637359.0\n",
      "logits: tensor([18200.4492], grad_fn=<SqueezeBackward1>)\n",
      "loss: 5226.2734375\n",
      "logits: tensor([19766.8242], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2232281.0\n",
      "logits: tensor([18309.3691], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1341.53369140625\n",
      "logits: tensor([19017.4043], grad_fn=<SqueezeBackward1>)\n",
      "loss: 554521.6875\n",
      "logits: tensor([17186.1582], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1180664.75\n",
      "logits: tensor([16626.1055], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2711412.5\n",
      "logits: tensor([16509.7832], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3108024.5\n",
      "logits: tensor([17552.2285], grad_fn=<SqueezeBackward1>)\n",
      "loss: 519139.9375\n",
      "logits: tensor([16823.3848], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2100637.0\n",
      "logits: tensor([20121.4980], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3417898.25\n",
      "logits: tensor([18509.2246], grad_fn=<SqueezeBackward1>)\n",
      "loss: 55923.9375\n",
      "logits: tensor([19379.3457], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1224571.375\n",
      "logits: tensor([19870.8223], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2553860.0\n",
      "logits: tensor([20211.3984], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3758388.0\n",
      "logits: tensor([15361.5908], grad_fn=<SqueezeBackward1>)\n",
      "loss: 8474802.0\n",
      "logits: tensor([16719.1387], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2413684.0\n",
      "logits: tensor([17751.4648], grad_fn=<SqueezeBackward1>)\n",
      "loss: 271730.0625\n",
      "logits: tensor([17938.2148], grad_fn=<SqueezeBackward1>)\n",
      "loss: 111908.546875\n",
      "logits: tensor([17473.1250], grad_fn=<SqueezeBackward1>)\n",
      "loss: 639387.625\n",
      "logits: tensor([19706.1543], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2054670.25\n",
      "logits: tensor([17996.5684], grad_fn=<SqueezeBackward1>)\n",
      "loss: 76271.984375\n",
      "logits: tensor([19067.9785], grad_fn=<SqueezeBackward1>)\n",
      "loss: 632400.8125\n",
      "logits: tensor([19770.6895], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2243846.0\n",
      "Training, Epoch: 1, Batch 450: Loss = 2243846.0\n",
      "logits: tensor([18463.8750], grad_fn=<SqueezeBackward1>)\n",
      "loss: 36531.75390625\n",
      "logits: tensor([17516.4824], grad_fn=<SqueezeBackward1>)\n",
      "loss: 571928.8125\n",
      "logits: tensor([17663.1289], grad_fn=<SqueezeBackward1>)\n",
      "loss: 371628.34375\n",
      "logits: tensor([15947.4854], grad_fn=<SqueezeBackward1>)\n",
      "loss: 5406819.5\n",
      "logits: tensor([16649.2246], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2635809.25\n",
      "logits: tensor([19092.2949], grad_fn=<SqueezeBackward1>)\n",
      "loss: 671666.6875\n",
      "logits: tensor([18394.9824], grad_fn=<SqueezeBackward1>)\n",
      "loss: 14942.6748046875\n",
      "logits: tensor([20672.5469], grad_fn=<SqueezeBackward1>)\n",
      "loss: 5759062.5\n",
      "logits: tensor([19325.2910], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1107859.0\n",
      "logits: tensor([17944.1895], grad_fn=<SqueezeBackward1>)\n",
      "loss: 107946.8984375\n",
      "logits: tensor([18223.0488], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2469.429931640625\n",
      "logits: tensor([19050.0801], grad_fn=<SqueezeBackward1>)\n",
      "loss: 604254.1875\n",
      "logits: tensor([18817.7324], grad_fn=<SqueezeBackward1>)\n",
      "loss: 297014.34375\n",
      "logits: tensor([18315.5020], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1828.3975830078125\n",
      "logits: tensor([16705.5781], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2456003.25\n",
      "logits: tensor([16164.1191], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4446291.0\n",
      "logits: tensor([18069.6934], grad_fn=<SqueezeBackward1>)\n",
      "loss: 41228.828125\n",
      "logits: tensor([18083.7285], grad_fn=<SqueezeBackward1>)\n",
      "loss: 35726.16796875\n",
      "logits: tensor([17215.7246], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1117286.125\n",
      "logits: tensor([18250.], grad_fn=<SqueezeBackward1>)\n",
      "loss: 517.2070922851562\n",
      "logits: tensor([18169.1719], grad_fn=<SqueezeBackward1>)\n",
      "loss: 10726.8095703125\n",
      "logits: tensor([19072.7832], grad_fn=<SqueezeBackward1>)\n",
      "loss: 640065.625\n",
      "logits: tensor([19175.2715], grad_fn=<SqueezeBackward1>)\n",
      "loss: 814559.125\n",
      "logits: tensor([20628.2227], grad_fn=<SqueezeBackward1>)\n",
      "loss: 5548288.0\n",
      "logits: tensor([18515.8984], grad_fn=<SqueezeBackward1>)\n",
      "loss: 59124.9609375\n",
      "logits: tensor([17818.1758], grad_fn=<SqueezeBackward1>)\n",
      "loss: 206630.625\n",
      "logits: tensor([17705.5566], grad_fn=<SqueezeBackward1>)\n",
      "loss: 321699.4375\n",
      "logits: tensor([15640.3223], grad_fn=<SqueezeBackward1>)\n",
      "loss: 6929634.5\n",
      "logits: tensor([18231.4062], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1708.65966796875\n",
      "logits: tensor([16600.9473], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2794898.25\n",
      "logits: tensor([18454.2441], grad_fn=<SqueezeBackward1>)\n",
      "loss: 32942.9609375\n",
      "logits: tensor([17774.3711], grad_fn=<SqueezeBackward1>)\n",
      "loss: 248373.75\n",
      "logits: tensor([18919.8457], grad_fn=<SqueezeBackward1>)\n",
      "loss: 418742.96875\n",
      "logits: tensor([19947.4570], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2804669.75\n",
      "logits: tensor([19478.1738], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1453065.5\n",
      "logits: tensor([18140.6445], grad_fn=<SqueezeBackward1>)\n",
      "loss: 17449.791015625\n",
      "logits: tensor([19735.8672], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2140734.75\n",
      "logits: tensor([18099.1270], grad_fn=<SqueezeBackward1>)\n",
      "loss: 30142.25\n",
      "logits: tensor([16976.0312], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1681459.25\n",
      "logits: tensor([15893.0957], grad_fn=<SqueezeBackward1>)\n",
      "loss: 5662717.5\n",
      "logits: tensor([17638.9160], grad_fn=<SqueezeBackward1>)\n",
      "loss: 401735.625\n",
      "logits: tensor([18667.4258], grad_fn=<SqueezeBackward1>)\n",
      "loss: 155775.140625\n",
      "logits: tensor([18913.7266], grad_fn=<SqueezeBackward1>)\n",
      "loss: 410860.96875\n",
      "logits: tensor([17971.8359], grad_fn=<SqueezeBackward1>)\n",
      "loss: 90544.5703125\n",
      "logits: tensor([18847.2207], grad_fn=<SqueezeBackward1>)\n",
      "loss: 330025.5625\n",
      "logits: tensor([17644.2031], grad_fn=<SqueezeBackward1>)\n",
      "loss: 395061.34375\n",
      "logits: tensor([18845.2305], grad_fn=<SqueezeBackward1>)\n",
      "loss: 327742.84375\n",
      "logits: tensor([19038.3809], grad_fn=<SqueezeBackward1>)\n",
      "loss: 586202.5625\n",
      "logits: tensor([19964.7383], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2862850.75\n",
      "logits: tensor([17333.9258], grad_fn=<SqueezeBackward1>)\n",
      "loss: 881376.25\n",
      "Training, Epoch: 1, Batch 500: Loss = 881376.25\n",
      "logits: tensor([16444.0957], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3343948.0\n",
      "logits: tensor([17708.1836], grad_fn=<SqueezeBackward1>)\n",
      "loss: 318726.40625\n",
      "logits: tensor([17722.1074], grad_fn=<SqueezeBackward1>)\n",
      "loss: 303198.65625\n",
      "logits: tensor([18673.0215], grad_fn=<SqueezeBackward1>)\n",
      "loss: 160223.515625\n",
      "logits: tensor([18721.2090], grad_fn=<SqueezeBackward1>)\n",
      "loss: 201122.46875\n",
      "logits: tensor([19080.8418], grad_fn=<SqueezeBackward1>)\n",
      "loss: 653025.0\n",
      "logits: tensor([17766.6406], grad_fn=<SqueezeBackward1>)\n",
      "loss: 256138.796875\n",
      "logits: tensor([19064.9258], grad_fn=<SqueezeBackward1>)\n",
      "loss: 627554.875\n",
      "logits: tensor([18336.7129], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4092.2509765625\n",
      "logits: tensor([16588.2109], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2837645.5\n",
      "logits: tensor([17588.0391], grad_fn=<SqueezeBackward1>)\n",
      "loss: 468818.375\n",
      "logits: tensor([18827.4883], grad_fn=<SqueezeBackward1>)\n",
      "loss: 307743.21875\n",
      "logits: tensor([18463.0801], grad_fn=<SqueezeBackward1>)\n",
      "loss: 36228.51171875\n",
      "logits: tensor([18926.8633], grad_fn=<SqueezeBackward1>)\n",
      "loss: 427874.40625\n",
      "logits: tensor([18621.3535], grad_fn=<SqueezeBackward1>)\n",
      "loss: 121529.859375\n",
      "logits: tensor([19887.6387], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2607890.75\n",
      "logits: tensor([17681.6152], grad_fn=<SqueezeBackward1>)\n",
      "loss: 349431.0625\n",
      "logits: tensor([16908.4453], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1861306.0\n",
      "logits: tensor([18457.4141], grad_fn=<SqueezeBackward1>)\n",
      "loss: 34103.703125\n",
      "logits: tensor([17740.6777], grad_fn=<SqueezeBackward1>)\n",
      "loss: 283092.59375\n",
      "logits: tensor([17355.3711], grad_fn=<SqueezeBackward1>)\n",
      "loss: 841569.75\n",
      "logits: tensor([17731.0762], grad_fn=<SqueezeBackward1>)\n",
      "loss: 293402.0625\n",
      "logits: tensor([19347.8984], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1155961.0\n",
      "logits: tensor([18351.0312], grad_fn=<SqueezeBackward1>)\n",
      "loss: 6129.17724609375\n",
      "logits: tensor([17944.0020], grad_fn=<SqueezeBackward1>)\n",
      "loss: 108070.140625\n",
      "logits: tensor([18869.9277], grad_fn=<SqueezeBackward1>)\n",
      "loss: 356630.5625\n",
      "logits: tensor([18494.2305], grad_fn=<SqueezeBackward1>)\n",
      "loss: 49057.05859375\n",
      "logits: tensor([19629.5273], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1840866.0\n",
      "logits: tensor([17526.2891], grad_fn=<SqueezeBackward1>)\n",
      "loss: 557192.25\n",
      "logits: tensor([18883.4609], grad_fn=<SqueezeBackward1>)\n",
      "loss: 372977.40625\n",
      "logits: tensor([16474.0234], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3235389.25\n",
      "logits: tensor([17220.2266], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1107789.125\n",
      "logits: tensor([18147.1738], grad_fn=<SqueezeBackward1>)\n",
      "loss: 15767.4130859375\n",
      "logits: tensor([18087.8457], grad_fn=<SqueezeBackward1>)\n",
      "loss: 34186.7109375\n",
      "logits: tensor([18611.9531], grad_fn=<SqueezeBackward1>)\n",
      "loss: 115064.0625\n",
      "logits: tensor([17808.1035], grad_fn=<SqueezeBackward1>)\n",
      "loss: 215889.09375\n",
      "logits: tensor([19070.3145], grad_fn=<SqueezeBackward1>)\n",
      "loss: 636121.5\n",
      "logits: tensor([18931.1055])\n",
      "loss: 433442.21875\n",
      "Testing, Epoch: 1, Batch 0: Loss = 433442.21875\n",
      "logits: tensor([19139.3691])\n",
      "loss: 751042.25\n",
      "logits: tensor([19244.9434])\n",
      "loss: 945175.125\n",
      "logits: tensor([20044.0391])\n",
      "loss: 3137492.5\n",
      "logits: tensor([18291.2402])\n",
      "loss: 342.177734375\n",
      "logits: tensor([18312.3574])\n",
      "loss: 1569.3668212890625\n",
      "logits: tensor([18438.4316])\n",
      "loss: 27452.994140625\n",
      "logits: tensor([19570.1641])\n",
      "loss: 1683303.5\n",
      "logits: tensor([18083.8691])\n",
      "loss: 35673.02734375\n",
      "logits: tensor([18999.6191])\n",
      "loss: 528350.125\n",
      "logits: tensor([20034.8652])\n",
      "loss: 3105077.75\n",
      "logits: tensor([19794.1738])\n",
      "loss: 2314754.25\n",
      "logits: tensor([19985.4375])\n",
      "loss: 2933325.25\n",
      "logits: tensor([19102.4980])\n",
      "loss: 688494.8125\n",
      "logits: tensor([19584.5137])\n",
      "loss: 1720744.375\n",
      "logits: tensor([18573.8652])\n",
      "loss: 90675.0859375\n",
      "logits: tensor([19514.3477])\n",
      "loss: 1541584.125\n",
      "logits: tensor([19772.0156])\n",
      "loss: 2247820.75\n",
      "logits: tensor([20041.3613])\n",
      "loss: 3128013.75\n",
      "logits: tensor([19778.6465])\n",
      "loss: 2267747.75\n",
      "logits: tensor([18422.3203])\n",
      "loss: 22373.615234375\n",
      "logits: tensor([19379.1816])\n",
      "loss: 1224208.25\n",
      "logits: tensor([20164.9395])\n",
      "loss: 3580410.5\n",
      "logits: tensor([18368.6367])\n",
      "loss: 9195.7607421875\n",
      "logits: tensor([17927.9043])\n",
      "loss: 118913.171875\n",
      "logits: tensor([18740.2695])\n",
      "loss: 218581.8125\n",
      "logits: tensor([18730.0488])\n",
      "loss: 209129.359375\n",
      "logits: tensor([18343.8086])\n",
      "loss: 5050.43408203125\n",
      "logits: tensor([18368.4531])\n",
      "loss: 9160.583984375\n",
      "logits: tensor([18911.7246])\n",
      "loss: 408298.53125\n",
      "logits: tensor([18140.0449])\n",
      "loss: 17608.564453125\n",
      "logits: tensor([19753.5527])\n",
      "loss: 2192800.0\n",
      "logits: tensor([20091.7520])\n",
      "loss: 3308796.5\n",
      "logits: tensor([19321.8574])\n",
      "loss: 1100642.75\n",
      "logits: tensor([20118.3652])\n",
      "loss: 3406324.5\n",
      "logits: tensor([19050.])\n",
      "loss: 604129.6875\n",
      "logits: tensor([18287.0254])\n",
      "loss: 204.0098876953125\n",
      "logits: tensor([18783.0957])\n",
      "loss: 260460.703125\n",
      "logits: tensor([19125.5820])\n",
      "loss: 727335.8125\n",
      "logits: tensor([20072.2246])\n",
      "loss: 3238137.0\n",
      "logits: tensor([18795.2559])\n",
      "loss: 273020.53125\n",
      "logits: tensor([20250.3965])\n",
      "loss: 3911116.5\n",
      "logits: tensor([20048.9180])\n",
      "loss: 3154800.5\n",
      "logits: tensor([20457.9531])\n",
      "loss: 4775147.0\n",
      "logits: tensor([20212.0273])\n",
      "loss: 3760827.0\n",
      "logits: tensor([20596.6367])\n",
      "loss: 5400486.0\n",
      "logits: tensor([19745.7598])\n",
      "loss: 2169780.75\n",
      "logits: tensor([19215.5371])\n",
      "loss: 888862.25\n",
      "logits: tensor([18659.3848])\n",
      "loss: 149492.484375\n",
      "logits: tensor([18985.5703])\n",
      "loss: 508123.9375\n",
      "logits: tensor([17066.4453])\n",
      "loss: 1455152.125\n",
      "Testing, Epoch: 1, Batch 50: Loss = 1455152.125\n",
      "logits: tensor([19745.8652])\n",
      "loss: 2170091.5\n",
      "logits: tensor([20066.1406])\n",
      "loss: 3216278.0\n",
      "logits: tensor([18593.4277])\n",
      "loss: 102839.21875\n",
      "logits: tensor([18876.0723])\n",
      "loss: 364007.1875\n",
      "logits: tensor([18891.3438])\n",
      "loss: 382667.90625\n",
      "logits: tensor([18914.7207])\n",
      "loss: 412136.40625\n",
      "logits: tensor([19879.2598])\n",
      "loss: 2580898.75\n",
      "logits: tensor([19827.3652])\n",
      "loss: 2416852.75\n",
      "logits: tensor([19214.9355])\n",
      "loss: 887728.3125\n",
      "logits: tensor([19366.0430])\n",
      "loss: 1195306.625\n",
      "logits: tensor([18884.6250])\n",
      "loss: 374400.5625\n",
      "logits: tensor([19607.2383])\n",
      "loss: 1780879.875\n",
      "logits: tensor([18704.8594])\n",
      "loss: 186725.265625\n",
      "logits: tensor([19037.0410])\n",
      "loss: 584152.6875\n",
      "logits: tensor([18896.2637])\n",
      "loss: 388779.03125\n",
      "logits: tensor([17186.9980])\n",
      "loss: 1178840.375\n",
      "logits: tensor([17258.9395])\n",
      "loss: 1027796.0\n",
      "logits: tensor([18881.1387])\n",
      "loss: 370146.28125\n",
      "logits: tensor([20113.7715])\n",
      "loss: 3389388.75\n",
      "logits: tensor([20119.6777])\n",
      "loss: 3411171.0\n",
      "logits: tensor([18346.8887])\n",
      "loss: 5497.701171875\n",
      "logits: tensor([17343.7754])\n",
      "loss: 862979.3125\n",
      "logits: tensor([18674.6465])\n",
      "loss: 161527.0625\n",
      "logits: tensor([19752.4082])\n",
      "loss: 2189411.5\n",
      "logits: tensor([18815.9082])\n",
      "loss: 295029.3125\n",
      "logits: tensor([20816.0254])\n",
      "loss: 6468289.5\n",
      "logits: tensor([17747.8926])\n",
      "loss: 275467.125\n",
      "logits: tensor([19874.1426])\n",
      "loss: 2564483.25\n",
      "logits: tensor([19240.1387])\n",
      "loss: 935855.9375\n",
      "logits: tensor([19852.8496])\n",
      "loss: 2496739.5\n",
      "logits: tensor([18968.8691])\n",
      "loss: 484592.75\n",
      "logits: tensor([18694.5820])\n",
      "loss: 177948.859375\n",
      "logits: tensor([18587.9043])\n",
      "loss: 99327.15625\n",
      "logits: tensor([19136.9629])\n",
      "loss: 746877.4375\n",
      "logits: tensor([18980.0215])\n",
      "loss: 500244.0\n",
      "logits: tensor([19118.3691])\n",
      "loss: 715084.9375\n",
      "logits: tensor([20993.3770])\n",
      "loss: 7401853.5\n",
      "logits: tensor([17890.2988])\n",
      "loss: 146262.921875\n",
      "logits: tensor([19591.7461])\n",
      "loss: 1739771.25\n",
      "logits: tensor([19418.7090])\n",
      "loss: 1313239.875\n",
      "logits: tensor([20054.0215])\n",
      "loss: 3172956.0\n",
      "logits: tensor([18795.8359])\n",
      "loss: 273627.0625\n",
      "logits: tensor([18638.6992])\n",
      "loss: 133924.546875\n",
      "logits: tensor([17706.6055])\n",
      "loss: 320510.78125\n",
      "logits: tensor([18561.8496])\n",
      "loss: 83583.1015625\n",
      "logits: tensor([18668.6504])\n",
      "loss: 156743.3125\n",
      "logits: tensor([18576.4512])\n",
      "loss: 92239.1484375\n",
      "logits: tensor([18984.7871])\n",
      "loss: 507007.96875\n",
      "logits: tensor([18540.7871])\n",
      "loss: 71848.078125\n",
      "logits: tensor([18190.8633])\n",
      "loss: 6704.1552734375\n",
      "Testing, Epoch: 1, Batch 100: Loss = 6704.1552734375\n",
      "logits: tensor([18903.9141])\n",
      "loss: 398377.9375\n",
      "logits: tensor([18295.1348])\n",
      "loss: 501.42755126953125\n",
      "logits: tensor([18782.6152])\n",
      "loss: 259970.53125\n",
      "logits: tensor([19487.1914])\n",
      "loss: 1474886.875\n",
      "logits: tensor([20831.8984])\n",
      "loss: 6549280.5\n",
      "logits: tensor([20107.3711])\n",
      "loss: 3365863.25\n",
      "logits: tensor([18499.8965])\n",
      "loss: 51599.07421875\n",
      "logits: tensor([20053.8379])\n",
      "loss: 3172302.0\n",
      "logits: tensor([18574.5781])\n",
      "loss: 91104.9296875\n",
      "logits: tensor([19117.0488])\n",
      "loss: 712853.6875\n",
      "logits: tensor([17527.8984])\n",
      "loss: 554792.1875\n",
      "logits: tensor([18897.5684])\n",
      "loss: 390407.75\n",
      "logits: tensor([18713.4473])\n",
      "loss: 194220.96875\n",
      "logits: tensor([19229.3496])\n",
      "loss: 915097.75\n",
      "logits: tensor([18957.9258])\n",
      "loss: 469476.5625\n",
      "logits: tensor([17774.5020])\n",
      "loss: 248243.328125\n",
      "logits: tensor([19021.2871])\n",
      "loss: 560319.5\n",
      "logits: tensor([17730.9707])\n",
      "loss: 293516.34375\n",
      "logits: tensor([18813.5547])\n",
      "loss: 292478.15625\n",
      "logits: tensor([19591.7461])\n",
      "loss: 1739771.25\n",
      "logits: tensor([19533.2480])\n",
      "loss: 1588875.0\n",
      "logits: tensor([19158.2324])\n",
      "loss: 784092.9375\n",
      "logits: tensor([18550.1543])\n",
      "loss: 76957.4765625\n",
      "logits: tensor([19281.3809])\n",
      "loss: 1017352.0\n",
      "logits: tensor([20337.9648])\n",
      "loss: 4265144.5\n",
      "logits: tensor([17381.6172])\n",
      "loss: 794103.75\n",
      "logits: tensor([18116.5215])\n",
      "loss: 24404.908203125\n",
      "logits: tensor([18966.1133])\n",
      "loss: 480763.46875\n",
      "logits: tensor([19365.4570])\n",
      "loss: 1194025.75\n",
      "logits: tensor([20010.3535])\n",
      "loss: 3019293.25\n",
      "logits: tensor([19117.4531])\n",
      "loss: 713536.5625\n",
      "logits: tensor([19454.7891])\n",
      "loss: 1397234.875\n",
      "logits: tensor([19423.0762])\n",
      "loss: 1323268.25\n"
     ]
    }
   ],
   "source": [
    "train_losses, test_losses = main(epochs=epochs, train_dl=train_dataloader, test_dl=test_dataloader, model=nn_model, optimizer=optimizer, criterion=loss_fn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Curve Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=0<br>index=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "0",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "0",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537
         ],
         "xaxis": "x",
         "y": [
          0.9978857636451721,
          0.9899378418922424,
          0.9810359477996826,
          0.9630537629127502,
          0.9368183612823486,
          0.9084394574165344,
          0.8522977828979492,
          0.8010545969009399,
          0.7193020582199097,
          0.6142679452896118,
          0.42846521735191345,
          0.2988729178905487,
          0.20043323934078217,
          0.03640583157539368,
          0.3244229853153229,
          0.3386828303337097,
          0.4051331877708435,
          0.3377091884613037,
          0.2080158293247223,
          0.3055729866027832,
          0.2024170607328415,
          0.05403508245944977,
          0.0029161006677895784,
          0.100827157497406,
          0.15771473944187164,
          0.20488274097442627,
          0.2221822440624237,
          0.2968864142894745,
          0.18216565251350403,
          0.2504116892814636,
          0.28136977553367615,
          0.05069367587566376,
          0.19283969700336456,
          0.045805610716342926,
          0.06376525014638901,
          0.022645367309451103,
          0.27797412872314453,
          0.18623346090316772,
          0.20378704369068146,
          0.0009794087382033467,
          0.2049660086631775,
          0.13434681296348572,
          0.04918314516544342,
          0.02770509384572506,
          0.05618501454591751,
          0.03809657692909241,
          0.19667834043502808,
          0.2792930006980896,
          0.14202795922756195,
          0.15518023073673248,
          0.09007973968982697,
          0.02880443073809147,
          0.04191427305340767,
          0.12628932297229767,
          0.08992582559585571,
          0.07289225608110428,
          0.09795263409614563,
          0.05359620228409767,
          0.07277703285217285,
          0.010479236021637917,
          0.14322081208229065,
          0.10939648002386093,
          0.024518568068742752,
          0.04513072595000267,
          0.018770059570670128,
          0.018359078094363213,
          0.19836923480033875,
          0.07694382220506668,
          0.08096930384635925,
          0.09678766876459122,
          0.023039354011416435,
          0.09749644249677658,
          0.014364911243319511,
          0.07650429755449295,
          0.08962012827396393,
          0.042000848799943924,
          0.08976966142654419,
          0.014096410945057869,
          0.09570169448852539,
          0.05095255747437477,
          0.0894193947315216,
          0.12299735844135284,
          0.2269788682460785,
          0.17738495767116547,
          0.04917694628238678,
          0.008160741999745369,
          0.023204175755381584,
          0.06728067249059677,
          0.08333493769168854,
          0.01937856897711754,
          0.003951839171350002,
          0.10882949084043503,
          0.05902266129851341,
          0.08748301863670349,
          0.11033821105957031,
          0.04205162078142166,
          0.024230079725384712,
          0.011414927430450916,
          0.06999315321445465,
          0.03268401324748993,
          0.009173606522381306,
          0.03361671417951584,
          0.04533872753381729,
          0.11028727889060974,
          0.06570194661617279,
          0.0017525249859318137,
          0.14037825167179108,
          0.0989994928240776,
          0.01597655937075615,
          0.09762021899223328,
          0.04470948129892349,
          0.04245629534125328,
          0.019475838169455528,
          0.05715491250157356,
          0.012946410104632378,
          0.02526913210749626,
          0.0064703188836574554,
          0.01422392763197422,
          0.034116409718990326,
          0.12541760504245758,
          0.059082090854644775,
          0.0007177485385909677,
          0.11186151206493378,
          0.004019071348011494,
          0.0000037410572986118495,
          0.06973950564861298,
          0.09701523184776306,
          0.0481901615858078,
          0.0013262582942843437,
          0.05667562782764435,
          0.008192595094442368,
          0.07061876356601715,
          0.06757792085409164,
          0.0255912896245718,
          0.0012396795209497213,
          0.1566387116909027,
          0.014378593303263187,
          0.00871709082275629,
          0.0698811337351799,
          0.0051344409584999084,
          0.01279484387487173,
          0.059986893087625504,
          0.050202421844005585,
          0.0679887980222702,
          0.09471245110034943,
          0.005129844415932894,
          0.0650564506649971,
          0.004015757702291012,
          0.03251470625400543,
          0.11318360269069672,
          0.06734277307987213,
          0.050952665507793427,
          0.12263832241296768,
          0.042479705065488815,
          0.007191167213022709,
          0.11952944844961166,
          0.11985823512077332,
          0.1823616772890091,
          0.12409001588821411,
          0.013585489243268967,
          0.022605499252676964,
          0.03725740313529968,
          0.1290266066789627,
          0.18866392970085144,
          0.17104102671146393,
          0.1535046100616455,
          0.04027451202273369,
          0.08375681936740875,
          0.03403966501355171,
          0.16713601350784302,
          0.03249942138791084,
          0.026485081762075424,
          0.033016327768564224,
          0.0795769914984703,
          0.010388809256255627,
          0.015083194710314274,
          0.017252473160624504,
          0.021557575091719627,
          0.00467813853174448,
          0.0008155505056492984,
          0.020138325169682503,
          0.10036871582269669,
          0.022208305075764656,
          0.0230068601667881,
          0.033017609268426895,
          0.06008918210864067,
          0.03427909314632416,
          0.03581218048930168,
          0.09467632323503494,
          0.015281257219612598,
          0.009787460789084435,
          0.03416408225893974,
          0.07686034590005875,
          0.08015953004360199,
          0.03582308068871498,
          0.017667623236775398,
          0.04047214612364769,
          0.015478463843464851,
          0.020204273983836174,
          0.09254894405603409,
          0.10648620128631592,
          0.08301406353712082,
          0.0032704323530197144,
          0.018230706453323364,
          0.02620760351419449,
          0.03723965957760811,
          0.04735890030860901,
          0.01876225695014,
          0.025210771709680557,
          0.005290603265166283,
          0.04044703021645546,
          0.02616591565310955,
          0.06546037644147873,
          0.001146580558270216,
          0.007530000060796738,
          0.027796268463134766,
          0.042045313864946365,
          0.0013934903545305133,
          0.0036009280011057854,
          0.011372493579983711,
          0.037580523639917374,
          0.009569411166012287,
          0.045436955988407135,
          0.026962440460920334,
          0.013367759995162487,
          0.039947863668203354,
          0.027018021792173386,
          0.09548161178827286,
          0.03892313688993454,
          0.021804699674248695,
          0.02044113725423813,
          0.005722534842789173,
          0.10336659103631973,
          0.06046852469444275,
          0.012997501529753208,
          0.04039251431822777,
          0.0004626084410119802,
          0.10840509831905365,
          0.075444296002388,
          0.02912990190088749,
          0.08089672774076462,
          0.041364122182130814,
          0.04563972353935242,
          0.04214450716972351,
          0.025790100917220116,
          0.1616954356431961,
          0.005458309315145016,
          0.003807220607995987,
          0.11311744153499603,
          0.005817237310111523,
          0.043184734880924225,
          0.012714464217424393,
          0.022121833637356758,
          0.007441390305757523,
          0.010522953234612942,
          0.011387350969016552,
          0.0018991744145751,
          0.025631051510572433,
          0.008729810826480389,
          0.07862067222595215,
          0.04288598522543907,
          0.07507532089948654,
          0.05448411777615547,
          0.0692235603928566,
          0.0263516865670681,
          0.022081537172198296,
          0.0055842227302491665,
          0.06942461431026459,
          0.08185454457998276,
          0.05335228517651558,
          0.050311874598264694,
          0.012447566725313663,
          0.06099259480834007,
          0.11819089949131012,
          0.08950351178646088,
          0.1663770079612732,
          0.05550232529640198,
          0.05319003015756607,
          0.07428243011236191,
          0.02793244458734989,
          0.06209246441721916,
          0.00565049285069108,
          0.008579954504966736,
          0.11231295019388199,
          0.05091824755072594,
          0.016006166115403175,
          0.05793016403913498,
          0.025923175737261772,
          0.005174523685127497,
          0.08084916323423386,
          0.04631182923913002,
          0.052704229950904846,
          0.03124135546386242,
          0.07570403814315796,
          0.05210929363965988,
          0.01821114681661129,
          0.013313781470060349,
          0.09163441509008408,
          0.0249392781406641,
          0.013867564499378204,
          0.07632975280284882,
          0.011570234782993793,
          0.04772776737809181,
          0.03355375677347183,
          0.021205702796578407,
          0.023285944014787674,
          0.013705951161682606,
          0.04860306903719902,
          0.05778052285313606,
          0.0019984727259725332,
          0.07048718631267548,
          0.054153941571712494,
          0.0020398381166160107,
          0.08423823863267899,
          0.029108203947544098,
          0.00011212482786504552,
          0.0329822301864624,
          0.060578618198633194,
          0.02138206548988819,
          0.07109654694795609,
          0.0014478960074484348,
          0.04268813505768776,
          0.09184039384126663,
          0.010670671239495277,
          0.05367337539792061,
          0.09146136790513992,
          0.04758870601654053,
          0.09877331554889679,
          0.11893558502197266,
          0.030050523579120636,
          0.06757643073797226,
          0.023491380736231804,
          0.0483941026031971,
          0.09814588725566864,
          0.08111339062452316,
          0.09499634802341461,
          0.027391059324145317,
          0.01151080522686243,
          0.059333059936761856,
          0.08121301233768463,
          0.13226903975009918,
          0.1197659969329834,
          0.00329448189586401,
          0.06151249632239342,
          0.0636584684252739,
          0.13227678835391998,
          0.051142070442438126,
          0.0938040167093277,
          0.0748724490404129,
          0.032232094556093216,
          0.015301458537578583,
          0.07453126460313797,
          0.1181742250919342,
          0.09766104817390442,
          0.14197494089603424,
          0.013577044941484928,
          0.02986026369035244,
          0.10983840376138687,
          0.13606016337871552,
          0.08656378835439682,
          0.09512482583522797,
          0.04364616796374321,
          0.0020020001102238894,
          0.03029080666601658,
          0.028742650523781776,
          0.07818146795034409,
          0.04722977802157402,
          0.12343351542949677,
          0.12200752645730972,
          0.040559154003858566,
          0.082133948802948,
          0.05278204381465912,
          0.11055246740579605,
          0.06437963992357254,
          0.13314828276634216,
          0.018577663227915764,
          0.07457626610994339,
          0.006445521023124456,
          0.001063849776983261,
          0.06290363520383835,
          0.06907252967357635,
          0.06471922248601913,
          0.016242174431681633,
          0.12057176232337952,
          0.13005737960338593,
          0.035406649112701416,
          0.007842538878321648,
          0.011073742993175983,
          0.02739896811544895,
          0.04993659257888794,
          0.010608676820993423,
          0.11404965817928314,
          0.03408519923686981,
          0.015923649072647095,
          0.05217470973730087,
          0.007069208659231663,
          0.0324421264231205,
          0.01678890362381935,
          0.04588032513856888,
          0.03529665991663933,
          0.10446833074092865,
          0.02341356687247753,
          0.08186791092157364,
          0.031198814511299133,
          0.13743574917316437,
          0.06417740881443024,
          0.02258048765361309,
          0.10547499358654022,
          0.18198640644550323,
          0.0697108581662178,
          0.03704950585961342,
          0.002209040801972151,
          0.08057788759469986,
          0.07865722477436066,
          0.041787076741456985,
          0.027808988466858864,
          0.010488535277545452,
          0.008048082701861858,
          0.003135219682008028,
          0.09548866748809814,
          0.028185125440359116,
          0.13439513742923737,
          0.0091839749366045,
          0.02201131172478199,
          0.032422780990600586,
          0.14666077494621277,
          0.025113075971603394,
          0.04369063302874565,
          0.003956328611820936,
          0.08176561444997787,
          0.0020044585689902306,
          0.04075261950492859,
          0.059464745223522186,
          0.09011437743902206,
          0.09648026525974274,
          0.03943106532096863,
          0.07931800186634064,
          0.10117561370134354,
          0.012941813096404076,
          0.06056034192442894,
          0.08745704591274261,
          0.10609553009271622,
          0.15931661427021027,
          0.08502300828695297,
          0.02852759324014187,
          0.018307451158761978,
          0.043760109692811966,
          0.07844537496566772,
          0.015113978646695614,
          0.04352036118507385,
          0.08197714388370514,
          0.010459995828568935,
          0.04138731583952904,
          0.03336189314723015,
          0.1272527575492859,
          0.08884914964437485,
          0.04485110938549042,
          0.006689758505672216,
          0.13133248686790466,
          0.05760212615132332,
          0.017980482429265976,
          0.002719534793868661,
          0.04254084452986717,
          0.02982531115412712,
          0.0023400848731398582,
          0.08576513081789017,
          0.11539718508720398,
          0.011112116277217865,
          0.010344023816287518,
          0.057846687734127045,
          0.001244596322067082,
          0.005668022204190493,
          0.04378330335021019,
          0.04939211159944534,
          0.12890678644180298,
          0.013307048007845879,
          0.024876747280359268,
          0.031039979308843613,
          0.14406266808509827,
          0.002262163907289505,
          0.09149119257926941,
          0.009932934306561947,
          0.02727401815354824,
          0.03541359677910805,
          0.09165098518133163,
          0.0659688413143158,
          0.007229219190776348,
          0.08007144927978516,
          0.009501323103904724,
          0.07096422463655472,
          0.13022930920124054,
          0.03468697518110275,
          0.021599581465125084,
          0.03507871925830841,
          0.016467493027448654,
          0.03143909573554993,
          0.034397631883621216,
          0.031330179423093796,
          0.04190059006214142,
          0.09259672462940216,
          0.05137797072529793,
          0.10007509589195251,
          0.03089621663093567,
          0.03013421595096588,
          0.021905813366174698,
          0.02454293891787529,
          0.044224321842193604,
          0.02769707702100277,
          0.04335329681634903,
          0.0035008813720196486,
          0.09218820184469223,
          0.037471283227205276,
          0.030359214171767235,
          0.010416492819786072,
          0.03579764440655708,
          0.019078215584158897,
          0.08837734907865524,
          0.03235020488500595,
          0.0746629536151886,
          0.010106412693858147,
          0.029117930680513382,
          0.05020434781908989,
          0.029643390327692032,
          0.0588393472135067,
          0.004284472670406103,
          0.01799074374139309,
          0.032681770622730255,
          0.012121239677071571,
          0.07425186038017273,
          0.04085063561797142,
          0.03342239186167717,
          0.09843726456165314,
          0.05760031193494797,
          0.006871894467622042,
          0.010118705220520496,
          0.0185637678951025,
          0.025427965447306633,
          0.04364819824695587
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "index"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"e233a5d4-b584-4a9b-befc-e4b127a7c6ae\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e233a5d4-b584-4a9b-befc-e4b127a7c6ae\")) {                    Plotly.newPlot(                        \"e233a5d4-b584-4a9b-befc-e4b127a7c6ae\",                        [{\"hovertemplate\":\"variable=0<br>index=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537],\"xaxis\":\"x\",\"y\":[0.9978857636451721,0.9899378418922424,0.9810359477996826,0.9630537629127502,0.9368183612823486,0.9084394574165344,0.8522977828979492,0.8010545969009399,0.7193020582199097,0.6142679452896118,0.42846521735191345,0.2988729178905487,0.20043323934078217,0.03640583157539368,0.3244229853153229,0.3386828303337097,0.4051331877708435,0.3377091884613037,0.2080158293247223,0.3055729866027832,0.2024170607328415,0.05403508245944977,0.0029161006677895784,0.100827157497406,0.15771473944187164,0.20488274097442627,0.2221822440624237,0.2968864142894745,0.18216565251350403,0.2504116892814636,0.28136977553367615,0.05069367587566376,0.19283969700336456,0.045805610716342926,0.06376525014638901,0.022645367309451103,0.27797412872314453,0.18623346090316772,0.20378704369068146,0.0009794087382033467,0.2049660086631775,0.13434681296348572,0.04918314516544342,0.02770509384572506,0.05618501454591751,0.03809657692909241,0.19667834043502808,0.2792930006980896,0.14202795922756195,0.15518023073673248,0.09007973968982697,0.02880443073809147,0.04191427305340767,0.12628932297229767,0.08992582559585571,0.07289225608110428,0.09795263409614563,0.05359620228409767,0.07277703285217285,0.010479236021637917,0.14322081208229065,0.10939648002386093,0.024518568068742752,0.04513072595000267,0.018770059570670128,0.018359078094363213,0.19836923480033875,0.07694382220506668,0.08096930384635925,0.09678766876459122,0.023039354011416435,0.09749644249677658,0.014364911243319511,0.07650429755449295,0.08962012827396393,0.042000848799943924,0.08976966142654419,0.014096410945057869,0.09570169448852539,0.05095255747437477,0.0894193947315216,0.12299735844135284,0.2269788682460785,0.17738495767116547,0.04917694628238678,0.008160741999745369,0.023204175755381584,0.06728067249059677,0.08333493769168854,0.01937856897711754,0.003951839171350002,0.10882949084043503,0.05902266129851341,0.08748301863670349,0.11033821105957031,0.04205162078142166,0.024230079725384712,0.011414927430450916,0.06999315321445465,0.03268401324748993,0.009173606522381306,0.03361671417951584,0.04533872753381729,0.11028727889060974,0.06570194661617279,0.0017525249859318137,0.14037825167179108,0.0989994928240776,0.01597655937075615,0.09762021899223328,0.04470948129892349,0.04245629534125328,0.019475838169455528,0.05715491250157356,0.012946410104632378,0.02526913210749626,0.0064703188836574554,0.01422392763197422,0.034116409718990326,0.12541760504245758,0.059082090854644775,0.0007177485385909677,0.11186151206493378,0.004019071348011494,3.7410572986118495e-06,0.06973950564861298,0.09701523184776306,0.0481901615858078,0.0013262582942843437,0.05667562782764435,0.008192595094442368,0.07061876356601715,0.06757792085409164,0.0255912896245718,0.0012396795209497213,0.1566387116909027,0.014378593303263187,0.00871709082275629,0.0698811337351799,0.0051344409584999084,0.01279484387487173,0.059986893087625504,0.050202421844005585,0.0679887980222702,0.09471245110034943,0.005129844415932894,0.0650564506649971,0.004015757702291012,0.03251470625400543,0.11318360269069672,0.06734277307987213,0.050952665507793427,0.12263832241296768,0.042479705065488815,0.007191167213022709,0.11952944844961166,0.11985823512077332,0.1823616772890091,0.12409001588821411,0.013585489243268967,0.022605499252676964,0.03725740313529968,0.1290266066789627,0.18866392970085144,0.17104102671146393,0.1535046100616455,0.04027451202273369,0.08375681936740875,0.03403966501355171,0.16713601350784302,0.03249942138791084,0.026485081762075424,0.033016327768564224,0.0795769914984703,0.010388809256255627,0.015083194710314274,0.017252473160624504,0.021557575091719627,0.00467813853174448,0.0008155505056492984,0.020138325169682503,0.10036871582269669,0.022208305075764656,0.0230068601667881,0.033017609268426895,0.06008918210864067,0.03427909314632416,0.03581218048930168,0.09467632323503494,0.015281257219612598,0.009787460789084435,0.03416408225893974,0.07686034590005875,0.08015953004360199,0.03582308068871498,0.017667623236775398,0.04047214612364769,0.015478463843464851,0.020204273983836174,0.09254894405603409,0.10648620128631592,0.08301406353712082,0.0032704323530197144,0.018230706453323364,0.02620760351419449,0.03723965957760811,0.04735890030860901,0.01876225695014,0.025210771709680557,0.005290603265166283,0.04044703021645546,0.02616591565310955,0.06546037644147873,0.001146580558270216,0.007530000060796738,0.027796268463134766,0.042045313864946365,0.0013934903545305133,0.0036009280011057854,0.011372493579983711,0.037580523639917374,0.009569411166012287,0.045436955988407135,0.026962440460920334,0.013367759995162487,0.039947863668203354,0.027018021792173386,0.09548161178827286,0.03892313688993454,0.021804699674248695,0.02044113725423813,0.005722534842789173,0.10336659103631973,0.06046852469444275,0.012997501529753208,0.04039251431822777,0.0004626084410119802,0.10840509831905365,0.075444296002388,0.02912990190088749,0.08089672774076462,0.041364122182130814,0.04563972353935242,0.04214450716972351,0.025790100917220116,0.1616954356431961,0.005458309315145016,0.003807220607995987,0.11311744153499603,0.005817237310111523,0.043184734880924225,0.012714464217424393,0.022121833637356758,0.007441390305757523,0.010522953234612942,0.011387350969016552,0.0018991744145751,0.025631051510572433,0.008729810826480389,0.07862067222595215,0.04288598522543907,0.07507532089948654,0.05448411777615547,0.0692235603928566,0.0263516865670681,0.022081537172198296,0.0055842227302491665,0.06942461431026459,0.08185454457998276,0.05335228517651558,0.050311874598264694,0.012447566725313663,0.06099259480834007,0.11819089949131012,0.08950351178646088,0.1663770079612732,0.05550232529640198,0.05319003015756607,0.07428243011236191,0.02793244458734989,0.06209246441721916,0.00565049285069108,0.008579954504966736,0.11231295019388199,0.05091824755072594,0.016006166115403175,0.05793016403913498,0.025923175737261772,0.005174523685127497,0.08084916323423386,0.04631182923913002,0.052704229950904846,0.03124135546386242,0.07570403814315796,0.05210929363965988,0.01821114681661129,0.013313781470060349,0.09163441509008408,0.0249392781406641,0.013867564499378204,0.07632975280284882,0.011570234782993793,0.04772776737809181,0.03355375677347183,0.021205702796578407,0.023285944014787674,0.013705951161682606,0.04860306903719902,0.05778052285313606,0.0019984727259725332,0.07048718631267548,0.054153941571712494,0.0020398381166160107,0.08423823863267899,0.029108203947544098,0.00011212482786504552,0.0329822301864624,0.060578618198633194,0.02138206548988819,0.07109654694795609,0.0014478960074484348,0.04268813505768776,0.09184039384126663,0.010670671239495277,0.05367337539792061,0.09146136790513992,0.04758870601654053,0.09877331554889679,0.11893558502197266,0.030050523579120636,0.06757643073797226,0.023491380736231804,0.0483941026031971,0.09814588725566864,0.08111339062452316,0.09499634802341461,0.027391059324145317,0.01151080522686243,0.059333059936761856,0.08121301233768463,0.13226903975009918,0.1197659969329834,0.00329448189586401,0.06151249632239342,0.0636584684252739,0.13227678835391998,0.051142070442438126,0.0938040167093277,0.0748724490404129,0.032232094556093216,0.015301458537578583,0.07453126460313797,0.1181742250919342,0.09766104817390442,0.14197494089603424,0.013577044941484928,0.02986026369035244,0.10983840376138687,0.13606016337871552,0.08656378835439682,0.09512482583522797,0.04364616796374321,0.0020020001102238894,0.03029080666601658,0.028742650523781776,0.07818146795034409,0.04722977802157402,0.12343351542949677,0.12200752645730972,0.040559154003858566,0.082133948802948,0.05278204381465912,0.11055246740579605,0.06437963992357254,0.13314828276634216,0.018577663227915764,0.07457626610994339,0.006445521023124456,0.001063849776983261,0.06290363520383835,0.06907252967357635,0.06471922248601913,0.016242174431681633,0.12057176232337952,0.13005737960338593,0.035406649112701416,0.007842538878321648,0.011073742993175983,0.02739896811544895,0.04993659257888794,0.010608676820993423,0.11404965817928314,0.03408519923686981,0.015923649072647095,0.05217470973730087,0.007069208659231663,0.0324421264231205,0.01678890362381935,0.04588032513856888,0.03529665991663933,0.10446833074092865,0.02341356687247753,0.08186791092157364,0.031198814511299133,0.13743574917316437,0.06417740881443024,0.02258048765361309,0.10547499358654022,0.18198640644550323,0.0697108581662178,0.03704950585961342,0.002209040801972151,0.08057788759469986,0.07865722477436066,0.041787076741456985,0.027808988466858864,0.010488535277545452,0.008048082701861858,0.003135219682008028,0.09548866748809814,0.028185125440359116,0.13439513742923737,0.0091839749366045,0.02201131172478199,0.032422780990600586,0.14666077494621277,0.025113075971603394,0.04369063302874565,0.003956328611820936,0.08176561444997787,0.0020044585689902306,0.04075261950492859,0.059464745223522186,0.09011437743902206,0.09648026525974274,0.03943106532096863,0.07931800186634064,0.10117561370134354,0.012941813096404076,0.06056034192442894,0.08745704591274261,0.10609553009271622,0.15931661427021027,0.08502300828695297,0.02852759324014187,0.018307451158761978,0.043760109692811966,0.07844537496566772,0.015113978646695614,0.04352036118507385,0.08197714388370514,0.010459995828568935,0.04138731583952904,0.03336189314723015,0.1272527575492859,0.08884914964437485,0.04485110938549042,0.006689758505672216,0.13133248686790466,0.05760212615132332,0.017980482429265976,0.002719534793868661,0.04254084452986717,0.02982531115412712,0.0023400848731398582,0.08576513081789017,0.11539718508720398,0.011112116277217865,0.010344023816287518,0.057846687734127045,0.001244596322067082,0.005668022204190493,0.04378330335021019,0.04939211159944534,0.12890678644180298,0.013307048007845879,0.024876747280359268,0.031039979308843613,0.14406266808509827,0.002262163907289505,0.09149119257926941,0.009932934306561947,0.02727401815354824,0.03541359677910805,0.09165098518133163,0.0659688413143158,0.007229219190776348,0.08007144927978516,0.009501323103904724,0.07096422463655472,0.13022930920124054,0.03468697518110275,0.021599581465125084,0.03507871925830841,0.016467493027448654,0.03143909573554993,0.034397631883621216,0.031330179423093796,0.04190059006214142,0.09259672462940216,0.05137797072529793,0.10007509589195251,0.03089621663093567,0.03013421595096588,0.021905813366174698,0.02454293891787529,0.044224321842193604,0.02769707702100277,0.04335329681634903,0.0035008813720196486,0.09218820184469223,0.037471283227205276,0.030359214171767235,0.010416492819786072,0.03579764440655708,0.019078215584158897,0.08837734907865524,0.03235020488500595,0.0746629536151886,0.010106412693858147,0.029117930680513382,0.05020434781908989,0.029643390327692032,0.0588393472135067,0.004284472670406103,0.01799074374139309,0.032681770622730255,0.012121239677071571,0.07425186038017273,0.04085063561797142,0.03342239186167717,0.09843726456165314,0.05760031193494797,0.006871894467622042,0.010118705220520496,0.0185637678951025,0.025427965447306633,0.04364819824695587],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('e233a5d4-b584-4a9b-befc-e4b127a7c6ae');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "px.line(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=0<br>index=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "0",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "0",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133
         ],
         "xaxis": "x",
         "y": [
          0.03602980077266693,
          0.047427307814359665,
          0.05320499464869499,
          0.09693656861782074,
          0.0010123300598934293,
          0.0021679960191249847,
          0.009067574515938759,
          0.07100313156843185,
          0.010336327366530895,
          0.03977930173277855,
          0.09643451869487762,
          0.0832623615860939,
          0.09372951835393906,
          0.045409489423036575,
          0.07178843021392822,
          0.016479358077049255,
          0.06794850528240204,
          0.08204971998929977,
          0.09679002314805984,
          0.08241260796785355,
          0.008185860700905323,
          0.06055136397480965,
          0.10355299711227417,
          0.005247955210506916,
          0.01887170970439911,
          0.025586051866412163,
          0.025026710703969002,
          0.0038892030715942383,
          0.005237907636910677,
          0.034969158470630646,
          0.00726203341037035,
          0.08103931695222855,
          0.09954771399497986,
          0.0574142187833786,
          0.10100416094064713,
          0.04253646358847618,
          0.000781667185947299,
          0.027929771691560745,
          0.04667278751730919,
          0.09847905486822128,
          0.028595251962542534,
          0.10822974890470505,
          0.0972035676240921,
          0.11958856135606766,
          0.10612994432449341,
          0.12717820703983307,
          0.08061283826828003,
          0.05159569904208183,
          0.021159525960683823,
          0.039010461419820786,
          0.06601618975400925,
          0.08061860501766205,
          0.09814610332250595,
          0.017549941316246986,
          0.03301803767681122,
          0.033853787928819656,
          0.03513312339782715,
          0.08791880309581757,
          0.08507880568504333,
          0.051562778651714325,
          0.05983233079314232,
          0.03348609805107117,
          0.07303206622600555,
          0.023648185655474663,
          0.04182726517319679,
          0.03412303701043129,
          0.05941878631711006,
          0.055481694638729095,
          0.03329530358314514,
          0.10075276345014572,
          0.10107599198818207,
          0.004057764541357756,
          0.05083893612027168,
          0.02199474535882473,
          0.08097667992115021,
          0.02972547896206379,
          0.13918453454971313,
          0.028723089024424553,
          0.08763875812292099,
          0.052942052483558655,
          0.08647347241640091,
          0.03809646889567375,
          0.023085743188858032,
          0.01724766381084919,
          0.047295622527599335,
          0.03870679438114166,
          0.046278055757284164,
          0.14889033138751984,
          0.020929718390107155,
          0.0721842348575592,
          0.06271454691886902,
          0.09748286753892899,
          0.028626997023820877,
          0.020027482882142067,
          0.03098258189857006,
          0.0158217865973711,
          0.021666601300239563,
          0.016620876267552376,
          0.03896760195493698,
          0.014669112861156464,
          0.00448093144223094,
          0.03454171493649483,
          0.0012254634639248252,
          0.027903476729989052,
          0.06646233797073364,
          0.14005321264266968,
          0.10040249675512314,
          0.012431319802999496,
          0.09747281670570374,
          0.016518371179699898,
          0.0462058000266552,
          0.040762558579444885,
          0.03419443964958191,
          0.024118168279528618,
          0.052351608872413635,
          0.03749758005142212,
          0.027266856282949448,
          0.040965110063552856,
          0.02964916080236435,
          0.029596678912639618,
          0.0721842348575592,
          0.06898285448551178,
          0.048459626734256744,
          0.01518174447119236,
          0.05519908666610718,
          0.11302204430103302,
          0.048767995089292526,
          0.008549384772777557,
          0.03794565051794052,
          0.05980026721954346,
          0.09509307891130447,
          0.04622792452573776,
          0.06468907743692398,
          0.06295354664325714
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "index"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"ac605c71-3b5a-499a-9f23-6f5427b803b4\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ac605c71-3b5a-499a-9f23-6f5427b803b4\")) {                    Plotly.newPlot(                        \"ac605c71-3b5a-499a-9f23-6f5427b803b4\",                        [{\"hovertemplate\":\"variable=0<br>index=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133],\"xaxis\":\"x\",\"y\":[0.03602980077266693,0.047427307814359665,0.05320499464869499,0.09693656861782074,0.0010123300598934293,0.0021679960191249847,0.009067574515938759,0.07100313156843185,0.010336327366530895,0.03977930173277855,0.09643451869487762,0.0832623615860939,0.09372951835393906,0.045409489423036575,0.07178843021392822,0.016479358077049255,0.06794850528240204,0.08204971998929977,0.09679002314805984,0.08241260796785355,0.008185860700905323,0.06055136397480965,0.10355299711227417,0.005247955210506916,0.01887170970439911,0.025586051866412163,0.025026710703969002,0.0038892030715942383,0.005237907636910677,0.034969158470630646,0.00726203341037035,0.08103931695222855,0.09954771399497986,0.0574142187833786,0.10100416094064713,0.04253646358847618,0.000781667185947299,0.027929771691560745,0.04667278751730919,0.09847905486822128,0.028595251962542534,0.10822974890470505,0.0972035676240921,0.11958856135606766,0.10612994432449341,0.12717820703983307,0.08061283826828003,0.05159569904208183,0.021159525960683823,0.039010461419820786,0.06601618975400925,0.08061860501766205,0.09814610332250595,0.017549941316246986,0.03301803767681122,0.033853787928819656,0.03513312339782715,0.08791880309581757,0.08507880568504333,0.051562778651714325,0.05983233079314232,0.03348609805107117,0.07303206622600555,0.023648185655474663,0.04182726517319679,0.03412303701043129,0.05941878631711006,0.055481694638729095,0.03329530358314514,0.10075276345014572,0.10107599198818207,0.004057764541357756,0.05083893612027168,0.02199474535882473,0.08097667992115021,0.02972547896206379,0.13918453454971313,0.028723089024424553,0.08763875812292099,0.052942052483558655,0.08647347241640091,0.03809646889567375,0.023085743188858032,0.01724766381084919,0.047295622527599335,0.03870679438114166,0.046278055757284164,0.14889033138751984,0.020929718390107155,0.0721842348575592,0.06271454691886902,0.09748286753892899,0.028626997023820877,0.020027482882142067,0.03098258189857006,0.0158217865973711,0.021666601300239563,0.016620876267552376,0.03896760195493698,0.014669112861156464,0.00448093144223094,0.03454171493649483,0.0012254634639248252,0.027903476729989052,0.06646233797073364,0.14005321264266968,0.10040249675512314,0.012431319802999496,0.09747281670570374,0.016518371179699898,0.0462058000266552,0.040762558579444885,0.03419443964958191,0.024118168279528618,0.052351608872413635,0.03749758005142212,0.027266856282949448,0.040965110063552856,0.02964916080236435,0.029596678912639618,0.0721842348575592,0.06898285448551178,0.048459626734256744,0.01518174447119236,0.05519908666610718,0.11302204430103302,0.048767995089292526,0.008549384772777557,0.03794565051794052,0.05980026721954346,0.09509307891130447,0.04622792452573776,0.06468907743692398,0.06295354664325714],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('ac605c71-3b5a-499a-9f23-6f5427b803b4');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "px.line(test_losses)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=ground_truth<br>vehicle_count=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "ground_truth",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "ground_truth",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0.48670023679733276,
          1.9991343021392822,
          1.2769339084625244,
          1.9991343021392822,
          1.3554339408874512,
          0.4814668893814087,
          1.5700007677078247,
          1.261233925819397,
          0.4814668893814087,
          1.1827338933944702,
          0.2512001097202301,
          0.23550011217594147,
          0.2512001097202301,
          1.2664672136306763,
          0.068033367395401,
          0.9472337961196899,
          1.402534008026123,
          0.08896670490503311,
          0.9681671261787415,
          0.10466671735048294
         ],
         "xaxis": "x",
         "y": [
          18272.7421875,
          18272.7421875,
          18272.7421875,
          18272.7421875,
          18272.7421875,
          18272.7421875,
          18272.7421875,
          18272.7421875,
          18272.7421875,
          18272.7421875,
          18272.7421875,
          18272.7421875,
          18272.7421875,
          18272.7421875,
          18272.7421875,
          18272.7421875,
          18272.7421875,
          18272.7421875,
          18272.7421875,
          18272.7421875
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=predictions<br>vehicle_count=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "predictions",
         "marker": {
          "color": "#EF553B",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "predictions",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0.48670023679733276,
          1.9991343021392822,
          1.2769339084625244,
          1.9991343021392822,
          1.3554339408874512,
          0.4814668893814087,
          1.5700007677078247,
          1.261233925819397,
          0.4814668893814087,
          1.1827338933944702,
          0.2512001097202301,
          0.23550011217594147,
          0.2512001097202301,
          1.2664672136306763,
          0.068033367395401,
          0.9472337961196899,
          1.402534008026123,
          0.08896670490503311,
          0.9681671261787415,
          0.10466671735048294
         ],
         "xaxis": "x",
         "y": [
          20113.771484375,
          18911.724609375,
          20048.91796875,
          18911.724609375,
          18422.3203125,
          18984.787109375,
          18659.384765625,
          20596.63671875,
          18116.521484375,
          20118.365234375,
          19102.498046875,
          18931.10546875,
          19752.408203125,
          20041.361328125,
          17527.8984375,
          19117.453125,
          18343.80859375,
          18815.908203125,
          19418.708984375,
          17927.904296875
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "vehicle_count"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"c9a91f4b-04d5-4256-a5a3-8c51e5121aa1\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c9a91f4b-04d5-4256-a5a3-8c51e5121aa1\")) {                    Plotly.newPlot(                        \"c9a91f4b-04d5-4256-a5a3-8c51e5121aa1\",                        [{\"hovertemplate\":\"variable=ground_truth<br>vehicle_count=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"ground_truth\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"ground_truth\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.48670023679733276,1.9991343021392822,1.2769339084625244,1.9991343021392822,1.3554339408874512,0.4814668893814087,1.5700007677078247,1.261233925819397,0.4814668893814087,1.1827338933944702,0.2512001097202301,0.23550011217594147,0.2512001097202301,1.2664672136306763,0.068033367395401,0.9472337961196899,1.402534008026123,0.08896670490503311,0.9681671261787415,0.10466671735048294],\"xaxis\":\"x\",\"y\":[18272.7421875,18272.7421875,18272.7421875,18272.7421875,18272.7421875,18272.7421875,18272.7421875,18272.7421875,18272.7421875,18272.7421875,18272.7421875,18272.7421875,18272.7421875,18272.7421875,18272.7421875,18272.7421875,18272.7421875,18272.7421875,18272.7421875,18272.7421875],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"variable=predictions<br>vehicle_count=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"predictions\",\"marker\":{\"color\":\"#EF553B\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"predictions\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.48670023679733276,1.9991343021392822,1.2769339084625244,1.9991343021392822,1.3554339408874512,0.4814668893814087,1.5700007677078247,1.261233925819397,0.4814668893814087,1.1827338933944702,0.2512001097202301,0.23550011217594147,0.2512001097202301,1.2664672136306763,0.068033367395401,0.9472337961196899,1.402534008026123,0.08896670490503311,0.9681671261787415,0.10466671735048294],\"xaxis\":\"x\",\"y\":[20113.771484375,18911.724609375,20048.91796875,18911.724609375,18422.3203125,18984.787109375,18659.384765625,20596.63671875,18116.521484375,20118.365234375,19102.498046875,18931.10546875,19752.408203125,20041.361328125,17527.8984375,19117.453125,18343.80859375,18815.908203125,19418.708984375,17927.904296875],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"vehicle_count\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('c9a91f4b-04d5-4256-a5a3-8c51e5121aa1');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = []\n",
    "ground_truth = []\n",
    "vehicle_counts = []\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    random_idx = np.random.randint(0,len(test_data))\n",
    "    x, y = test_data[random_idx]\n",
    "    vehicle_counts.append(x[0])\n",
    "    ground_truth.append(float(y))\n",
    "    pred_y = float(nn_model(x)[0])\n",
    "    preds.append(pred_y)\n",
    "\n",
    "df = pd.DataFrame({'vehicle_count': vehicle_counts, 'ground_truth': ground_truth, 'predictions': preds})\n",
    "\n",
    "px.scatter(df, x='vehicle_count', y=['ground_truth', 'predictions'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(nn_model, NN_MODEL_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Jun 22 2022, 20:18:18) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
