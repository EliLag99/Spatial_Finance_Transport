{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AADT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import segmentation_models_pytorch as smp\n",
    "import albumentations as album\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import plotly.express as px\n",
    "import torchmetrics\n",
    "from torchmetrics import MeanAbsolutePercentageError\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 1024\n",
    "VEHICLE_DETECTION_COUNT_PATH = '/home/ah2719/FYP/Spatial_Finance_Transport/data/vehicle_counts_detection.csv'\n",
    "DAILY_COUNT_PATH = '/home/ah2719/FYP/Spatial_Finance_Transport/data/ground_truth_data/df_aadt_week.csv'\n",
    "SPEED_DATA_PATH = \"/home/ah2719/FYP/Spatial_Finance_Transport/data/ground_truth_data/avg_mph.csv\"\n",
    "ROAD_WIDTH_PATH = \"\"\n",
    "TIMESTAMP_PATH = \"/home/ah2719/FYP/Spatial_Finance_Transport/data/ground_truth_data/timestamp.csv\"\n",
    "AVG_MPH_PATH = \"/home/ah2719/FYP/Spatial_Finance_Transport/data/ground_truth_data/avg_mph.csv\"\n",
    "\n",
    "NN_MODEL_PATH = \"/home/ah2719/FYP/Spatial_Finance_Transport/models/nn_model.pth\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True Count Data\n",
    "- Traffic monitoring stations for long-term traffic count data\n",
    "    - Extract at same time as Satellite Image!\n",
    "- How to use permanent and temporary traffic count stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Ground Truth Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vehicle detection number\n",
    "From vehicle detection model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Road characteristics\n",
    "From road characterstics pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Includes:\n",
    "- Road width\n",
    "- Live speed data\n",
    "- Directionality"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.labels = torch.tensor(pd.read_csv(DAILY_COUNT_PATH)['aadt'].values.astype('float32'))\n",
    "        self.vehicle_count = torch.tensor(pd.read_csv(DAILY_COUNT_PATH)['total_volume_normalised'].values.astype('float32')).unsqueeze(1) # Training\n",
    "        #self.speed_data = pd.read_csv(SPEED_DATA_PATH) \n",
    "        #self.road_width = pd.read_csv(ROAD_WIDTH_PATH)\n",
    "        self.hour = torch.tensor(pd.read_csv(DAILY_COUNT_PATH)['hour'].values.astype('float32')).unsqueeze(1)\n",
    "        self.avg_mph = torch.tensor(pd.read_csv(DAILY_COUNT_PATH)['avg_mph'].values.astype('float32')).unsqueeze(1)\n",
    "        self.day = torch.tensor(pd.read_csv(DAILY_COUNT_PATH)['day'].values.astype('float32')).unsqueeze(1)\n",
    "        self.month = torch.tensor(pd.read_csv(DAILY_COUNT_PATH)['month'].values.astype('float32')).unsqueeze(1)\n",
    "\n",
    "        self.x = torch.concat((self.vehicle_count, self.avg_mph, self.day, self.month, self.hour), dim=-1)\n",
    "        self.y = self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "custom_data = CustomDataset()\n",
    "train_split = 0.8\n",
    "train_data, test_data = random_split(custom_data, [train_split, 1-train_split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(5, 5),\n",
    "            nn.Linear(5,20),\n",
    "            nn.Linear(20,1)\n",
    "            #nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=5, bias=True)\n",
       "    (1): Linear(in_features=5, out_features=20, bias=True)\n",
       "    (2): Linear(in_features=20, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model = NeuralNetwork()\n",
    "nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=5, bias=True)\n",
       "    (1): Linear(in_features=5, out_features=20, bias=True)\n",
       "    (2): Linear(in_features=20, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "nn_model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-1\n",
    "batch_size = 1\n",
    "epochs = 1\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(nn_model.parameters(), lr=learning_rate)\n",
    "\n",
    "MAPE = MeanAbsolutePercentageError()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=False, sampler=None,\n",
    "                    batch_sampler=None, num_workers=0, collate_fn=None,\n",
    "                    pin_memory=False, drop_last=False, timeout=0,\n",
    "                    worker_init_fn=None, prefetch_factor=2,\n",
    "                    persistent_workers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False, sampler=None,\n",
    "                    batch_sampler=None, num_workers=0, collate_fn=None,\n",
    "                    pin_memory=False, drop_last=False, timeout=0,\n",
    "                    worker_init_fn=None, prefetch_factor=2,\n",
    "                    persistent_workers=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(ep_id, action, loader, model, optimizer, criterion):\n",
    "    losses = [] # Keep list of accuracies to track progress\n",
    "    is_training = action == \"train\" # True when action == \"train\", else False \n",
    "\n",
    "    # Looping over all batches\n",
    "    for batch_idx, batch in enumerate(loader): \n",
    "            x, y = batch\n",
    "            #print(\"x: {}\".format(x))\n",
    "            #print(\"y: {}\".format(y))\n",
    "\n",
    "            # Resetting the optimizer gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Setting model to train or test\n",
    "            with torch.set_grad_enabled(is_training):\n",
    "                \n",
    "                # Feed batch to model\n",
    "                logits = nn_model(x).squeeze(1)\n",
    "                print(\"logits: {}\".format(logits))\n",
    "\n",
    "                # Calculate the loss based on predictions and real labels\n",
    "                loss = criterion(logits, y)\n",
    "                print(\"loss: {}\".format(loss))\n",
    "                mape_loss = MAPE(logits, y)\n",
    "\n",
    "                # If training, perform backprop and update weights\n",
    "                if is_training:\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # Append current batch accuracy\n",
    "                losses.append(mape_loss.detach().numpy())\n",
    "\n",
    "                # Print some stats every 50th batch \n",
    "                if batch_idx % 50 == 0:\n",
    "                    print(f\"{action.capitalize()}ing, Epoch: {ep_id+1}, Batch {batch_idx}: Loss = {loss.item()}\")\n",
    "    # Return accuracies to main loop                 \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(epochs, train_dl, test_dl, model, optimizer, criterion):\n",
    "\n",
    "    # Keep lists of accuracies to track performance on train and test sets\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    # Looping over epochs\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Looping over train set and training\n",
    "        train_loss = run_epoch(epoch, \"train\", train_dl, model, optimizer, criterion)\n",
    "\n",
    "        # Looping over test set\n",
    "        test_loss = run_epoch(epoch, \"test\", test_dl, model, optimizer, criterion) \n",
    "\n",
    "        # Collecting stats\n",
    "        train_losses += train_loss\n",
    "        test_losses += test_loss         \n",
    "            \n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits: tensor([-27.9224], grad_fn=<SqueezeBackward1>)\n",
      "loss: 334914304.0\n",
      "Training, Epoch: 1, Batch 0: Loss = 334914304.0\n",
      "logits: tensor([22.4050], grad_fn=<SqueezeBackward1>)\n",
      "loss: 333074848.0\n",
      "logits: tensor([66.4024], grad_fn=<SqueezeBackward1>)\n",
      "loss: 331470816.0\n",
      "logits: tensor([141.3888], grad_fn=<SqueezeBackward1>)\n",
      "loss: 328745984.0\n",
      "logits: tensor([272.9131], grad_fn=<SqueezeBackward1>)\n",
      "loss: 323993888.0\n",
      "logits: tensor([512.6834], grad_fn=<SqueezeBackward1>)\n",
      "loss: 315419680.0\n",
      "logits: tensor([822.3222], grad_fn=<SqueezeBackward1>)\n",
      "loss: 304517152.0\n",
      "logits: tensor([1259.9628], grad_fn=<SqueezeBackward1>)\n",
      "loss: 289434656.0\n",
      "logits: tensor([2052.2590], grad_fn=<SqueezeBackward1>)\n",
      "loss: 263104080.0\n",
      "logits: tensor([2561.1357], grad_fn=<SqueezeBackward1>)\n",
      "loss: 246854576.0\n",
      "logits: tensor([3877.5342], grad_fn=<SqueezeBackward1>)\n",
      "loss: 207222016.0\n",
      "logits: tensor([5276.5591], grad_fn=<SqueezeBackward1>)\n",
      "loss: 168900784.0\n",
      "logits: tensor([7895.9409], grad_fn=<SqueezeBackward1>)\n",
      "loss: 107677992.0\n",
      "logits: tensor([10463.7539], grad_fn=<SqueezeBackward1>)\n",
      "loss: 60980296.0\n",
      "logits: tensor([11400.9736], grad_fn=<SqueezeBackward1>)\n",
      "loss: 47221204.0\n",
      "logits: tensor([17451.2168], grad_fn=<SqueezeBackward1>)\n",
      "loss: 674903.9375\n",
      "logits: tensor([20364.7148], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4376349.5\n",
      "logits: tensor([21727.5625], grad_fn=<SqueezeBackward1>)\n",
      "loss: 11935783.0\n",
      "logits: tensor([28148.5098], grad_fn=<SqueezeBackward1>)\n",
      "loss: 97530784.0\n",
      "logits: tensor([28591.5566], grad_fn=<SqueezeBackward1>)\n",
      "loss: 106477928.0\n",
      "logits: tensor([26683.3457], grad_fn=<SqueezeBackward1>)\n",
      "loss: 70738248.0\n",
      "logits: tensor([21780.1777], grad_fn=<SqueezeBackward1>)\n",
      "loss: 12302104.0\n",
      "logits: tensor([22828.0215], grad_fn=<SqueezeBackward1>)\n",
      "loss: 20750570.0\n",
      "logits: tensor([19848.5801], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2483265.0\n",
      "logits: tensor([14038.9473], grad_fn=<SqueezeBackward1>)\n",
      "loss: 17925020.0\n",
      "logits: tensor([16152.4053], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4495828.5\n",
      "logits: tensor([11622.0928], grad_fn=<SqueezeBackward1>)\n",
      "loss: 44231136.0\n",
      "logits: tensor([11701.8252], grad_fn=<SqueezeBackward1>)\n",
      "loss: 43176952.0\n",
      "logits: tensor([13112.5566], grad_fn=<SqueezeBackward1>)\n",
      "loss: 26627514.0\n",
      "logits: tensor([13512.4482], grad_fn=<SqueezeBackward1>)\n",
      "loss: 22660398.0\n",
      "logits: tensor([13415.7256], grad_fn=<SqueezeBackward1>)\n",
      "loss: 23590610.0\n",
      "logits: tensor([13136.4873], grad_fn=<SqueezeBackward1>)\n",
      "loss: 26381114.0\n",
      "logits: tensor([13680.5674], grad_fn=<SqueezeBackward1>)\n",
      "loss: 21088070.0\n",
      "logits: tensor([15322.2773], grad_fn=<SqueezeBackward1>)\n",
      "loss: 8705243.0\n",
      "logits: tensor([16109.9424], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4677703.0\n",
      "logits: tensor([18864.2773], grad_fn=<SqueezeBackward1>)\n",
      "loss: 349913.84375\n",
      "logits: tensor([19081.3066], grad_fn=<SqueezeBackward1>)\n",
      "loss: 653776.5\n",
      "logits: tensor([18991.3887], grad_fn=<SqueezeBackward1>)\n",
      "loss: 516452.78125\n",
      "logits: tensor([20297.2676], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4098703.0\n",
      "logits: tensor([21733.0352], grad_fn=<SqueezeBackward1>)\n",
      "loss: 11973627.0\n",
      "logits: tensor([20965.3652], grad_fn=<SqueezeBackward1>)\n",
      "loss: 7250219.0\n",
      "logits: tensor([20713.9082], grad_fn=<SqueezeBackward1>)\n",
      "loss: 5959291.5\n",
      "logits: tensor([21943.9199], grad_fn=<SqueezeBackward1>)\n",
      "loss: 13477546.0\n",
      "logits: tensor([20834.0820], grad_fn=<SqueezeBackward1>)\n",
      "loss: 6560462.0\n",
      "logits: tensor([19187.5332], grad_fn=<SqueezeBackward1>)\n",
      "loss: 836842.625\n",
      "logits: tensor([17594.8711], grad_fn=<SqueezeBackward1>)\n",
      "loss: 459509.21875\n",
      "logits: tensor([14772.2217], grad_fn=<SqueezeBackward1>)\n",
      "loss: 12253644.0\n",
      "logits: tensor([16714.5449], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2427978.75\n",
      "logits: tensor([16632.3750], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2690804.5\n",
      "logits: tensor([16646.7578], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2643825.25\n",
      "logits: tensor([16034.9521], grad_fn=<SqueezeBackward1>)\n",
      "loss: 5007704.5\n",
      "Training, Epoch: 1, Batch 50: Loss = 5007704.5\n",
      "logits: tensor([16961.5918], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1719115.375\n",
      "logits: tensor([17409.3750], grad_fn=<SqueezeBackward1>)\n",
      "loss: 745402.875\n",
      "logits: tensor([17751.4922], grad_fn=<SqueezeBackward1>)\n",
      "loss: 271701.5625\n",
      "logits: tensor([18834.1797], grad_fn=<SqueezeBackward1>)\n",
      "loss: 315212.0625\n",
      "logits: tensor([17879.5410], grad_fn=<SqueezeBackward1>)\n",
      "loss: 154607.15625\n",
      "logits: tensor([19412.3652], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1298740.75\n",
      "logits: tensor([17256.3770], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1032998.3125\n",
      "logits: tensor([19888.7656], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2611531.75\n",
      "logits: tensor([19617.7227], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1808972.5\n",
      "logits: tensor([18673.9590], grad_fn=<SqueezeBackward1>)\n",
      "loss: 160974.921875\n",
      "logits: tensor([19319.0410], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1094741.25\n",
      "logits: tensor([19366.5059], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1196319.0\n",
      "logits: tensor([17511.0273], grad_fn=<SqueezeBackward1>)\n",
      "loss: 580209.5\n",
      "logits: tensor([17460.9414], grad_fn=<SqueezeBackward1>)\n",
      "loss: 659020.5\n",
      "logits: tensor([19410.9473], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1295510.75\n",
      "logits: tensor([18691.0332], grad_fn=<SqueezeBackward1>)\n",
      "loss: 174967.375\n",
      "logits: tensor([17384.2051], grad_fn=<SqueezeBackward1>)\n",
      "loss: 789498.1875\n",
      "logits: tensor([17152.7637], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1254351.875\n",
      "logits: tensor([17993.5176], grad_fn=<SqueezeBackward1>)\n",
      "loss: 77966.3828125\n",
      "logits: tensor([15244.8555], grad_fn=<SqueezeBackward1>)\n",
      "loss: 9168098.0\n",
      "logits: tensor([18123.6191], grad_fn=<SqueezeBackward1>)\n",
      "loss: 22237.68359375\n",
      "logits: tensor([16819.8535], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2110885.5\n",
      "logits: tensor([19301.8984], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1059162.625\n",
      "logits: tensor([19831.9609], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2431163.0\n",
      "logits: tensor([18255.4531], grad_fn=<SqueezeBackward1>)\n",
      "loss: 298.91168212890625\n",
      "logits: tensor([18297.3262], grad_fn=<SqueezeBackward1>)\n",
      "loss: 604.372314453125\n",
      "logits: tensor([17936.7891], grad_fn=<SqueezeBackward1>)\n",
      "loss: 112864.5\n",
      "logits: tensor([18573.6250], grad_fn=<SqueezeBackward1>)\n",
      "loss: 90530.46875\n",
      "logits: tensor([19525.1289], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1568472.5\n",
      "logits: tensor([19165.9355], grad_fn=<SqueezeBackward1>)\n",
      "loss: 797794.375\n",
      "logits: tensor([18273.7969], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1.11236572265625\n",
      "logits: tensor([18257.2266], grad_fn=<SqueezeBackward1>)\n",
      "loss: 240.734619140625\n",
      "logits: tensor([17421.4824], grad_fn=<SqueezeBackward1>)\n",
      "loss: 724643.1875\n",
      "logits: tensor([17215.5840], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1117583.5\n",
      "logits: tensor([17761.7363], grad_fn=<SqueezeBackward1>)\n",
      "loss: 261126.984375\n",
      "logits: tensor([17581.8574], grad_fn=<SqueezeBackward1>)\n",
      "loss: 477321.75\n",
      "logits: tensor([16618.5742], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2736271.75\n",
      "logits: tensor([17725.2676], grad_fn=<SqueezeBackward1>)\n",
      "loss: 299728.4375\n",
      "logits: tensor([19629.6113], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1841093.875\n",
      "logits: tensor([18624.2949], grad_fn=<SqueezeBackward1>)\n",
      "loss: 123589.328125\n",
      "logits: tensor([20495.5059], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4940678.5\n",
      "logits: tensor([18845.6660], grad_fn=<SqueezeBackward1>)\n",
      "loss: 328241.71875\n",
      "logits: tensor([18482.6445], grad_fn=<SqueezeBackward1>)\n",
      "loss: 44058.9921875\n",
      "logits: tensor([18218.8027], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2909.464599609375\n",
      "logits: tensor([17401.4531], grad_fn=<SqueezeBackward1>)\n",
      "loss: 759144.625\n",
      "logits: tensor([17894.3262], grad_fn=<SqueezeBackward1>)\n",
      "loss: 143198.6875\n",
      "logits: tensor([17874.7266], grad_fn=<SqueezeBackward1>)\n",
      "loss: 158416.4375\n",
      "logits: tensor([17617.8301], grad_fn=<SqueezeBackward1>)\n",
      "loss: 428909.875\n",
      "logits: tensor([18848.3633], grad_fn=<SqueezeBackward1>)\n",
      "loss: 331339.65625\n",
      "logits: tensor([16797.7461], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2175613.5\n",
      "Training, Epoch: 1, Batch 100: Loss = 2175613.5\n",
      "logits: tensor([19093.0059], grad_fn=<SqueezeBackward1>)\n",
      "loss: 672832.5\n",
      "logits: tensor([18172.6523], grad_fn=<SqueezeBackward1>)\n",
      "loss: 10017.9765625\n",
      "logits: tensor([19493.3281], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1489830.0\n",
      "logits: tensor([17345.5469], grad_fn=<SqueezeBackward1>)\n",
      "loss: 859691.125\n",
      "logits: tensor([18942.3613], grad_fn=<SqueezeBackward1>)\n",
      "loss: 448389.78125\n",
      "logits: tensor([18910.3984], grad_fn=<SqueezeBackward1>)\n",
      "loss: 406605.5\n",
      "logits: tensor([17272.0410], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1001402.8125\n",
      "logits: tensor([15575.1826], grad_fn=<SqueezeBackward1>)\n",
      "loss: 7276827.5\n",
      "logits: tensor([17848.6211], grad_fn=<SqueezeBackward1>)\n",
      "loss: 179878.703125\n",
      "logits: tensor([18358.1055], grad_fn=<SqueezeBackward1>)\n",
      "loss: 7286.8896484375\n",
      "logits: tensor([19073.6250], grad_fn=<SqueezeBackward1>)\n",
      "loss: 641413.25\n",
      "logits: tensor([18532.4766], grad_fn=<SqueezeBackward1>)\n",
      "loss: 67461.9453125\n",
      "logits: tensor([18125.5723], grad_fn=<SqueezeBackward1>)\n",
      "loss: 21658.986328125\n",
      "logits: tensor([17449.5547], grad_fn=<SqueezeBackward1>)\n",
      "loss: 677637.6875\n",
      "logits: tensor([18215.3281], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3296.37451171875\n",
      "logits: tensor([20424.2715], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4629078.5\n",
      "logits: tensor([18275.0918], grad_fn=<SqueezeBackward1>)\n",
      "loss: 5.520664215087891\n",
      "logits: tensor([16756.5977], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2298694.25\n",
      "logits: tensor([19022.6543], grad_fn=<SqueezeBackward1>)\n",
      "loss: 562368.1875\n",
      "logits: tensor([18558.3691], grad_fn=<SqueezeBackward1>)\n",
      "loss: 81582.7578125\n",
      "logits: tensor([19033.8574], grad_fn=<SqueezeBackward1>)\n",
      "loss: 579296.375\n",
      "logits: tensor([17994.5703], grad_fn=<SqueezeBackward1>)\n",
      "loss: 77379.59375\n",
      "logits: tensor([18394.4531], grad_fn=<SqueezeBackward1>)\n",
      "loss: 14813.552734375\n",
      "logits: tensor([18171.5352], grad_fn=<SqueezeBackward1>)\n",
      "loss: 10242.86328125\n",
      "logits: tensor([17658.6719], grad_fn=<SqueezeBackward1>)\n",
      "loss: 377082.34375\n",
      "logits: tensor([18968.3457], grad_fn=<SqueezeBackward1>)\n",
      "loss: 483864.25\n",
      "logits: tensor([18732.7559], grad_fn=<SqueezeBackward1>)\n",
      "loss: 211612.578125\n",
      "logits: tensor([18915.7031], grad_fn=<SqueezeBackward1>)\n",
      "loss: 413398.78125\n",
      "logits: tensor([17757.4434], grad_fn=<SqueezeBackward1>)\n",
      "loss: 265532.875\n",
      "logits: tensor([17515.6992], grad_fn=<SqueezeBackward1>)\n",
      "loss: 573114.0625\n",
      "logits: tensor([17006.7559], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1602721.375\n",
      "logits: tensor([17653.1133], grad_fn=<SqueezeBackward1>)\n",
      "loss: 383939.96875\n",
      "logits: tensor([18820.9707], grad_fn=<SqueezeBackward1>)\n",
      "loss: 300554.5\n",
      "logits: tensor([17918.5293], grad_fn=<SqueezeBackward1>)\n",
      "loss: 125466.7734375\n",
      "logits: tensor([18362.5469], grad_fn=<SqueezeBackward1>)\n",
      "loss: 8064.8818359375\n",
      "logits: tensor([17490.5371], grad_fn=<SqueezeBackward1>)\n",
      "loss: 611844.8125\n",
      "logits: tensor([17729.0664], grad_fn=<SqueezeBackward1>)\n",
      "loss: 295583.34375\n",
      "logits: tensor([17600.6250], grad_fn=<SqueezeBackward1>)\n",
      "loss: 451741.5\n",
      "logits: tensor([18125.5215], grad_fn=<SqueezeBackward1>)\n",
      "loss: 21673.935546875\n",
      "logits: tensor([20713.1328], grad_fn=<SqueezeBackward1>)\n",
      "loss: 5955506.5\n",
      "logits: tensor([20154.1387], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3539652.75\n",
      "logits: tensor([16744.7559], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2334742.25\n",
      "logits: tensor([17967.8965], grad_fn=<SqueezeBackward1>)\n",
      "loss: 92930.90625\n",
      "logits: tensor([16542.4395], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2993947.5\n",
      "logits: tensor([18216.1133], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3206.8330078125\n",
      "logits: tensor([18385.3145], grad_fn=<SqueezeBackward1>)\n",
      "loss: 12672.5146484375\n",
      "logits: tensor([20175.5098], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3620524.5\n",
      "logits: tensor([19037.3008], grad_fn=<SqueezeBackward1>)\n",
      "loss: 584549.8125\n",
      "logits: tensor([18804.7656], grad_fn=<SqueezeBackward1>)\n",
      "loss: 283048.9375\n",
      "logits: tensor([17623.2051], grad_fn=<SqueezeBackward1>)\n",
      "loss: 421898.46875\n",
      "Training, Epoch: 1, Batch 150: Loss = 421898.46875\n",
      "logits: tensor([17462.3594], grad_fn=<SqueezeBackward1>)\n",
      "loss: 656720.3125\n",
      "logits: tensor([17483.9863], grad_fn=<SqueezeBackward1>)\n",
      "loss: 622135.8125\n",
      "logits: tensor([18057.0820], grad_fn=<SqueezeBackward1>)\n",
      "loss: 46509.3046875\n",
      "logits: tensor([17675.5938], grad_fn=<SqueezeBackward1>)\n",
      "loss: 356586.25\n",
      "logits: tensor([17930.9395], grad_fn=<SqueezeBackward1>)\n",
      "loss: 116829.109375\n",
      "logits: tensor([17919.6152], grad_fn=<SqueezeBackward1>)\n",
      "loss: 124698.6484375\n",
      "logits: tensor([18606.0703], grad_fn=<SqueezeBackward1>)\n",
      "loss: 111107.640625\n",
      "logits: tensor([19321.2461], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1099360.5\n",
      "logits: tensor([18214.1406], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3434.14306640625\n",
      "logits: tensor([17495.1094], grad_fn=<SqueezeBackward1>)\n",
      "loss: 604712.8125\n",
      "logits: tensor([19683.0801], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1989053.0\n",
      "logits: tensor([19043.6309], grad_fn=<SqueezeBackward1>)\n",
      "loss: 594269.375\n",
      "logits: tensor([18568.1445], grad_fn=<SqueezeBackward1>)\n",
      "loss: 87262.546875\n",
      "logits: tensor([16595.8574], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2811942.5\n",
      "logits: tensor([17719.0352], grad_fn=<SqueezeBackward1>)\n",
      "loss: 306591.46875\n",
      "logits: tensor([17367.8652], grad_fn=<SqueezeBackward1>)\n",
      "loss: 818802.3125\n",
      "logits: tensor([18029.8945], grad_fn=<SqueezeBackward1>)\n",
      "loss: 58974.984375\n",
      "logits: tensor([18179.3652], grad_fn=<SqueezeBackward1>)\n",
      "loss: 8719.255859375\n",
      "logits: tensor([17573.8340], grad_fn=<SqueezeBackward1>)\n",
      "loss: 488472.6875\n",
      "logits: tensor([19472.7734], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1440075.0\n",
      "logits: tensor([18696.5625], grad_fn=<SqueezeBackward1>)\n",
      "loss: 179623.65625\n",
      "logits: tensor([19173.8887], grad_fn=<SqueezeBackward1>)\n",
      "loss: 812065.0\n",
      "logits: tensor([16541.2734], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2997984.0\n",
      "logits: tensor([18510.4863], grad_fn=<SqueezeBackward1>)\n",
      "loss: 56522.27734375\n",
      "logits: tensor([18333.6191], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3706.00341796875\n",
      "logits: tensor([20394.5859], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4502221.0\n",
      "logits: tensor([18699.8867], grad_fn=<SqueezeBackward1>)\n",
      "loss: 182452.453125\n",
      "logits: tensor([19185.5742], grad_fn=<SqueezeBackward1>)\n",
      "loss: 833262.3125\n",
      "logits: tensor([17248.4512], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1049172.125\n",
      "logits: tensor([18623.0234], grad_fn=<SqueezeBackward1>)\n",
      "loss: 122696.953125\n",
      "logits: tensor([16675.5156], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2551132.75\n",
      "logits: tensor([17521.2070], grad_fn=<SqueezeBackward1>)\n",
      "loss: 564805.0625\n",
      "logits: tensor([16503.7559], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3129312.75\n",
      "logits: tensor([18209.3418], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4019.609619140625\n",
      "logits: tensor([18858.3672], grad_fn=<SqueezeBackward1>)\n",
      "loss: 342956.625\n",
      "logits: tensor([16158.2188], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4471209.5\n",
      "logits: tensor([18794.5000], grad_fn=<SqueezeBackward1>)\n",
      "loss: 272231.21875\n",
      "logits: tensor([18821.9648], grad_fn=<SqueezeBackward1>)\n",
      "loss: 301645.53125\n",
      "logits: tensor([19995.7930], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2968904.0\n",
      "logits: tensor([17742.7598], grad_fn=<SqueezeBackward1>)\n",
      "loss: 280881.375\n",
      "logits: tensor([18754.0254], grad_fn=<SqueezeBackward1>)\n",
      "loss: 231633.515625\n",
      "logits: tensor([19866.7520], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2540867.25\n",
      "logits: tensor([17663.0840], grad_fn=<SqueezeBackward1>)\n",
      "loss: 371683.125\n",
      "logits: tensor([19451.5430], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1389571.25\n",
      "logits: tensor([17585.3047], grad_fn=<SqueezeBackward1>)\n",
      "loss: 472570.3125\n",
      "logits: tensor([17481.5176], grad_fn=<SqueezeBackward1>)\n",
      "loss: 626036.375\n",
      "logits: tensor([18812.5332], grad_fn=<SqueezeBackward1>)\n",
      "loss: 291374.34375\n",
      "logits: tensor([17552.8066], grad_fn=<SqueezeBackward1>)\n",
      "loss: 518307.1875\n",
      "logits: tensor([17422.8652], grad_fn=<SqueezeBackward1>)\n",
      "loss: 722290.8125\n",
      "logits: tensor([16775.7227], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2241067.5\n",
      "Training, Epoch: 1, Batch 200: Loss = 2241067.5\n",
      "logits: tensor([17434.4844], grad_fn=<SqueezeBackward1>)\n",
      "loss: 702676.1875\n",
      "logits: tensor([15746.6582], grad_fn=<SqueezeBackward1>)\n",
      "loss: 6381100.5\n",
      "logits: tensor([16321.6543], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3806744.0\n",
      "logits: tensor([19846.7734], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2477574.5\n",
      "logits: tensor([19019.5781], grad_fn=<SqueezeBackward1>)\n",
      "loss: 557763.9375\n",
      "logits: tensor([19722.3379], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2101327.75\n",
      "logits: tensor([20897.8848], grad_fn=<SqueezeBackward1>)\n",
      "loss: 6891373.5\n",
      "logits: tensor([19837.2988], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2447837.5\n",
      "logits: tensor([18944.1211], grad_fn=<SqueezeBackward1>)\n",
      "loss: 450749.625\n",
      "logits: tensor([18754.0020], grad_fn=<SqueezeBackward1>)\n",
      "loss: 231610.96875\n",
      "logits: tensor([18217.8125], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3017.2705078125\n",
      "logits: tensor([15722.5635], grad_fn=<SqueezeBackward1>)\n",
      "loss: 6503411.5\n",
      "logits: tensor([18698.6621], grad_fn=<SqueezeBackward1>)\n",
      "loss: 181407.78125\n",
      "logits: tensor([15803.2119], grad_fn=<SqueezeBackward1>)\n",
      "loss: 6098580.0\n",
      "logits: tensor([16606.7949], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2775380.25\n",
      "logits: tensor([16798.2246], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2174202.0\n",
      "logits: tensor([19386.6504], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1240791.5\n",
      "logits: tensor([17660.9453], grad_fn=<SqueezeBackward1>)\n",
      "loss: 374295.40625\n",
      "logits: tensor([17693.4766], grad_fn=<SqueezeBackward1>)\n",
      "loss: 335548.65625\n",
      "logits: tensor([19798.0352], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2326518.75\n",
      "logits: tensor([19177.1074], grad_fn=<SqueezeBackward1>)\n",
      "loss: 817876.5\n",
      "logits: tensor([20089.7715], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3301595.5\n",
      "logits: tensor([16648.6582], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2637648.75\n",
      "logits: tensor([18641.2227], grad_fn=<SqueezeBackward1>)\n",
      "loss: 135777.859375\n",
      "logits: tensor([18834.8516], grad_fn=<SqueezeBackward1>)\n",
      "loss: 315966.9375\n",
      "logits: tensor([19275.8613], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1006248.0\n",
      "logits: tensor([18232.0527], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1655.631591796875\n",
      "logits: tensor([17524.7168], grad_fn=<SqueezeBackward1>)\n",
      "loss: 559542.0\n",
      "logits: tensor([18624.], grad_fn=<SqueezeBackward1>)\n",
      "loss: 123382.0546875\n",
      "logits: tensor([17413.6055], grad_fn=<SqueezeBackward1>)\n",
      "loss: 738115.875\n",
      "logits: tensor([18766.5801], grad_fn=<SqueezeBackward1>)\n",
      "loss: 243875.859375\n",
      "logits: tensor([16153.2061], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4492433.5\n",
      "logits: tensor([17417.2969], grad_fn=<SqueezeBackward1>)\n",
      "loss: 731786.6875\n",
      "logits: tensor([16402.1484], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3499121.0\n",
      "logits: tensor([17957.1621], grad_fn=<SqueezeBackward1>)\n",
      "loss: 99590.7890625\n",
      "logits: tensor([18786.3008], grad_fn=<SqueezeBackward1>)\n",
      "loss: 263742.4375\n",
      "logits: tensor([20677.9727], grad_fn=<SqueezeBackward1>)\n",
      "loss: 5785133.5\n",
      "logits: tensor([18361.7773], grad_fn=<SqueezeBackward1>)\n",
      "loss: 7927.25927734375\n",
      "logits: tensor([19020.6426], grad_fn=<SqueezeBackward1>)\n",
      "loss: 559355.0\n",
      "logits: tensor([19503.0137], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1513567.875\n",
      "logits: tensor([18459.2734], grad_fn=<SqueezeBackward1>)\n",
      "loss: 34793.90625\n",
      "logits: tensor([18207.6895], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4231.8583984375\n",
      "logits: tensor([18629.7773], grad_fn=<SqueezeBackward1>)\n",
      "loss: 127474.1015625\n",
      "logits: tensor([17904.0742], grad_fn=<SqueezeBackward1>)\n",
      "loss: 135916.078125\n",
      "logits: tensor([17204.3301], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1141504.375\n",
      "logits: tensor([17066.5684], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1454855.25\n",
      "logits: tensor([18638.4121], grad_fn=<SqueezeBackward1>)\n",
      "loss: 133714.484375\n",
      "logits: tensor([17096.7090], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1383054.125\n",
      "logits: tensor([18137.0469], grad_fn=<SqueezeBackward1>)\n",
      "loss: 18413.21875\n",
      "logits: tensor([17639.2852], grad_fn=<SqueezeBackward1>)\n",
      "loss: 401267.8125\n",
      "Training, Epoch: 1, Batch 250: Loss = 401267.8125\n",
      "logits: tensor([17596.0176], grad_fn=<SqueezeBackward1>)\n",
      "loss: 457956.1875\n",
      "logits: tensor([18770.8672], grad_fn=<SqueezeBackward1>)\n",
      "loss: 248128.515625\n",
      "logits: tensor([18817.1543], grad_fn=<SqueezeBackward1>)\n",
      "loss: 296384.53125\n",
      "logits: tensor([19232.5449], grad_fn=<SqueezeBackward1>)\n",
      "loss: 921221.3125\n",
      "logits: tensor([19134.9785], grad_fn=<SqueezeBackward1>)\n",
      "loss: 743451.5\n",
      "logits: tensor([19197.7344], grad_fn=<SqueezeBackward1>)\n",
      "loss: 855610.5625\n",
      "logits: tensor([19034.9434], grad_fn=<SqueezeBackward1>)\n",
      "loss: 580950.625\n",
      "logits: tensor([17729.7090], grad_fn=<SqueezeBackward1>)\n",
      "loss: 294885.0625\n",
      "logits: tensor([17167.0801], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1222488.75\n",
      "logits: tensor([18701.6445], grad_fn=<SqueezeBackward1>)\n",
      "loss: 183957.21875\n",
      "logits: tensor([17300.8281], grad_fn=<SqueezeBackward1>)\n",
      "loss: 944616.9375\n",
      "logits: tensor([17359.2773], grad_fn=<SqueezeBackward1>)\n",
      "loss: 834418.0\n",
      "logits: tensor([17292.6836], grad_fn=<SqueezeBackward1>)\n",
      "loss: 960514.875\n",
      "logits: tensor([17515.4023], grad_fn=<SqueezeBackward1>)\n",
      "loss: 573563.625\n",
      "logits: tensor([20132.0117], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3456883.25\n",
      "logits: tensor([19702.9434], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2045475.375\n",
      "logits: tensor([18104.0117], grad_fn=<SqueezeBackward1>)\n",
      "loss: 28469.970703125\n",
      "logits: tensor([18231.7188], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1682.92236328125\n",
      "logits: tensor([18355.6445], grad_fn=<SqueezeBackward1>)\n",
      "loss: 6872.798828125\n",
      "logits: tensor([16781.7852], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2222952.75\n",
      "logits: tensor([19704.4531], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2049796.25\n",
      "logits: tensor([17558.2012], grad_fn=<SqueezeBackward1>)\n",
      "loss: 510568.875\n",
      "logits: tensor([18520.0137], grad_fn=<SqueezeBackward1>)\n",
      "loss: 61143.1875\n",
      "logits: tensor([17439.4004], grad_fn=<SqueezeBackward1>)\n",
      "loss: 694458.5625\n",
      "logits: tensor([18275.2715], grad_fn=<SqueezeBackward1>)\n",
      "loss: 6.397342681884766\n",
      "logits: tensor([16300.1924], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3890952.75\n",
      "logits: tensor([17797.4805], grad_fn=<SqueezeBackward1>)\n",
      "loss: 225873.703125\n",
      "logits: tensor([18408.4844], grad_fn=<SqueezeBackward1>)\n",
      "loss: 18425.94140625\n",
      "logits: tensor([19116.6758], grad_fn=<SqueezeBackward1>)\n",
      "loss: 712223.9375\n",
      "logits: tensor([19308.7832], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1073381.0\n",
      "logits: tensor([19228.8652], grad_fn=<SqueezeBackward1>)\n",
      "loss: 914171.25\n",
      "logits: tensor([19127.6016], grad_fn=<SqueezeBackward1>)\n",
      "loss: 730784.5625\n",
      "logits: tensor([18235.8477], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1361.2064208984375\n",
      "logits: tensor([18451.9980], grad_fn=<SqueezeBackward1>)\n",
      "loss: 32132.6640625\n",
      "logits: tensor([18543.9688], grad_fn=<SqueezeBackward1>)\n",
      "loss: 73563.8515625\n",
      "logits: tensor([17542.8750], grad_fn=<SqueezeBackward1>)\n",
      "loss: 532706.125\n",
      "logits: tensor([15818.5176], grad_fn=<SqueezeBackward1>)\n",
      "loss: 6023218.5\n",
      "logits: tensor([17851.2090], grad_fn=<SqueezeBackward1>)\n",
      "loss: 177690.234375\n",
      "logits: tensor([16760.8652], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2285772.0\n",
      "logits: tensor([17658.4727], grad_fn=<SqueezeBackward1>)\n",
      "loss: 377327.0625\n",
      "logits: tensor([18449.5234], grad_fn=<SqueezeBackward1>)\n",
      "loss: 31251.609375\n",
      "logits: tensor([19439.5156], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1361360.25\n",
      "logits: tensor([20456.1641], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4767331.0\n",
      "logits: tensor([18740.7988], grad_fn=<SqueezeBackward1>)\n",
      "loss: 219077.015625\n",
      "logits: tensor([19323.4355], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1103956.5\n",
      "logits: tensor([18149.7051], grad_fn=<SqueezeBackward1>)\n",
      "loss: 15138.1298828125\n",
      "logits: tensor([18014.0156], grad_fn=<SqueezeBackward1>)\n",
      "loss: 66939.4375\n",
      "logits: tensor([18277.8281], grad_fn=<SqueezeBackward1>)\n",
      "loss: 25.86676025390625\n",
      "logits: tensor([17713.7910], grad_fn=<SqueezeBackward1>)\n",
      "loss: 312426.40625\n",
      "logits: tensor([16574.6250], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2883602.0\n",
      "Training, Epoch: 1, Batch 300: Loss = 2883602.0\n",
      "logits: tensor([15666.6348], grad_fn=<SqueezeBackward1>)\n",
      "loss: 6791796.0\n",
      "logits: tensor([16722.2949], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2403886.75\n",
      "logits: tensor([18648.0586], grad_fn=<SqueezeBackward1>)\n",
      "loss: 140862.40625\n",
      "logits: tensor([17940.9414], grad_fn=<SqueezeBackward1>)\n",
      "loss: 110091.7578125\n",
      "logits: tensor([20527.5762], grad_fn=<SqueezeBackward1>)\n",
      "loss: 5084276.5\n",
      "logits: tensor([20283.0293], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4041254.25\n",
      "logits: tensor([18677.0195], grad_fn=<SqueezeBackward1>)\n",
      "loss: 163440.171875\n",
      "logits: tensor([19485.6797], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1471217.375\n",
      "logits: tensor([18269.5234], grad_fn=<SqueezeBackward1>)\n",
      "loss: 10.3603515625\n",
      "logits: tensor([17348.0801], grad_fn=<SqueezeBackward1>)\n",
      "loss: 855000.0\n",
      "logits: tensor([17362.8184], grad_fn=<SqueezeBackward1>)\n",
      "loss: 827961.375\n",
      "logits: tensor([18571.7168], grad_fn=<SqueezeBackward1>)\n",
      "loss: 89385.8203125\n",
      "logits: tensor([16764.6113], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2274458.75\n",
      "logits: tensor([15417.3398], grad_fn=<SqueezeBackward1>)\n",
      "loss: 8153322.5\n",
      "logits: tensor([15720.7598], grad_fn=<SqueezeBackward1>)\n",
      "loss: 6512614.5\n",
      "logits: tensor([18512.8633], grad_fn=<SqueezeBackward1>)\n",
      "loss: 57658.140625\n",
      "logits: tensor([21154.8867], grad_fn=<SqueezeBackward1>)\n",
      "loss: 8306757.0\n",
      "logits: tensor([18698.1953], grad_fn=<SqueezeBackward1>)\n",
      "loss: 181010.359375\n",
      "logits: tensor([19006.4922], grad_fn=<SqueezeBackward1>)\n",
      "loss: 538389.0625\n",
      "logits: tensor([20283.0762], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4041442.75\n",
      "logits: tensor([19292.1094], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1039109.4375\n",
      "logits: tensor([19780.3301], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2272821.25\n",
      "logits: tensor([18754.0117], grad_fn=<SqueezeBackward1>)\n",
      "loss: 231620.359375\n",
      "logits: tensor([16534.1074], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3022850.75\n",
      "logits: tensor([15913.9141], grad_fn=<SqueezeBackward1>)\n",
      "loss: 5564070.0\n",
      "logits: tensor([17060.4883], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1469559.5\n",
      "logits: tensor([15912.0361], grad_fn=<SqueezeBackward1>)\n",
      "loss: 5572933.0\n",
      "logits: tensor([17236.3301], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1074150.0\n",
      "logits: tensor([17591.6914], grad_fn=<SqueezeBackward1>)\n",
      "loss: 463830.15625\n",
      "logits: tensor([18195.1465], grad_fn=<SqueezeBackward1>)\n",
      "loss: 6021.09326171875\n",
      "logits: tensor([19320.1367], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1097035.25\n",
      "logits: tensor([19275.9707], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1006467.4375\n",
      "logits: tensor([19925.7988], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2732596.25\n",
      "logits: tensor([20766.7012], grad_fn=<SqueezeBackward1>)\n",
      "loss: 6219831.5\n",
      "logits: tensor([20429.6738], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4652354.0\n",
      "logits: tensor([18079.6914], grad_fn=<SqueezeBackward1>)\n",
      "loss: 37268.60546875\n",
      "logits: tensor([16288.4512], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3937410.75\n",
      "logits: tensor([17238.1406], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1070400.375\n",
      "logits: tensor([16923.2363], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1821166.125\n",
      "logits: tensor([15969.3965], grad_fn=<SqueezeBackward1>)\n",
      "loss: 5305401.5\n",
      "logits: tensor([16632.2988], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2691054.5\n",
      "logits: tensor([16752.6992], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2310530.75\n",
      "logits: tensor([17748.7227], grad_fn=<SqueezeBackward1>)\n",
      "loss: 274596.46875\n",
      "logits: tensor([18530.1211], grad_fn=<SqueezeBackward1>)\n",
      "loss: 66243.8984375\n",
      "logits: tensor([19245.9492], grad_fn=<SqueezeBackward1>)\n",
      "loss: 947131.9375\n",
      "logits: tensor([19559.9922], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1657012.5\n",
      "logits: tensor([20119.2578], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3409620.0\n",
      "logits: tensor([19753.0195], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2191221.0\n",
      "logits: tensor([19449.1934], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1384037.375\n",
      "logits: tensor([17867.0840], grad_fn=<SqueezeBackward1>)\n",
      "loss: 164558.578125\n",
      "Training, Epoch: 1, Batch 350: Loss = 164558.578125\n",
      "logits: tensor([16925.6504], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1814656.25\n",
      "logits: tensor([18302.6133], grad_fn=<SqueezeBackward1>)\n",
      "loss: 892.2822265625\n",
      "logits: tensor([17020.7598], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1567460.0\n",
      "logits: tensor([17221.1660], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1105812.5\n",
      "logits: tensor([16275.5986], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3988582.5\n",
      "logits: tensor([18271.4355], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1.7073097229003906\n",
      "logits: tensor([18940.8398], grad_fn=<SqueezeBackward1>)\n",
      "loss: 446354.46875\n",
      "logits: tensor([18238.1719], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1195.1064453125\n",
      "logits: tensor([18721.1191], grad_fn=<SqueezeBackward1>)\n",
      "loss: 201041.890625\n",
      "logits: tensor([20164.5859], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3579072.75\n",
      "logits: tensor([20686.4023], grad_fn=<SqueezeBackward1>)\n",
      "loss: 5825755.5\n",
      "logits: tensor([17406.2988], grad_fn=<SqueezeBackward1>)\n",
      "loss: 750724.125\n",
      "logits: tensor([17050.4980], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1493880.75\n",
      "logits: tensor([18401.4141], grad_fn=<SqueezeBackward1>)\n",
      "loss: 16556.451171875\n",
      "logits: tensor([17256.1152], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1033530.375\n",
      "logits: tensor([17132.0020], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1301288.25\n",
      "logits: tensor([17013.2402], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1586345.125\n",
      "logits: tensor([16776.3398], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2239220.0\n",
      "logits: tensor([17919.4941], grad_fn=<SqueezeBackward1>)\n",
      "loss: 124784.1796875\n",
      "logits: tensor([19309.5703], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1075012.5\n",
      "logits: tensor([18287.9023], grad_fn=<SqueezeBackward1>)\n",
      "loss: 229.83033752441406\n",
      "logits: tensor([19914.6484], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2695856.25\n",
      "logits: tensor([21064.1152], grad_fn=<SqueezeBackward1>)\n",
      "loss: 7791763.5\n",
      "logits: tensor([20047.0234], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3148074.0\n",
      "logits: tensor([19144.6953], grad_fn=<SqueezeBackward1>)\n",
      "loss: 760302.25\n",
      "logits: tensor([18729.4590], grad_fn=<SqueezeBackward1>)\n",
      "loss: 208590.234375\n",
      "logits: tensor([16121.0244], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4629889.5\n",
      "logits: tensor([14594.6377], grad_fn=<SqueezeBackward1>)\n",
      "loss: 13528453.0\n",
      "logits: tensor([15253.1807], grad_fn=<SqueezeBackward1>)\n",
      "loss: 9117752.0\n",
      "logits: tensor([16485.6953], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3193536.5\n",
      "logits: tensor([17686.1699], grad_fn=<SqueezeBackward1>)\n",
      "loss: 344067.03125\n",
      "logits: tensor([18260.8047], grad_fn=<SqueezeBackward1>)\n",
      "loss: 142.50390625\n",
      "logits: tensor([20383.7969], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4456552.0\n",
      "logits: tensor([19134.6328], grad_fn=<SqueezeBackward1>)\n",
      "loss: 742855.4375\n",
      "logits: tensor([19089.5059], grad_fn=<SqueezeBackward1>)\n",
      "loss: 667102.875\n",
      "logits: tensor([19708.2441], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2060665.875\n",
      "logits: tensor([19273.1660], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1000847.8125\n",
      "logits: tensor([18861.8477], grad_fn=<SqueezeBackward1>)\n",
      "loss: 347045.25\n",
      "logits: tensor([19192.3652], grad_fn=<SqueezeBackward1>)\n",
      "loss: 845706.5625\n",
      "logits: tensor([18148.4707], grad_fn=<SqueezeBackward1>)\n",
      "loss: 15443.4013671875\n",
      "logits: tensor([16068.2119], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4859953.5\n",
      "logits: tensor([17078.0820], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1427212.875\n",
      "logits: tensor([16844.6836], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2039351.375\n",
      "logits: tensor([17478.0742], grad_fn=<SqueezeBackward1>)\n",
      "loss: 631497.1875\n",
      "logits: tensor([17902.4414], grad_fn=<SqueezeBackward1>)\n",
      "loss: 137122.671875\n",
      "logits: tensor([17583.4766], grad_fn=<SqueezeBackward1>)\n",
      "loss: 475087.09375\n",
      "logits: tensor([18719.5059], grad_fn=<SqueezeBackward1>)\n",
      "loss: 199597.78125\n",
      "logits: tensor([18819.7695], grad_fn=<SqueezeBackward1>)\n",
      "loss: 299238.90625\n",
      "logits: tensor([19710.6348], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2067535.125\n",
      "logits: tensor([19192.7168], grad_fn=<SqueezeBackward1>)\n",
      "loss: 846353.3125\n",
      "Training, Epoch: 1, Batch 400: Loss = 846353.3125\n",
      "logits: tensor([19613.8555], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1798584.875\n",
      "logits: tensor([19288.5293], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1031823.4375\n",
      "logits: tensor([20132.2910], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3457921.75\n",
      "logits: tensor([15553.8047], grad_fn=<SqueezeBackward1>)\n",
      "loss: 7392621.0\n",
      "logits: tensor([18335.4727], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3935.11181640625\n",
      "logits: tensor([16479.6250], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3215269.25\n",
      "logits: tensor([16442.2930], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3350544.25\n",
      "logits: tensor([18461.0703], grad_fn=<SqueezeBackward1>)\n",
      "loss: 35467.484375\n",
      "logits: tensor([15980.9482], grad_fn=<SqueezeBackward1>)\n",
      "loss: 5252319.5\n",
      "logits: tensor([17576.2129], grad_fn=<SqueezeBackward1>)\n",
      "loss: 485153.0625\n",
      "logits: tensor([18860.3613], grad_fn=<SqueezeBackward1>)\n",
      "loss: 345296.25\n",
      "logits: tensor([19087.5469], grad_fn=<SqueezeBackward1>)\n",
      "loss: 663906.6875\n",
      "logits: tensor([18561.6816], grad_fn=<SqueezeBackward1>)\n",
      "loss: 83486.0078125\n",
      "logits: tensor([20504.9941], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4982949.0\n",
      "logits: tensor([19076.5703], grad_fn=<SqueezeBackward1>)\n",
      "loss: 646139.625\n",
      "logits: tensor([17080.4395], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1421585.75\n",
      "logits: tensor([18208.7344], grad_fn=<SqueezeBackward1>)\n",
      "loss: 4097.0\n",
      "logits: tensor([19595.1191], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1748680.75\n",
      "logits: tensor([17162.9668], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1231601.375\n",
      "logits: tensor([17043.4863], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1511070.0\n",
      "logits: tensor([17836.7734], grad_fn=<SqueezeBackward1>)\n",
      "loss: 190068.75\n",
      "logits: tensor([17431.4609], grad_fn=<SqueezeBackward1>)\n",
      "loss: 707754.125\n",
      "logits: tensor([17649.3184], grad_fn=<SqueezeBackward1>)\n",
      "loss: 388657.28125\n",
      "logits: tensor([18896.3555], grad_fn=<SqueezeBackward1>)\n",
      "loss: 388893.53125\n",
      "logits: tensor([17417.2852], grad_fn=<SqueezeBackward1>)\n",
      "loss: 731806.75\n",
      "logits: tensor([20016.8672], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3041972.0\n",
      "logits: tensor([19374.4551], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1213771.25\n",
      "logits: tensor([20764.0352], grad_fn=<SqueezeBackward1>)\n",
      "loss: 6206540.5\n",
      "logits: tensor([18280.8203], grad_fn=<SqueezeBackward1>)\n",
      "loss: 65.256103515625\n",
      "logits: tensor([17730.8223], grad_fn=<SqueezeBackward1>)\n",
      "loss: 293677.1875\n",
      "logits: tensor([17856.4414], grad_fn=<SqueezeBackward1>)\n",
      "loss: 173306.34375\n",
      "logits: tensor([16986.3789], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1654730.5\n",
      "logits: tensor([15742.7041], grad_fn=<SqueezeBackward1>)\n",
      "loss: 6401092.5\n",
      "logits: tensor([16421.3848], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3427524.25\n",
      "logits: tensor([16348.5283], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3702599.0\n",
      "logits: tensor([18738.1465], grad_fn=<SqueezeBackward1>)\n",
      "loss: 216601.15625\n",
      "logits: tensor([19085.5312], grad_fn=<SqueezeBackward1>)\n",
      "loss: 660626.0625\n",
      "logits: tensor([19260.8633], grad_fn=<SqueezeBackward1>)\n",
      "loss: 976383.3125\n",
      "logits: tensor([21216.1133], grad_fn=<SqueezeBackward1>)\n",
      "loss: 8663433.0\n",
      "logits: tensor([19974.9902], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2897648.5\n",
      "logits: tensor([18780.0684], grad_fn=<SqueezeBackward1>)\n",
      "loss: 257379.84375\n",
      "logits: tensor([16982.5312], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1664644.25\n",
      "logits: tensor([18778.4492], grad_fn=<SqueezeBackward1>)\n",
      "loss: 255739.59375\n",
      "logits: tensor([15737.3887], grad_fn=<SqueezeBackward1>)\n",
      "loss: 6428017.5\n",
      "logits: tensor([15888.0303], grad_fn=<SqueezeBackward1>)\n",
      "loss: 5686851.0\n",
      "logits: tensor([17814.1758], grad_fn=<SqueezeBackward1>)\n",
      "loss: 210283.15625\n",
      "logits: tensor([17335.6270], grad_fn=<SqueezeBackward1>)\n",
      "loss: 878184.9375\n",
      "logits: tensor([16375.5977], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3599157.25\n",
      "logits: tensor([18991.2988], grad_fn=<SqueezeBackward1>)\n",
      "loss: 516323.65625\n",
      "logits: tensor([18770.0098], grad_fn=<SqueezeBackward1>)\n",
      "loss: 247275.046875\n",
      "Training, Epoch: 1, Batch 450: Loss = 247275.046875\n",
      "logits: tensor([20946.0586], grad_fn=<SqueezeBackward1>)\n",
      "loss: 7146620.5\n",
      "logits: tensor([19332.6836], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1123475.75\n",
      "logits: tensor([18136.6348], grad_fn=<SqueezeBackward1>)\n",
      "loss: 18525.23046875\n",
      "logits: tensor([19713.1777], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2074854.625\n",
      "logits: tensor([18291.7285], grad_fn=<SqueezeBackward1>)\n",
      "loss: 360.48065185546875\n",
      "logits: tensor([18480.8887], grad_fn=<SqueezeBackward1>)\n",
      "loss: 43324.95703125\n",
      "logits: tensor([17543.9199], grad_fn=<SqueezeBackward1>)\n",
      "loss: 531181.875\n",
      "logits: tensor([15974.6807], grad_fn=<SqueezeBackward1>)\n",
      "loss: 5281087.0\n",
      "logits: tensor([18057.8203], grad_fn=<SqueezeBackward1>)\n",
      "loss: 46191.4140625\n",
      "logits: tensor([17681.5078], grad_fn=<SqueezeBackward1>)\n",
      "loss: 349558.09375\n",
      "logits: tensor([16859.2422], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1997982.25\n",
      "logits: tensor([18732.3359], grad_fn=<SqueezeBackward1>)\n",
      "loss: 211226.421875\n",
      "logits: tensor([18122.8965], grad_fn=<SqueezeBackward1>)\n",
      "loss: 22453.734375\n",
      "logits: tensor([17628.5254], grad_fn=<SqueezeBackward1>)\n",
      "loss: 415015.28125\n",
      "logits: tensor([17954.3027], grad_fn=<SqueezeBackward1>)\n",
      "loss: 101403.6875\n",
      "logits: tensor([19691.6992], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2013439.0\n",
      "logits: tensor([19786.9512], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2292828.75\n",
      "logits: tensor([20267.7344], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3979993.75\n",
      "logits: tensor([18569.4961], grad_fn=<SqueezeBackward1>)\n",
      "loss: 88062.8828125\n",
      "logits: tensor([17424.3203], grad_fn=<SqueezeBackward1>)\n",
      "loss: 719819.6875\n",
      "logits: tensor([17967.0117], grad_fn=<SqueezeBackward1>)\n",
      "loss: 93471.1171875\n",
      "logits: tensor([17975.8125], grad_fn=<SqueezeBackward1>)\n",
      "loss: 88167.2421875\n",
      "logits: tensor([17582.5703], grad_fn=<SqueezeBackward1>)\n",
      "loss: 476337.21875\n",
      "logits: tensor([18032.6406], grad_fn=<SqueezeBackward1>)\n",
      "loss: 57648.76171875\n",
      "logits: tensor([16821.7988], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2105236.75\n",
      "logits: tensor([17725.8145], grad_fn=<SqueezeBackward1>)\n",
      "loss: 299129.9375\n",
      "logits: tensor([17815.4844], grad_fn=<SqueezeBackward1>)\n",
      "loss: 209084.703125\n",
      "logits: tensor([16926.4941], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1812383.75\n",
      "logits: tensor([18364.9590], grad_fn=<SqueezeBackward1>)\n",
      "loss: 8503.9375\n",
      "logits: tensor([17923.5879], grad_fn=<SqueezeBackward1>)\n",
      "loss: 121908.7265625\n",
      "logits: tensor([19841.3281], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2460461.75\n",
      "logits: tensor([21371.3398], grad_fn=<SqueezeBackward1>)\n",
      "loss: 9601307.0\n",
      "logits: tensor([19336.4844], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1131547.5\n",
      "logits: tensor([17889.3887], grad_fn=<SqueezeBackward1>)\n",
      "loss: 146959.921875\n",
      "logits: tensor([18818.6172], grad_fn=<SqueezeBackward1>)\n",
      "loss: 297979.5\n",
      "logits: tensor([17404.9883], grad_fn=<SqueezeBackward1>)\n",
      "loss: 752996.8125\n",
      "logits: tensor([15834.9941], grad_fn=<SqueezeBackward1>)\n",
      "loss: 5942615.5\n",
      "logits: tensor([16604.3379], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2783573.0\n",
      "logits: tensor([17828.2578], grad_fn=<SqueezeBackward1>)\n",
      "loss: 197566.359375\n",
      "logits: tensor([17622.7031], grad_fn=<SqueezeBackward1>)\n",
      "loss: 422550.78125\n",
      "logits: tensor([18530.3086], grad_fn=<SqueezeBackward1>)\n",
      "loss: 66340.453125\n",
      "logits: tensor([20060.9688], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3197754.25\n",
      "logits: tensor([19253.5820], grad_fn=<SqueezeBackward1>)\n",
      "loss: 962046.8125\n",
      "logits: tensor([18805.2480], grad_fn=<SqueezeBackward1>)\n",
      "loss: 283562.5\n",
      "logits: tensor([17103.8398], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1366332.75\n",
      "logits: tensor([17349.8379], grad_fn=<SqueezeBackward1>)\n",
      "loss: 851752.3125\n",
      "logits: tensor([19054.7559], grad_fn=<SqueezeBackward1>)\n",
      "loss: 611545.375\n",
      "logits: tensor([19344.1230], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1147857.0\n",
      "logits: tensor([17316.4492], grad_fn=<SqueezeBackward1>)\n",
      "loss: 914496.25\n",
      "logits: tensor([17701.2402], grad_fn=<SqueezeBackward1>)\n",
      "loss: 326614.46875\n",
      "Training, Epoch: 1, Batch 500: Loss = 326614.46875\n",
      "logits: tensor([16992.5195], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1638970.0\n",
      "logits: tensor([18217.4219], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3060.3369140625\n",
      "logits: tensor([19098.3086], grad_fn=<SqueezeBackward1>)\n",
      "loss: 681559.875\n",
      "logits: tensor([18579.9316], grad_fn=<SqueezeBackward1>)\n",
      "loss: 94365.359375\n",
      "logits: tensor([18571.1562], grad_fn=<SqueezeBackward1>)\n",
      "loss: 89050.953125\n",
      "logits: tensor([18413.0039], grad_fn=<SqueezeBackward1>)\n",
      "loss: 19673.349609375\n",
      "logits: tensor([17667.8203], grad_fn=<SqueezeBackward1>)\n",
      "loss: 365930.46875\n",
      "logits: tensor([17664.6484], grad_fn=<SqueezeBackward1>)\n",
      "loss: 369778.0\n",
      "logits: tensor([19513.6289], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1539799.875\n",
      "logits: tensor([18474.2168], grad_fn=<SqueezeBackward1>)\n",
      "loss: 40592.01953125\n",
      "logits: tensor([18977.3262], grad_fn=<SqueezeBackward1>)\n",
      "loss: 496438.59375\n",
      "logits: tensor([16948.9707], grad_fn=<SqueezeBackward1>)\n",
      "loss: 1752371.0\n",
      "logits: tensor([18136.5586], grad_fn=<SqueezeBackward1>)\n",
      "loss: 18545.970703125\n",
      "logits: tensor([18427.3066], grad_fn=<SqueezeBackward1>)\n",
      "loss: 23890.169921875\n",
      "logits: tensor([17966.2871], grad_fn=<SqueezeBackward1>)\n",
      "loss: 93914.71875\n",
      "logits: tensor([16629.1484], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2701400.5\n",
      "logits: tensor([19155.1855], grad_fn=<SqueezeBackward1>)\n",
      "loss: 778706.3125\n",
      "logits: tensor([19800.5000], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2334044.0\n",
      "logits: tensor([18915.0996], grad_fn=<SqueezeBackward1>)\n",
      "loss: 412623.0625\n",
      "logits: tensor([18302.5996], grad_fn=<SqueezeBackward1>)\n",
      "loss: 891.4656372070312\n",
      "logits: tensor([17575.4551], grad_fn=<SqueezeBackward1>)\n",
      "loss: 486209.3125\n",
      "logits: tensor([18700.6328], grad_fn=<SqueezeBackward1>)\n",
      "loss: 183090.390625\n",
      "logits: tensor([18040.7695], grad_fn=<SqueezeBackward1>)\n",
      "loss: 53811.3125\n",
      "logits: tensor([18114.2617], grad_fn=<SqueezeBackward1>)\n",
      "loss: 25116.05859375\n",
      "logits: tensor([17664.4023], grad_fn=<SqueezeBackward1>)\n",
      "loss: 370077.375\n",
      "logits: tensor([16360.3438], grad_fn=<SqueezeBackward1>)\n",
      "loss: 3657267.75\n",
      "logits: tensor([16685.9629], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2517868.5\n",
      "logits: tensor([17651.5430], grad_fn=<SqueezeBackward1>)\n",
      "loss: 385888.46875\n",
      "logits: tensor([19791.2578], grad_fn=<SqueezeBackward1>)\n",
      "loss: 2305889.75\n",
      "logits: tensor([21568.2793], grad_fn=<SqueezeBackward1>)\n",
      "loss: 10860565.0\n",
      "logits: tensor([18169.5957], grad_fn=<SqueezeBackward1>)\n",
      "loss: 10639.197265625\n",
      "logits: tensor([17780.2012], grad_fn=<SqueezeBackward1>)\n",
      "loss: 242596.65625\n",
      "logits: tensor([18568.2402], grad_fn=<SqueezeBackward1>)\n",
      "loss: 87319.09375\n",
      "logits: tensor([18186.4023], grad_fn=<SqueezeBackward1>)\n",
      "loss: 7454.56884765625\n",
      "logits: tensor([18486.7793], grad_fn=<SqueezeBackward1>)\n",
      "loss: 45811.8828125\n",
      "logits: tensor([17415.8789], grad_fn=<SqueezeBackward1>)\n",
      "loss: 734214.6875\n",
      "logits: tensor([17591.7988], grad_fn=<SqueezeBackward1>)\n",
      "loss: 463683.84375\n",
      "logits: tensor([16144.9756])\n",
      "loss: 4527390.5\n",
      "Testing, Epoch: 1, Batch 0: Loss = 4527390.5\n",
      "logits: tensor([18618.6328])\n",
      "loss: 119640.328125\n",
      "logits: tensor([18594.0508])\n",
      "loss: 103239.2109375\n",
      "logits: tensor([18072.9688])\n",
      "loss: 39909.42578125\n",
      "logits: tensor([16459.2520])\n",
      "loss: 3288746.75\n",
      "logits: tensor([18574.5156])\n",
      "loss: 91067.2109375\n",
      "logits: tensor([17399.9180])\n",
      "loss: 761822.125\n",
      "logits: tensor([16677.9551])\n",
      "loss: 2543346.0\n",
      "logits: tensor([18092.2168])\n",
      "loss: 32589.416015625\n",
      "logits: tensor([17620.1094])\n",
      "loss: 425929.59375\n",
      "logits: tensor([17521.6973])\n",
      "loss: 564068.5\n",
      "logits: tensor([18475.2773])\n",
      "loss: 41020.48828125\n",
      "logits: tensor([17405.5410])\n",
      "loss: 752037.875\n",
      "logits: tensor([18472.8164])\n",
      "loss: 40029.69140625\n",
      "logits: tensor([18876.0918])\n",
      "loss: 364030.75\n",
      "logits: tensor([16364.6162])\n",
      "loss: 3640944.75\n",
      "logits: tensor([17362.2266])\n",
      "loss: 829038.6875\n",
      "logits: tensor([17807.1406])\n",
      "loss: 216784.8125\n",
      "logits: tensor([16059.4053])\n",
      "loss: 4898860.5\n",
      "logits: tensor([16946.6797])\n",
      "loss: 1758441.75\n",
      "logits: tensor([15833.5908])\n",
      "loss: 5949459.5\n",
      "logits: tensor([17509.3887])\n",
      "loss: 582708.5625\n",
      "logits: tensor([16218.3164])\n",
      "loss: 4220665.5\n",
      "logits: tensor([18241.9727])\n",
      "loss: 946.7640380859375\n",
      "logits: tensor([16985.5273])\n",
      "loss: 1656922.0\n",
      "logits: tensor([17109.6641])\n",
      "loss: 1352750.75\n",
      "logits: tensor([17000.9336])\n",
      "loss: 1617497.125\n",
      "logits: tensor([17797.7891])\n",
      "loss: 225580.46875\n",
      "logits: tensor([17811.4219])\n",
      "loss: 212816.4375\n",
      "logits: tensor([18087.2930])\n",
      "loss: 34391.4140625\n",
      "logits: tensor([17912.0137])\n",
      "loss: 130125.0625\n",
      "logits: tensor([17642.4844])\n",
      "loss: 397224.90625\n",
      "logits: tensor([16644.7207])\n",
      "loss: 2650454.0\n",
      "logits: tensor([18551.8750])\n",
      "loss: 77915.125\n",
      "logits: tensor([16612.1992])\n",
      "loss: 2757403.0\n",
      "logits: tensor([17320.7852])\n",
      "loss: 906222.1875\n",
      "logits: tensor([17329.2461])\n",
      "loss: 890184.875\n",
      "logits: tensor([17178.8945])\n",
      "loss: 1196502.75\n",
      "logits: tensor([18515.0703])\n",
      "loss: 58722.921875\n",
      "logits: tensor([16487.3105])\n",
      "loss: 3187766.25\n",
      "logits: tensor([18533.7754])\n",
      "loss: 68138.3359375\n",
      "logits: tensor([17568.9199])\n",
      "loss: 495365.78125\n",
      "logits: tensor([16630.5215])\n",
      "loss: 2696888.75\n",
      "logits: tensor([17580.0918])\n",
      "loss: 479764.5625\n",
      "logits: tensor([18283.6562])\n",
      "loss: 119.11676025390625\n",
      "logits: tensor([18166.3555])\n",
      "loss: 11318.1337890625\n",
      "logits: tensor([16985.2578])\n",
      "loss: 1657616.0\n",
      "logits: tensor([16579.6016])\n",
      "loss: 2866725.25\n",
      "logits: tensor([16986.5352])\n",
      "loss: 1654328.5\n",
      "logits: tensor([16343.0576])\n",
      "loss: 3723682.5\n",
      "logits: tensor([18157.0273])\n",
      "loss: 13389.9248046875\n",
      "Testing, Epoch: 1, Batch 50: Loss = 13389.9248046875\n",
      "logits: tensor([17231.3359])\n",
      "loss: 1084527.0\n",
      "logits: tensor([16381.5439])\n",
      "loss: 3576630.75\n",
      "logits: tensor([17699.6973])\n",
      "loss: 328380.46875\n",
      "logits: tensor([17262.6055])\n",
      "loss: 1020376.1875\n",
      "logits: tensor([17804.1875])\n",
      "loss: 219543.5\n",
      "logits: tensor([17038.9199])\n",
      "loss: 1522317.375\n",
      "logits: tensor([16342.3164])\n",
      "loss: 3726543.75\n",
      "logits: tensor([17853.9570])\n",
      "loss: 175381.0\n",
      "logits: tensor([16693.0078])\n",
      "loss: 2495560.75\n",
      "logits: tensor([16070.2119])\n",
      "loss: 4851139.5\n",
      "logits: tensor([17696.2520])\n",
      "loss: 332341.0\n",
      "logits: tensor([17496.5273])\n",
      "loss: 602509.5\n",
      "logits: tensor([17557.8203])\n",
      "loss: 511113.28125\n",
      "logits: tensor([16847.1309])\n",
      "loss: 2032367.625\n",
      "logits: tensor([15611.7158])\n",
      "loss: 7081061.5\n",
      "logits: tensor([17128.8945])\n",
      "loss: 1308387.5\n",
      "logits: tensor([16979.2754])\n",
      "loss: 1673056.375\n",
      "logits: tensor([18886.7305])\n",
      "loss: 376981.625\n",
      "logits: tensor([18925.1230])\n",
      "loss: 425600.78125\n",
      "logits: tensor([16339.1191])\n",
      "loss: 3738898.0\n",
      "logits: tensor([17058.7891])\n",
      "loss: 1473682.25\n",
      "logits: tensor([17268.0195])\n",
      "loss: 1009467.625\n",
      "logits: tensor([18416.8164])\n",
      "loss: 20757.380859375\n",
      "logits: tensor([17332.3477])\n",
      "loss: 884341.875\n",
      "logits: tensor([17565.7773])\n",
      "loss: 499799.28125\n",
      "logits: tensor([16178.9404])\n",
      "loss: 4384006.0\n",
      "logits: tensor([16720.0664])\n",
      "loss: 2410802.0\n",
      "logits: tensor([16991.1133])\n",
      "loss: 1642572.625\n",
      "logits: tensor([17284.5293])\n",
      "loss: 976564.6875\n",
      "logits: tensor([16952.5859])\n",
      "loss: 1742812.5\n",
      "logits: tensor([16542.1914])\n",
      "loss: 2994806.0\n",
      "logits: tensor([17170.8555])\n",
      "loss: 1214154.375\n",
      "logits: tensor([17555.4395])\n",
      "loss: 514523.21875\n",
      "logits: tensor([18128.0703])\n",
      "loss: 20929.951171875\n",
      "logits: tensor([16672.7012])\n",
      "loss: 2560131.25\n",
      "logits: tensor([18095.6602])\n",
      "loss: 31358.044921875\n",
      "logits: tensor([17110.1016])\n",
      "loss: 1351733.25\n",
      "logits: tensor([18659.5547])\n",
      "loss: 149623.90625\n",
      "logits: tensor([17075.9023])\n",
      "loss: 1432425.625\n",
      "logits: tensor([17470.0996])\n",
      "loss: 644235.125\n",
      "logits: tensor([17111.0449])\n",
      "loss: 1349540.5\n",
      "logits: tensor([16404.3730])\n",
      "loss: 3490803.25\n",
      "logits: tensor([18204.0664])\n",
      "loss: 4716.36279296875\n",
      "logits: tensor([16865.0703])\n",
      "loss: 1981540.125\n",
      "logits: tensor([18414.8340])\n",
      "loss: 20190.078125\n",
      "logits: tensor([18378.1953])\n",
      "loss: 11120.361328125\n",
      "logits: tensor([17001.3750])\n",
      "loss: 1616374.5\n",
      "logits: tensor([17529.9375])\n",
      "loss: 551758.8125\n",
      "logits: tensor([17021.4824])\n",
      "loss: 1565651.0\n",
      "logits: tensor([17424.4375])\n",
      "loss: 719620.8125\n",
      "Testing, Epoch: 1, Batch 100: Loss = 719620.8125\n",
      "logits: tensor([16969.2344])\n",
      "loss: 1699132.625\n",
      "logits: tensor([17452.5645])\n",
      "loss: 672691.5\n",
      "logits: tensor([18061.5762])\n",
      "loss: 44591.0859375\n",
      "logits: tensor([16708.8926])\n",
      "loss: 2445625.5\n",
      "logits: tensor([18350.4434])\n",
      "loss: 6037.47216796875\n",
      "logits: tensor([16870.0820])\n",
      "loss: 1967455.5\n",
      "logits: tensor([15974.8584])\n",
      "loss: 5280270.0\n",
      "logits: tensor([16734.9922])\n",
      "loss: 2364675.0\n",
      "logits: tensor([15900.3955])\n",
      "loss: 5628029.0\n",
      "logits: tensor([16371.5078])\n",
      "loss: 3614692.25\n",
      "logits: tensor([17643.1562])\n",
      "loss: 396378.4375\n",
      "logits: tensor([17427.6895])\n",
      "loss: 714114.125\n",
      "logits: tensor([18074.7891])\n",
      "loss: 39185.44140625\n",
      "logits: tensor([18497.7305])\n",
      "loss: 50619.7265625\n",
      "logits: tensor([17643.2305])\n",
      "loss: 396285.0\n",
      "logits: tensor([17369.4609])\n",
      "loss: 815917.0\n",
      "logits: tensor([16684.8242])\n",
      "loss: 2521483.5\n",
      "logits: tensor([17294.0312])\n",
      "loss: 957875.125\n",
      "logits: tensor([16464.9375])\n",
      "loss: 3268157.75\n",
      "logits: tensor([17555.6270])\n",
      "loss: 514254.25\n",
      "logits: tensor([15927.4668])\n",
      "loss: 5500316.5\n",
      "logits: tensor([16823.0156])\n",
      "loss: 2101707.0\n",
      "logits: tensor([16879.4688])\n",
      "loss: 1941210.875\n",
      "logits: tensor([16856.7773])\n",
      "loss: 2004956.5\n",
      "logits: tensor([17657.2969])\n",
      "loss: 378772.9375\n",
      "logits: tensor([17412.6211])\n",
      "loss: 739808.3125\n",
      "logits: tensor([19243.7461])\n",
      "loss: 942848.5625\n",
      "logits: tensor([17435.4922])\n",
      "loss: 700987.5625\n",
      "logits: tensor([17532.8164])\n",
      "loss: 547490.1875\n",
      "logits: tensor([16701.3730])\n",
      "loss: 2469201.0\n",
      "logits: tensor([16979.7168])\n",
      "loss: 1671914.625\n",
      "logits: tensor([16519.0605])\n",
      "loss: 3075399.25\n",
      "logits: tensor([17294.5352])\n",
      "loss: 956889.0\n"
     ]
    }
   ],
   "source": [
    "train_losses, test_losses = main(epochs=epochs, train_dl=train_dataloader, test_dl=test_dataloader, model=nn_model, optimizer=optimizer, criterion=loss_fn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Curve Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=0<br>index=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "0",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "0",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537
         ],
         "xaxis": "x",
         "y": [
          1.001528024673462,
          0.9987738728523254,
          0.996366024017334,
          0.9922623038291931,
          0.9850645065307617,
          0.9719427227973938,
          0.9549973011016846,
          0.9310468435287476,
          0.8876874446868896,
          0.8598384857177734,
          0.7877967953681946,
          0.7112333178520203,
          0.5678841471672058,
          0.4273572266101837,
          0.3760666251182556,
          0.044959064573049545,
          0.1144859716296196,
          0.18906961381435394,
          0.540464460849762,
          0.564710795879364,
          0.4602814018726349,
          0.1919490545988083,
          0.24929368495941162,
          0.08623981475830078,
          0.23170003294944763,
          0.1160382404923439,
          0.36396560072898865,
          0.3596021234989166,
          0.282397985458374,
          0.26051339507102966,
          0.2658066749572754,
          0.28108835220336914,
          0.25131285190582275,
          0.16146808862686157,
          0.11836208403110504,
          0.03237254545092583,
          0.0442497581243515,
          0.03932888060808182,
          0.11079483479261398,
          0.1893691122531891,
          0.14735735952854156,
          0.1335960477590561,
          0.2009100615978241,
          0.14017271995544434,
          0.05006314814090729,
          0.037097394466400146,
          0.19157062470912933,
          0.08527440577745438,
          0.08977126330137253,
          0.08898414671421051,
          0.12246602028608322,
          0.07175444066524506,
          0.04724891111254692,
          0.028526095673441887,
          0.03072541020810604,
          0.02151845395565033,
          0.062367379665374756,
          0.055621933192014694,
          0.08843902498483658,
          0.07360583543777466,
          0.021957119926810265,
          0.05726008862257004,
          0.05985766276717186,
          0.04168585315346718,
          0.044426873326301575,
          0.062289778143167496,
          0.02289152890443802,
          0.0486263707280159,
          0.06129230558872223,
          0.015280935913324356,
          0.1657051146030426,
          0.00816095620393753,
          0.07951125502586365,
          0.05632193759083748,
          0.0853303074836731,
          0.0009461668087169528,
          0.0013453910360112786,
          0.018385479226708412,
          0.016466209664940834,
          0.06853852421045303,
          0.04888118803501129,
          0.00005771916767116636,
          0.0008491131011396646,
          0.04658631607890129,
          0.05785438045859337,
          0.027965471148490906,
          0.0378095842897892,
          0.0905265286564827,
          0.029961273074150085,
          0.07425645738840103,
          0.019239189103245735,
          0.12164368480443954,
          0.031354013830423355,
          0.011487183161079884,
          0.0029519079253077507,
          0.047682445496320724,
          0.020709317177534103,
          0.021781932562589645,
          0.03584093227982521,
          0.03150162473320961,
          0.08072111010551453,
          0.044890016317367554,
          0.00547754904255271,
          0.06679818034172058,
          0.05074198916554451,
          0.0366457924246788,
          0.03489658236503601,
          0.05476469546556473,
          0.14762751758098602,
          0.023210588842630386,
          0.004671618342399597,
          0.04382937029004097,
          0.014214307069778442,
          0.008054068312048912,
          0.04505002498626709,
          0.0031420604791492224,
          0.1177452877163887,
          0.00012858548143412918,
          0.08297301828861237,
          0.041039932519197464,
          0.015631312504410744,
          0.04165303707122803,
          0.015223324298858643,
          0.0066607920452952385,
          0.0055386885069310665,
          0.03360581025481224,
          0.03806782141327858,
          0.025174856185913086,
          0.03518688678741455,
          0.028200410306453705,
          0.04143017902970314,
          0.06928277760744095,
          0.03391001373529434,
          0.03000253066420555,
          0.01938476972281933,
          0.0049146804958581924,
          0.0428072065114975,
          0.02975337579846382,
          0.03678250312805176,
          0.008056847378611565,
          0.133553609251976,
          0.10296191275119781,
          0.0836210772395134,
          0.01668308489024639,
          0.09469310939311981,
          0.0030990918166935444,
          0.006160666234791279,
          0.10413147509098053,
          0.04184148088097572,
          0.02911568619310856,
          0.03554677963256836,
          0.044349271804094315,
          0.04316570982336998,
          0.01180228777229786,
          0.03267974033951759,
          0.01870560646057129,
          0.019325340166687965,
          0.018241822719573975,
          0.05738076567649841,
          0.0032070481684058905,
          0.04255698621273041,
          0.07718260586261749,
          0.042187903076410294,
          0.016166284680366516,
          0.091769739985466,
          0.030302349478006363,
          0.0495205894112587,
          0.013290159404277802,
          0.005110177211463451,
          0.03824867680668831,
          0.06567329913377762,
          0.023194126784801483,
          0.04931643232703209,
          0.09475691616535187,
          0.013010862283408642,
          0.0033315718173980713,
          0.11612071096897125,
          0.02337604947388172,
          0.04995594173669815,
          0.05605567991733551,
          0.019169604405760765,
          0.0874103382229805,
          0.04112875461578369,
          0.09681011736392975,
          0.0034696701914072037,
          0.03204910457134247,
          0.11572009325027466,
          0.028553886339068413,
          0.030056936666369438,
          0.09429623186588287,
          0.029003988951444626,
          0.026338860392570496,
          0.08723429590463638,
          0.03336435183882713,
          0.06451143324375153,
          0.03762092813849449,
          0.0433008149266243,
          0.0295407772064209,
          0.03939942643046379,
          0.046510640531778336,
          0.0819263756275177,
          0.04587476700544357,
          0.13824328780174255,
          0.10677586495876312,
          0.0861409455537796,
          0.04087158665060997,
          0.07933104038238525,
          0.1436644047498703,
          0.08562242984771729,
          0.03674209862947464,
          0.026337577030062675,
          0.00300609995611012,
          0.13956190645694733,
          0.02330903150141239,
          0.1351483166217804,
          0.09117116779088974,
          0.08069492876529694,
          0.06096009910106659,
          0.03348139300942421,
          0.03170107677578926,
          0.08347367495298386,
          0.04949258267879486,
          0.09943933039903641,
          0.08888014405965805,
          0.0201655812561512,
          0.03076217882335186,
          0.05489702150225639,
          0.0022267841268330812,
          0.040936678647994995,
          0.01922304928302765,
          0.04701739549636841,
          0.02702593244612217,
          0.1159944236278534,
          0.04681537672877312,
          0.1023707166314125,
          0.017270537093281746,
          0.028105173259973526,
          0.13162942230701447,
          0.004872566554695368,
          0.04092983901500702,
          0.06732823699712753,
          0.010208169929683208,
          0.0035600969567894936,
          0.01953922212123871,
          0.020175842568278313,
          0.05847026780247688,
          0.06600946187973022,
          0.020011769607663155,
          0.06435997039079666,
          0.007426105439662933,
          0.034666772931814194,
          0.03703464940190315,
          0.02726054936647415,
          0.029793674126267433,
          0.05252647399902344,
          0.04718702286481857,
          0.05062142014503479,
          0.04171246662735939,
          0.02971821092069149,
          0.06050882115960121,
          0.023472247645258904,
          0.05318928509950638,
          0.04999057203531265,
          0.05363500490784645,
          0.04144642502069473,
          0.10175098478794098,
          0.07826965302228928,
          0.009233998134732246,
          0.0022450617980211973,
          0.00453694025054574,
          0.08159459382295609,
          0.07835227251052856,
          0.03910420462489128,
          0.013532259501516819,
          0.04560573399066925,
          0.00013841911277268082,
          0.10795039683580399,
          0.026009326800704002,
          0.007428670767694712,
          0.04618538171052933,
          0.056698717176914215,
          0.05232509970664978,
          0.04678330942988396,
          0.0020191019866615534,
          0.009810013696551323,
          0.014843232929706573,
          0.039942946285009384,
          0.13431069254875183,
          0.02306896261870861,
          0.0827394649386406,
          0.03361671417951584,
          0.009674588218331337,
          0.06385321915149689,
          0.11949065327644348,
          0.025615019723773003,
          0.05750058591365814,
          0.006733368616551161,
          0.014159153215587139,
          0.0002783346571959555,
          0.03058934211730957,
          0.09293171018362045,
          0.1426226794719696,
          0.08485028147697449,
          0.02053968794643879,
          0.018158236518502235,
          0.12339877337217331,
          0.1100156232714653,
          0.02212461270391941,
          0.0663796067237854,
          0.0001761503517627716,
          0.05060335621237755,
          0.04979678615927696,
          0.0163617804646492,
          0.08253445476293564,
          0.15626567602157593,
          0.13966061174869537,
          0.013140944764018059,
          0.15772917866706848,
          0.02328348532319069,
          0.04015544056892395,
          0.11001818627119064,
          0.055786218494176865,
          0.0825047418475151,
          0.026338111609220505,
          0.09514908492565155,
          0.12908999621868134,
          0.06634219735860825,
          0.1291927695274353,
          0.05671902373433113,
          0.0372714065015316,
          0.004246527329087257,
          0.05732005089521408,
          0.05490300804376602,
          0.09046570956707001,
          0.13648520410060883,
          0.11804094165563583,
          0.010564959608018398,
          0.10859294980764389,
          0.05661993846297264,
          0.0738534927368164,
          0.12605364620685577,
          0.0897754356265068,
          0.08318636566400528,
          0.02867766283452511,
          0.014085400849580765,
          0.053260043263435364,
          0.07044646143913269,
          0.10105301439762115,
          0.08101014047861099,
          0.06438285112380981,
          0.02220018208026886,
          0.07372137904167175,
          0.0016347351484000683,
          0.06851639598608017,
          0.057548899203538895,
          0.10929632186889648,
          0.00007150763849494979,
          0.03656252846121788,
          0.001891906140372157,
          0.02453802153468132,
          0.10353365540504456,
          0.1320907473564148,
          0.04741726070642471,
          0.06688892841339111,
          0.007041738834232092,
          0.05563625693321228,
          0.06242851912975311,
          0.06892791390419006,
          0.08189260214567184,
          0.01933196745812893,
          0.05674179270863533,
          0.0008296596352010965,
          0.08985549211502075,
          0.1527615785598755,
          0.09709989279508591,
          0.04771878942847252,
          0.02499443106353283,
          0.11775559931993484,
          0.2012891322374344,
          0.16524949669837952,
          0.09779850393533707,
          0.032100941985845566,
          0.0006532954866997898,
          0.11553025990724564,
          0.04716810584068298,
          0.04469847306609154,
          0.0785597413778305,
          0.054749518632888794,
          0.03223957493901253,
          0.05032758787274361,
          0.006800921633839607,
          0.12064583599567413,
          0.06537935882806778,
          0.07815239578485489,
          0.043489255011081696,
          0.02026520110666752,
          0.037720974534749985,
          0.024449734017252922,
          0.02993679605424404,
          0.07869057357311249,
          0.05034682899713516,
          0.07339420169591904,
          0.05559029430150986,
          0.10176627337932587,
          0.14879745244979858,
          0.0034330079797655344,
          0.0981307104229927,
          0.10017375648021698,
          0.010306505486369133,
          0.1254214495420456,
          0.03811848908662796,
          0.03215823695063591,
          0.0445912666618824,
          0.015812594443559647,
          0.12216294556856155,
          0.04399055615067482,
          0.06525034457445145,
          0.0035029123537242413,
          0.07236883044242859,
          0.06073392555117607,
          0.06727265566587448,
          0.023858966305851936,
          0.04604022949934006,
          0.034117694944143295,
          0.034128062427043915,
          0.04681601747870445,
          0.0954495519399643,
          0.060292694717645645,
          0.13633930683135986,
          0.0004420860786922276,
          0.029657285660505295,
          0.02278261072933674,
          0.07039793580770493,
          0.1384596824645996,
          0.10131798684597015,
          0.10530515015125275,
          0.025469865649938583,
          0.044480957090854645,
          0.05407623574137688,
          0.16107988357543945,
          0.09315777570009232,
          0.02776409685611725,
          0.07060850411653519,
          0.027675487101078033,
          0.1387505829334259,
          0.1305065155029297,
          0.025095652788877487,
          0.051284871995449066,
          0.10382374376058578,
          0.03932396322488785,
          0.027213625609874725,
          0.1463007777929306,
          0.05800669640302658,
          0.007448658812791109,
          0.07882974296808243,
          0.001039051916450262,
          0.011391092091798782,
          0.039885763078927994,
          0.12576445937156677,
          0.011761884205043316,
          0.032356083393096924,
          0.07735566049814224,
          0.025151876732707024,
          0.008200504817068577,
          0.03525561839342117,
          0.017427019774913788,
          0.07765430212020874,
          0.0828670933842659,
          0.1091785877943039,
          0.016240250319242477,
          0.046431008726358414,
          0.01673150435090065,
          0.016249870881438255,
          0.03777056932449341,
          0.0131398756057024,
          0.0794047936797142,
          0.029931344091892242,
          0.025024039670825005,
          0.07367520779371262,
          0.00504668615758419,
          0.01910793036222458,
          0.08584294468164444,
          0.16957485675811768,
          0.0582146979868412,
          0.02097952924668789,
          0.02987373247742653,
          0.0474889799952507,
          0.13340899348258972,
          0.09130563586950302,
          0.024324996396899223,
          0.03557424619793892,
          0.014095662161707878,
          0.09786306321620941,
          0.0536777600646019,
          0.029142087325453758,
          0.06396973133087158,
          0.050507158041000366,
          0.04279673472046852,
          0.058632735162973404,
          0.05233439803123474,
          0.03127619996666908,
          0.07006187736988068,
          0.0030274773016572,
          0.04518021270632744,
          0.016811348497867584,
          0.016331104561686516,
          0.007676008157432079,
          0.03310514986515045,
          0.03327873349189758,
          0.06790916621685028,
          0.01102596428245306,
          0.03855929151177406,
          0.07244514673948288,
          0.007452827412635088,
          0.008458743803203106,
          0.016771160066127777,
          0.08994784206151962,
          0.04829287901520729,
          0.08360856771469116,
          0.03515385836362839,
          0.0016339869471266866,
          0.03815995901823044,
          0.023416880518198013,
          0.012695010751485825,
          0.008673053234815598,
          0.03329220414161682,
          0.10465853661298752,
          0.08683859556913376,
          0.03399594873189926,
          0.08310277760028839,
          0.18035262823104858,
          0.0056448280811309814,
          0.026954958215355873,
          0.016171522438526154,
          0.004725062288343906,
          0.011713463813066483,
          0.04689297825098038,
          0.03726552799344063
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "index"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"f0c79549-3187-4eea-a8ff-0d2ae8ca1484\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f0c79549-3187-4eea-a8ff-0d2ae8ca1484\")) {                    Plotly.newPlot(                        \"f0c79549-3187-4eea-a8ff-0d2ae8ca1484\",                        [{\"hovertemplate\":\"variable=0<br>index=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537],\"xaxis\":\"x\",\"y\":[1.001528024673462,0.9987738728523254,0.996366024017334,0.9922623038291931,0.9850645065307617,0.9719427227973938,0.9549973011016846,0.9310468435287476,0.8876874446868896,0.8598384857177734,0.7877967953681946,0.7112333178520203,0.5678841471672058,0.4273572266101837,0.3760666251182556,0.044959064573049545,0.1144859716296196,0.18906961381435394,0.540464460849762,0.564710795879364,0.4602814018726349,0.1919490545988083,0.24929368495941162,0.08623981475830078,0.23170003294944763,0.1160382404923439,0.36396560072898865,0.3596021234989166,0.282397985458374,0.26051339507102966,0.2658066749572754,0.28108835220336914,0.25131285190582275,0.16146808862686157,0.11836208403110504,0.03237254545092583,0.0442497581243515,0.03932888060808182,0.11079483479261398,0.1893691122531891,0.14735735952854156,0.1335960477590561,0.2009100615978241,0.14017271995544434,0.05006314814090729,0.037097394466400146,0.19157062470912933,0.08527440577745438,0.08977126330137253,0.08898414671421051,0.12246602028608322,0.07175444066524506,0.04724891111254692,0.028526095673441887,0.03072541020810604,0.02151845395565033,0.062367379665374756,0.055621933192014694,0.08843902498483658,0.07360583543777466,0.021957119926810265,0.05726008862257004,0.05985766276717186,0.04168585315346718,0.044426873326301575,0.062289778143167496,0.02289152890443802,0.0486263707280159,0.06129230558872223,0.015280935913324356,0.1657051146030426,0.00816095620393753,0.07951125502586365,0.05632193759083748,0.0853303074836731,0.0009461668087169528,0.0013453910360112786,0.018385479226708412,0.016466209664940834,0.06853852421045303,0.04888118803501129,5.771916767116636e-05,0.0008491131011396646,0.04658631607890129,0.05785438045859337,0.027965471148490906,0.0378095842897892,0.0905265286564827,0.029961273074150085,0.07425645738840103,0.019239189103245735,0.12164368480443954,0.031354013830423355,0.011487183161079884,0.0029519079253077507,0.047682445496320724,0.020709317177534103,0.021781932562589645,0.03584093227982521,0.03150162473320961,0.08072111010551453,0.044890016317367554,0.00547754904255271,0.06679818034172058,0.05074198916554451,0.0366457924246788,0.03489658236503601,0.05476469546556473,0.14762751758098602,0.023210588842630386,0.004671618342399597,0.04382937029004097,0.014214307069778442,0.008054068312048912,0.04505002498626709,0.0031420604791492224,0.1177452877163887,0.00012858548143412918,0.08297301828861237,0.041039932519197464,0.015631312504410744,0.04165303707122803,0.015223324298858643,0.0066607920452952385,0.0055386885069310665,0.03360581025481224,0.03806782141327858,0.025174856185913086,0.03518688678741455,0.028200410306453705,0.04143017902970314,0.06928277760744095,0.03391001373529434,0.03000253066420555,0.01938476972281933,0.0049146804958581924,0.0428072065114975,0.02975337579846382,0.03678250312805176,0.008056847378611565,0.133553609251976,0.10296191275119781,0.0836210772395134,0.01668308489024639,0.09469310939311981,0.0030990918166935444,0.006160666234791279,0.10413147509098053,0.04184148088097572,0.02911568619310856,0.03554677963256836,0.044349271804094315,0.04316570982336998,0.01180228777229786,0.03267974033951759,0.01870560646057129,0.019325340166687965,0.018241822719573975,0.05738076567649841,0.0032070481684058905,0.04255698621273041,0.07718260586261749,0.042187903076410294,0.016166284680366516,0.091769739985466,0.030302349478006363,0.0495205894112587,0.013290159404277802,0.005110177211463451,0.03824867680668831,0.06567329913377762,0.023194126784801483,0.04931643232703209,0.09475691616535187,0.013010862283408642,0.0033315718173980713,0.11612071096897125,0.02337604947388172,0.04995594173669815,0.05605567991733551,0.019169604405760765,0.0874103382229805,0.04112875461578369,0.09681011736392975,0.0034696701914072037,0.03204910457134247,0.11572009325027466,0.028553886339068413,0.030056936666369438,0.09429623186588287,0.029003988951444626,0.026338860392570496,0.08723429590463638,0.03336435183882713,0.06451143324375153,0.03762092813849449,0.0433008149266243,0.0295407772064209,0.03939942643046379,0.046510640531778336,0.0819263756275177,0.04587476700544357,0.13824328780174255,0.10677586495876312,0.0861409455537796,0.04087158665060997,0.07933104038238525,0.1436644047498703,0.08562242984771729,0.03674209862947464,0.026337577030062675,0.00300609995611012,0.13956190645694733,0.02330903150141239,0.1351483166217804,0.09117116779088974,0.08069492876529694,0.06096009910106659,0.03348139300942421,0.03170107677578926,0.08347367495298386,0.04949258267879486,0.09943933039903641,0.08888014405965805,0.0201655812561512,0.03076217882335186,0.05489702150225639,0.0022267841268330812,0.040936678647994995,0.01922304928302765,0.04701739549636841,0.02702593244612217,0.1159944236278534,0.04681537672877312,0.1023707166314125,0.017270537093281746,0.028105173259973526,0.13162942230701447,0.004872566554695368,0.04092983901500702,0.06732823699712753,0.010208169929683208,0.0035600969567894936,0.01953922212123871,0.020175842568278313,0.05847026780247688,0.06600946187973022,0.020011769607663155,0.06435997039079666,0.007426105439662933,0.034666772931814194,0.03703464940190315,0.02726054936647415,0.029793674126267433,0.05252647399902344,0.04718702286481857,0.05062142014503479,0.04171246662735939,0.02971821092069149,0.06050882115960121,0.023472247645258904,0.05318928509950638,0.04999057203531265,0.05363500490784645,0.04144642502069473,0.10175098478794098,0.07826965302228928,0.009233998134732246,0.0022450617980211973,0.00453694025054574,0.08159459382295609,0.07835227251052856,0.03910420462489128,0.013532259501516819,0.04560573399066925,0.00013841911277268082,0.10795039683580399,0.026009326800704002,0.007428670767694712,0.04618538171052933,0.056698717176914215,0.05232509970664978,0.04678330942988396,0.0020191019866615534,0.009810013696551323,0.014843232929706573,0.039942946285009384,0.13431069254875183,0.02306896261870861,0.0827394649386406,0.03361671417951584,0.009674588218331337,0.06385321915149689,0.11949065327644348,0.025615019723773003,0.05750058591365814,0.006733368616551161,0.014159153215587139,0.0002783346571959555,0.03058934211730957,0.09293171018362045,0.1426226794719696,0.08485028147697449,0.02053968794643879,0.018158236518502235,0.12339877337217331,0.1100156232714653,0.02212461270391941,0.0663796067237854,0.0001761503517627716,0.05060335621237755,0.04979678615927696,0.0163617804646492,0.08253445476293564,0.15626567602157593,0.13966061174869537,0.013140944764018059,0.15772917866706848,0.02328348532319069,0.04015544056892395,0.11001818627119064,0.055786218494176865,0.0825047418475151,0.026338111609220505,0.09514908492565155,0.12908999621868134,0.06634219735860825,0.1291927695274353,0.05671902373433113,0.0372714065015316,0.004246527329087257,0.05732005089521408,0.05490300804376602,0.09046570956707001,0.13648520410060883,0.11804094165563583,0.010564959608018398,0.10859294980764389,0.05661993846297264,0.0738534927368164,0.12605364620685577,0.0897754356265068,0.08318636566400528,0.02867766283452511,0.014085400849580765,0.053260043263435364,0.07044646143913269,0.10105301439762115,0.08101014047861099,0.06438285112380981,0.02220018208026886,0.07372137904167175,0.0016347351484000683,0.06851639598608017,0.057548899203538895,0.10929632186889648,7.150763849494979e-05,0.03656252846121788,0.001891906140372157,0.02453802153468132,0.10353365540504456,0.1320907473564148,0.04741726070642471,0.06688892841339111,0.007041738834232092,0.05563625693321228,0.06242851912975311,0.06892791390419006,0.08189260214567184,0.01933196745812893,0.05674179270863533,0.0008296596352010965,0.08985549211502075,0.1527615785598755,0.09709989279508591,0.04771878942847252,0.02499443106353283,0.11775559931993484,0.2012891322374344,0.16524949669837952,0.09779850393533707,0.032100941985845566,0.0006532954866997898,0.11553025990724564,0.04716810584068298,0.04469847306609154,0.0785597413778305,0.054749518632888794,0.03223957493901253,0.05032758787274361,0.006800921633839607,0.12064583599567413,0.06537935882806778,0.07815239578485489,0.043489255011081696,0.02026520110666752,0.037720974534749985,0.024449734017252922,0.02993679605424404,0.07869057357311249,0.05034682899713516,0.07339420169591904,0.05559029430150986,0.10176627337932587,0.14879745244979858,0.0034330079797655344,0.0981307104229927,0.10017375648021698,0.010306505486369133,0.1254214495420456,0.03811848908662796,0.03215823695063591,0.0445912666618824,0.015812594443559647,0.12216294556856155,0.04399055615067482,0.06525034457445145,0.0035029123537242413,0.07236883044242859,0.06073392555117607,0.06727265566587448,0.023858966305851936,0.04604022949934006,0.034117694944143295,0.034128062427043915,0.04681601747870445,0.0954495519399643,0.060292694717645645,0.13633930683135986,0.0004420860786922276,0.029657285660505295,0.02278261072933674,0.07039793580770493,0.1384596824645996,0.10131798684597015,0.10530515015125275,0.025469865649938583,0.044480957090854645,0.05407623574137688,0.16107988357543945,0.09315777570009232,0.02776409685611725,0.07060850411653519,0.027675487101078033,0.1387505829334259,0.1305065155029297,0.025095652788877487,0.051284871995449066,0.10382374376058578,0.03932396322488785,0.027213625609874725,0.1463007777929306,0.05800669640302658,0.007448658812791109,0.07882974296808243,0.001039051916450262,0.011391092091798782,0.039885763078927994,0.12576445937156677,0.011761884205043316,0.032356083393096924,0.07735566049814224,0.025151876732707024,0.008200504817068577,0.03525561839342117,0.017427019774913788,0.07765430212020874,0.0828670933842659,0.1091785877943039,0.016240250319242477,0.046431008726358414,0.01673150435090065,0.016249870881438255,0.03777056932449341,0.0131398756057024,0.0794047936797142,0.029931344091892242,0.025024039670825005,0.07367520779371262,0.00504668615758419,0.01910793036222458,0.08584294468164444,0.16957485675811768,0.0582146979868412,0.02097952924668789,0.02987373247742653,0.0474889799952507,0.13340899348258972,0.09130563586950302,0.024324996396899223,0.03557424619793892,0.014095662161707878,0.09786306321620941,0.0536777600646019,0.029142087325453758,0.06396973133087158,0.050507158041000366,0.04279673472046852,0.058632735162973404,0.05233439803123474,0.03127619996666908,0.07006187736988068,0.0030274773016572,0.04518021270632744,0.016811348497867584,0.016331104561686516,0.007676008157432079,0.03310514986515045,0.03327873349189758,0.06790916621685028,0.01102596428245306,0.03855929151177406,0.07244514673948288,0.007452827412635088,0.008458743803203106,0.016771160066127777,0.08994784206151962,0.04829287901520729,0.08360856771469116,0.03515385836362839,0.0016339869471266866,0.03815995901823044,0.023416880518198013,0.012695010751485825,0.008673053234815598,0.03329220414161682,0.10465853661298752,0.08683859556913376,0.03399594873189926,0.08310277760028839,0.18035262823104858,0.0056448280811309814,0.026954958215355873,0.016171522438526154,0.004725062288343906,0.011713463813066483,0.04689297825098038,0.03726552799344063],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('f0c79549-3187-4eea-a8ff-0d2ae8ca1484');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "px.line(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=0<br>index=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "0",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "0",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133
         ],
         "xaxis": "x",
         "y": [
          0.11644484102725983,
          0.018929321318864822,
          0.01758403889834881,
          0.010932865552604198,
          0.09924565255641937,
          0.01651495136320591,
          0.047766461968421936,
          0.08727683871984482,
          0.009879491291940212,
          0.03571619465947151,
          0.04110192880034447,
          0.011084004305303097,
          0.04745873063802719,
          0.010949326679110527,
          0.03301910683512688,
          0.10442472249269485,
          0.04982917383313179,
          0.025480661541223526,
          0.12112779170274734,
          0.07257052510976791,
          0.1334857940673828,
          0.04177553206682205,
          0.11243116855621338,
          0.001683903275988996,
          0.07044453918933868,
          0.06365098804235458,
          0.06960140913724899,
          0.025992438197135925,
          0.02524636499583721,
          0.010148953646421432,
          0.019741345196962357,
          0.03449169173836708,
          0.08909562975168228,
          0.01527591235935688,
          0.09087540954351425,
          0.05209710821509361,
          0.05163407325744629,
          0.05986225977540016,
          0.013261727057397366,
          0.09771011024713516,
          0.014285387471318245,
          0.038517605513334274,
          0.08987270295619965,
          0.037906210869550705,
          0.0005972865037620068,
          0.005822153761982918,
          0.07045928388834,
          0.0926593616604805,
          0.07038938254117966,
          0.10560454428195953,
          0.0063326479867100716,
          0.056992337107658386,
          0.10349832475185394,
          0.03136064112186432,
          0.05528106912970543,
          0.0256422758102417,
          0.0675225555896759,
          0.10564510524272919,
          0.022918572649359703,
          0.08645305782556534,
          0.12053638696670532,
          0.03154918923974037,
          0.04247938469052315,
          0.039125047624111176,
          0.07801846414804459,
          0.1456281840801239,
          0.0625985786318779,
          0.07078668475151062,
          0.033601321280002594,
          0.035702407360076904,
          0.10582008212804794,
          0.06643518805503845,
          0.05498477816581726,
          0.007884652353823185,
          0.05146433413028717,
          0.03868958726525307,
          0.11458607017993927,
          0.08497224003076553,
          0.0701388344168663,
          0.054081257432699203,
          0.07224729657173157,
          0.09470668435096741,
          0.06030220910906792,
          0.03925533965229988,
          0.007917359471321106,
          0.0875643640756607,
          0.009691048413515091,
          0.06362704932689667,
          0.021168826147913933,
          0.06549864262342453,
          0.04392567649483681,
          0.06357541680335999,
          0.10224897414445877,
          0.0037583729717880487,
          0.07703670859336853,
          0.007776161655783653,
          0.0057710618712008,
          0.06957725435495377,
          0.04065097123384476,
          0.0684768483042717,
          0.04642459750175476,
          0.07133618742227554,
          0.044885311275720596,
          0.01155633945018053,
          0.08558373898267746,
          0.004252299666404724,
          0.07676243036985397,
          0.1257547289133072,
          0.08415540307760239,
          0.12982980906963348,
          0.10404756665229797,
          0.03445492312312126,
          0.04624662920832634,
          0.010833246633410454,
          0.012312781065702438,
          0.03445086255669594,
          0.04943326115608215,
          0.08690091222524643,
          0.0535612516105175,
          0.09893450140953064,
          0.03924508020281792,
          0.12834830582141876,
          0.0793382078409195,
          0.07624873518943787,
          0.07749055325984955,
          0.03368106111884117,
          0.047071266919374466,
          0.053139474242925644,
          0.045819614082574844,
          0.04049341753125191,
          0.08599525690078735,
          0.0707625225186348,
          0.09597254544496536,
          0.05353367328643799
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "index"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"82418143-fba2-4626-8c22-029a176532cd\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"82418143-fba2-4626-8c22-029a176532cd\")) {                    Plotly.newPlot(                        \"82418143-fba2-4626-8c22-029a176532cd\",                        [{\"hovertemplate\":\"variable=0<br>index=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133],\"xaxis\":\"x\",\"y\":[0.11644484102725983,0.018929321318864822,0.01758403889834881,0.010932865552604198,0.09924565255641937,0.01651495136320591,0.047766461968421936,0.08727683871984482,0.009879491291940212,0.03571619465947151,0.04110192880034447,0.011084004305303097,0.04745873063802719,0.010949326679110527,0.03301910683512688,0.10442472249269485,0.04982917383313179,0.025480661541223526,0.12112779170274734,0.07257052510976791,0.1334857940673828,0.04177553206682205,0.11243116855621338,0.001683903275988996,0.07044453918933868,0.06365098804235458,0.06960140913724899,0.025992438197135925,0.02524636499583721,0.010148953646421432,0.019741345196962357,0.03449169173836708,0.08909562975168228,0.01527591235935688,0.09087540954351425,0.05209710821509361,0.05163407325744629,0.05986225977540016,0.013261727057397366,0.09771011024713516,0.014285387471318245,0.038517605513334274,0.08987270295619965,0.037906210869550705,0.0005972865037620068,0.005822153761982918,0.07045928388834,0.0926593616604805,0.07038938254117966,0.10560454428195953,0.0063326479867100716,0.056992337107658386,0.10349832475185394,0.03136064112186432,0.05528106912970543,0.0256422758102417,0.0675225555896759,0.10564510524272919,0.022918572649359703,0.08645305782556534,0.12053638696670532,0.03154918923974037,0.04247938469052315,0.039125047624111176,0.07801846414804459,0.1456281840801239,0.0625985786318779,0.07078668475151062,0.033601321280002594,0.035702407360076904,0.10582008212804794,0.06643518805503845,0.05498477816581726,0.007884652353823185,0.05146433413028717,0.03868958726525307,0.11458607017993927,0.08497224003076553,0.0701388344168663,0.054081257432699203,0.07224729657173157,0.09470668435096741,0.06030220910906792,0.03925533965229988,0.007917359471321106,0.0875643640756607,0.009691048413515091,0.06362704932689667,0.021168826147913933,0.06549864262342453,0.04392567649483681,0.06357541680335999,0.10224897414445877,0.0037583729717880487,0.07703670859336853,0.007776161655783653,0.0057710618712008,0.06957725435495377,0.04065097123384476,0.0684768483042717,0.04642459750175476,0.07133618742227554,0.044885311275720596,0.01155633945018053,0.08558373898267746,0.004252299666404724,0.07676243036985397,0.1257547289133072,0.08415540307760239,0.12982980906963348,0.10404756665229797,0.03445492312312126,0.04624662920832634,0.010833246633410454,0.012312781065702438,0.03445086255669594,0.04943326115608215,0.08690091222524643,0.0535612516105175,0.09893450140953064,0.03924508020281792,0.12834830582141876,0.0793382078409195,0.07624873518943787,0.07749055325984955,0.03368106111884117,0.047071266919374466,0.053139474242925644,0.045819614082574844,0.04049341753125191,0.08599525690078735,0.0707625225186348,0.09597254544496536,0.05353367328643799],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('82418143-fba2-4626-8c22-029a176532cd');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "px.line(test_losses)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=ground_truth<br>vehicle_count=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "ground_truth",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "ground_truth",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          1.3711339235305786,
          1.5804674625396729,
          0.1151333898305893,
          0.6332336068153381,
          1.5386006832122803,
          1.2246005535125732,
          1.3711339235305786,
          0.08373337239027023,
          0.28260013461112976,
          0.17270007729530334,
          1.6380341053009033,
          0.17270007729530334,
          1.1932005882263184,
          1.0728338956832886,
          1.5961674451828003,
          0.6437003016471863,
          1.1827338933944702,
          0.14653339982032776,
          0.28260013461112976,
          0.41866686940193176
         ],
         "xaxis": "x",
         "y": [
          18272.7421875,
          18272.7421875,
          18272.7421875,
          18272.7421875,
          18272.7421875,
          18272.7421875,
          18272.7421875,
          18272.7421875,
          18272.7421875,
          18272.7421875,
          18272.7421875,
          18272.7421875,
          18272.7421875,
          18272.7421875,
          18272.7421875,
          18272.7421875,
          18272.7421875,
          18272.7421875,
          18272.7421875,
          18272.7421875
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=predictions<br>vehicle_count=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "predictions",
         "marker": {
          "color": "#EF553B",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "predictions",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          1.3711339235305786,
          1.5804674625396729,
          0.1151333898305893,
          0.6332336068153381,
          1.5386006832122803,
          1.2246005535125732,
          1.3711339235305786,
          0.08373337239027023,
          0.28260013461112976,
          0.17270007729530334,
          1.6380341053009033,
          0.17270007729530334,
          1.1932005882263184,
          1.0728338956832886,
          1.5961674451828003,
          0.6437003016471863,
          1.1827338933944702,
          0.14653339982032776,
          0.28260013461112976,
          0.41866686940193176
         ],
         "xaxis": "x",
         "y": [
          16879.46875,
          17075.90234375,
          17568.919921875,
          18072.96875,
          16979.275390625,
          17362.2265625,
          16720.06640625,
          16059.4052734375,
          16979.716796875,
          17657.296875,
          16985.2578125,
          17657.296875,
          17804.1875,
          16708.892578125,
          17231.3359375,
          16339.119140625,
          18533.775390625,
          17452.564453125,
          16979.716796875,
          17021.482421875
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "vehicle_count"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"aeaa1103-af65-467c-aa64-df63f52556cc\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"aeaa1103-af65-467c-aa64-df63f52556cc\")) {                    Plotly.newPlot(                        \"aeaa1103-af65-467c-aa64-df63f52556cc\",                        [{\"hovertemplate\":\"variable=ground_truth<br>vehicle_count=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"ground_truth\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"ground_truth\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1.3711339235305786,1.5804674625396729,0.1151333898305893,0.6332336068153381,1.5386006832122803,1.2246005535125732,1.3711339235305786,0.08373337239027023,0.28260013461112976,0.17270007729530334,1.6380341053009033,0.17270007729530334,1.1932005882263184,1.0728338956832886,1.5961674451828003,0.6437003016471863,1.1827338933944702,0.14653339982032776,0.28260013461112976,0.41866686940193176],\"xaxis\":\"x\",\"y\":[18272.7421875,18272.7421875,18272.7421875,18272.7421875,18272.7421875,18272.7421875,18272.7421875,18272.7421875,18272.7421875,18272.7421875,18272.7421875,18272.7421875,18272.7421875,18272.7421875,18272.7421875,18272.7421875,18272.7421875,18272.7421875,18272.7421875,18272.7421875],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"variable=predictions<br>vehicle_count=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"predictions\",\"marker\":{\"color\":\"#EF553B\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"predictions\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1.3711339235305786,1.5804674625396729,0.1151333898305893,0.6332336068153381,1.5386006832122803,1.2246005535125732,1.3711339235305786,0.08373337239027023,0.28260013461112976,0.17270007729530334,1.6380341053009033,0.17270007729530334,1.1932005882263184,1.0728338956832886,1.5961674451828003,0.6437003016471863,1.1827338933944702,0.14653339982032776,0.28260013461112976,0.41866686940193176],\"xaxis\":\"x\",\"y\":[16879.46875,17075.90234375,17568.919921875,18072.96875,16979.275390625,17362.2265625,16720.06640625,16059.4052734375,16979.716796875,17657.296875,16985.2578125,17657.296875,17804.1875,16708.892578125,17231.3359375,16339.119140625,18533.775390625,17452.564453125,16979.716796875,17021.482421875],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"vehicle_count\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('aeaa1103-af65-467c-aa64-df63f52556cc');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = []\n",
    "ground_truth = []\n",
    "vehicle_counts = []\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    random_idx = np.random.randint(0,len(test_data))\n",
    "    x, y = test_data[random_idx]\n",
    "    vehicle_counts.append(x[0])\n",
    "    ground_truth.append(float(y))\n",
    "    pred_y = float(nn_model(x)[0])\n",
    "    preds.append(pred_y)\n",
    "\n",
    "df = pd.DataFrame({'vehicle_count': vehicle_counts, 'ground_truth': ground_truth, 'predictions': preds})\n",
    "\n",
    "px.scatter(df, x='vehicle_count', y=['ground_truth', 'predictions'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(nn_model.state_dict(), NN_MODEL_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Jun 22 2022, 20:18:18) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
