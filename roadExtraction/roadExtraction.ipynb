{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Road Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import cv2\n",
    "import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import segmentation_models_pytorch as smp\n",
    "import albumentations as album\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER = 'resnet50'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "CLASS_NAMES = ['road', 'background']\n",
    "CLASS_RGB_VALUES = [[255,255,255], [0,0,0]]\n",
    "IMG_SIZE = 1024\n",
    "IMG_PATH = '/home/ah2719/FYP/Spatial_Finance_Transport/data/road_extraction_example.jpg'\n",
    "PRED_MASK_IMG_PATH = '/home/ah2719/FYP/Spatial_Finance_Transport/data/pred_mask.jpeg'\n",
    "\n",
    "# Get RGB values of required classes\n",
    "SELECT_CLASS_INDICES = [CLASS_NAMES.index(cls.lower()) for cls in CLASS_NAMES]\n",
    "SELECT_CLASS_RGB_VALUES =  np.array(CLASS_RGB_VALUES)[SELECT_CLASS_INDICES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one hot encoding on label (TRAINING ONLY)\n",
    "def one_hot_encode(label, label_values):\n",
    "    \"\"\"\n",
    "    Convert a segmentation image label array to one-hot format\n",
    "    by replacing each pixel value with a vector of length num_classes\n",
    "    # Arguments\n",
    "        label: The 2D array segmentation image label\n",
    "        label_values\n",
    "        \n",
    "    # Returns\n",
    "        A 2D array with the same width and hieght as the input, but\n",
    "        with a depth size of num_classes\n",
    "    \"\"\"\n",
    "    semantic_map = []\n",
    "    for colour in label_values:\n",
    "        equality = np.equal(label, colour)\n",
    "        class_map = np.all(equality, axis = -1)\n",
    "        semantic_map.append(class_map)\n",
    "    semantic_map = np.stack(semantic_map, axis=-1)\n",
    "\n",
    "    return semantic_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform reverse one-hot-encoding on labels / preds\n",
    "def reverse_one_hot(image):\n",
    "    \"\"\"\n",
    "    Transform a 2D array in one-hot format (depth is num_classes),\n",
    "    to a 2D array with only 1 channel, where each pixel value is\n",
    "    the classified class key.\n",
    "    # Arguments\n",
    "        image: The one-hot format image \n",
    "        \n",
    "    # Returns\n",
    "        A 2D array with the same width and hieght as the input, but\n",
    "        with a depth size of 1, where each pixel value is the classified \n",
    "        class key.\n",
    "    \"\"\"\n",
    "    x = np.argmax(image, axis = -1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform colour coding on the reverse-one-hot outputs\n",
    "def colour_code_segmentation(pred_mask, img):\n",
    "    \"\"\"\n",
    "    Given a 1-channel array of class keys, colour code the segmentation results.\n",
    "    # Arguments\n",
    "        image: single channel array where each value represents the class key.\n",
    "        label_values\n",
    "\n",
    "    # Returns\n",
    "        Colour coded image for segmentation visualization\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    result_img = np.empty(img.shape)\n",
    "\n",
    "    print(\"pred_mask shape: {}\".format(pred_mask.shape))\n",
    "    \n",
    "    for i in range(IMG_SIZE):\n",
    "        for j in range(IMG_SIZE):\n",
    "            if np.any(pred_mask[i][j]):\n",
    "                result_img[i][j] = img[i][j]\n",
    "            else:\n",
    "                result_img[i][j] = np.array([0,0,0])\n",
    "    \n",
    "\n",
    "    where = np.where(pred_mask == 1)\n",
    "\n",
    "    print(\"final result_img shape: {}\".format(result_img.shape))\n",
    "    return result_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessing(preprocessing_fn=None):\n",
    "    \"\"\"Construct preprocessing transform    \n",
    "    Args:\n",
    "        preprocessing_fn (callable): data normalization function \n",
    "            (can be specific for each pretrained neural network)\n",
    "    Return:\n",
    "        transform: albumentations.Compose\n",
    "    \"\"\"\n",
    "    _transform = []\n",
    "    if preprocessing_fn:\n",
    "        _transform.append(album.Lambda(image=preprocessing_fn))\n",
    "    _transform.append(album.Lambda(image=to_tensor, mask=to_tensor))\n",
    "        \n",
    "    return album.Compose(_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Road Extraction Model\n",
    "https://ieeexplore.ieee.org/document/8127098\n",
    "\n",
    "https://www.kaggle.com/code/balraj98/road-extraction-from-satellite-images-deeplabv3/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May need to refer to https://www.kaggle.com/code/balraj98/road-extraction-from-satellite-images-deeplabv3/comments if errors\n",
    "#model = torch.load(\"/home/ah2719/FYP/Spatial_Finance_Transport/models/best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chkpt = torch.load(\"/home/ah2719/FYP/Spatial_Finance_Transport/models/state_dict.pth\")\n",
    "model = smp.DeepLabV3Plus(\n",
    "    encoder_name='resnet50', \n",
    "    encoder_weights='imagenet', \n",
    "    classes=2, \n",
    "    activation='sigmoid',\n",
    ")\n",
    "model.load_state_dict(chkpt)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random inference on a dataset not used for training process\n",
    "random_idx = random.randint(1,10)\n",
    "img = cv2.imread(IMG_PATH)\n",
    "img= cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n",
    "img= cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#show image\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "img_preprocessed= preprocessing_fn(img)\n",
    "x_tensor  = to_tensor(img_preprocessed)\n",
    "x_tensor = torch.from_numpy(x_tensor).unsqueeze(0)\n",
    "print(x_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mask = model(x_tensor)\n",
    "pred_mask = pred_mask.squeeze().detach().numpy()\n",
    "pred_mask = np.transpose(pred_mask,(1,2,0))\n",
    "\n",
    "pred_mask_reversed = reverse_one_hot(pred_mask)\n",
    "pred_mask_processed = colour_code_segmentation(pred_mask_reversed, img)\n",
    "\n",
    "pred_mask_processed = (pred_mask_processed * 255).astype(np.uint8)\n",
    "\n",
    "# show prediction\n",
    "plt.imshow(pred_mask_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mask_im = Image.fromarray(pred_mask_processed)\n",
    "pred_mask_im.save(\"/home/ah2719/FYP/Spatial_Finance_Transport/data/pred_mask.jpeg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save model state dict\n",
    "#torch.save(model.state_dict(), \"/home/ah2719/FYP/Spatial_Finance_Transport/models/state_dict.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line Segment Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read gray image\n",
    "img = cv2.imread(PRED_MASK_IMG_PATH,0)\n",
    "\n",
    "#Create default parametrization LSD\n",
    "lsd = cv2.createLineSegmentDetector(0)\n",
    "\n",
    "#Detect lines in the image\n",
    "lines = lsd.detect(img)[0] #Position 0 of the returned tuple are the detected lines\n",
    "\n",
    "#Draw detected lines in the image\n",
    "drawn_img = lsd.drawSegments(img,lines)\n",
    "\n",
    "#Show image\n",
    "plt.imshow(drawn_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
